{"edges": [[0, 6], [0, 2], [0, 1], [0, 3], [0, 4], [0, 5], [6, 7], [6, 8]], "layout": [[0.45454545454545453, 0.0], [0.0, 0.5], [0.18181818181818182, 0.5], [0.36363636363636365, 0.5], [0.5454545454545454, 0.5], [0.7272727272727273, 0.5], [0.9090909090909091, 0.5], [0.8181818181818182, 1.0], [1.0, 1.0]], "plan": ["To implement the preliminary version of QualityRoute, we will create a synthetic\ndataset to simulate query-response pairs. The model will be a simple linear\nregression to predict output quality based on the input features. We'll also\nsimulate processing time for each query. The training will involve optimizing\nthe model to minimize the loss while tracking the quality-speed trade-off score\nduring validation. Finally, we'll save the evaluation metrics and predictions\nfor further analysis.", "Hyperparam tuning name: learning rate. To implement hyperparameter tuning for\nthe learning rate, I will modify the existing training loop to iterate over a\npredefined list of learning rates. For each learning rate, I will initialize a\nnew model and optimizer, train the model, and collect the metrics and losses for\nboth training and validation phases. After completing the training for all\nlearning rates, I will save the results in a structured format, including\nmetrics and losses for each learning rate.", "Hyperparam tuning name: batch_size. To implement hyperparameter tuning for the\nbatch size in the provided code, I will create a loop that iterates over a\npredefined list of batch sizes. For each batch size, I will initialize the\nDataLoader and train the model, recording the training and validation losses as\nwell as the quality-speed tradeoff metrics. Finally, I will save all relevant\nexperiment data into the specified format for later analysis.", "Hyperparam tuning name: num_epochs. To implement hyperparameter tuning for the\nnumber of epochs, I will replace the fixed epoch count (50) with a variable that\nallows for testing different epoch values. I will create a list of potential\nepoch values and loop through each value, training the model on each iteration\nand recording the corresponding training and validation losses. This will allow\nus to assess the impact of varying epoch numbers on model performance.", "Hyperparam tuning name: weight_decay. To implement hyperparameter tuning for the\nweight decay parameter, I will modify the optimizer to include weight decay and\ncreate a loop that tests multiple values of the weight decay parameter. Each\nconfiguration will train the model, and I will store the training and validation\nlosses, as well as any relevant metrics for each weight decay value. After\ntraining, the results will be saved using the specified naming convention.", "Hyperparam tuning name: dropout_rate. To implement hyperparameter tuning for the\ndropout rate in the given code, I will modify the `QualityPredictor` model to\ninclude a dropout layer. I will create a function to train and evaluate the\nmodel for different dropout rates and store the results in the `experiment_data`\nstructure. This will allow us to analyze how varying the dropout rate impacts\nthe model's performance on the validation set.", "Hyperparam tuning name: momentum. To implement hyperparameter tuning for the\nmomentum parameter in the optimization process, I will modify the existing code\nto include a range of momentum values. I will create a loop that iterates over\nthese values, adjusts the optimizer to use SGD with momentum, and records the\ntraining and validation losses as well as other metrics for each momentum value.\nThe results will be saved in a structured format, allowing for easy analysis of\nthe effect of momentum on model performance.", "Seed node", "Seed node"], "code": ["import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset, random_split\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n\n# Synthetic dataset generation\nclass QueryResponseDataset(Dataset):\n    def __init__(self, num_samples=1000):\n        self.features = np.random.rand(num_samples, 5)  # 5 features\n        self.quality = np.dot(\n            self.features, np.array([0.3, 0.2, 0.5, 0.1, 0.4])\n        ) + np.random.normal(0, 0.1, num_samples)\n        self.processing_time = (\n            np.random.rand(num_samples) * 0.5 + 0.5\n        )  # Simulated processing time between 0.5 and 1.0 seconds\n\n    def __len__(self):\n        return len(self.features)\n\n    def __getitem__(self, idx):\n        return {\n            \"features\": torch.tensor(self.features[idx], dtype=torch.float32),\n            \"quality\": torch.tensor(self.quality[idx], dtype=torch.float32),\n            \"processing_time\": torch.tensor(\n                self.processing_time[idx], dtype=torch.float32\n            ),\n        }\n\n\n# Model definition\nclass QualityPredictor(nn.Module):\n    def __init__(self):\n        super(QualityPredictor, self).__init__()\n        self.linear = nn.Linear(5, 1)\n\n    def forward(self, x):\n        return self.linear(x)\n\n\n# Training and evaluation\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\ndataset = QueryResponseDataset()\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\nmodel = QualityPredictor().to(device)\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.01)\n\nexperiment_data = {\n    \"quality_route\": {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    },\n}\n\n# Training loop\nfor epoch in range(50):\n    model.train()\n    total_loss = 0\n    for batch in train_loader:\n        features = batch[\"features\"].to(device)\n        quality = batch[\"quality\"].to(device)\n        optimizer.zero_grad()\n        outputs = model(features)\n        loss = criterion(outputs.squeeze(), quality)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    avg_train_loss = total_loss / len(train_loader)\n    experiment_data[\"quality_route\"][\"losses\"][\"train\"].append(avg_train_loss)\n\n    # Validation phase\n    model.eval()\n    val_loss = 0\n    total_quality = 0\n    total_processing_time = 0\n    with torch.no_grad():\n        for batch in val_loader:\n            features = batch[\"features\"].to(device)\n            quality = batch[\"quality\"].to(device)\n            processing_time = batch[\"processing_time\"].to(device)\n            outputs = model(features)\n            val_loss += criterion(outputs.squeeze(), quality).item()\n            total_quality += outputs.sum().item()\n            total_processing_time += processing_time.sum().item()\n\n    avg_val_loss = val_loss / len(val_loader)\n    experiment_data[\"quality_route\"][\"losses\"][\"val\"].append(avg_val_loss)\n    quality_speed_tradeoff = total_quality / total_processing_time  # Simplified metric\n    experiment_data[\"quality_route\"][\"metrics\"][\"val\"].append(quality_speed_tradeoff)\n\n    print(\n        f\"Epoch {epoch+1}: train_loss = {avg_train_loss:.4f}, validation_loss = {avg_val_loss:.4f}, quality_speed_tradeoff = {quality_speed_tradeoff:.4f}\"\n    )\n\n# Saving experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset, random_split\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n\nclass QueryResponseDataset(Dataset):\n    def __init__(self, num_samples=1000):\n        self.features = np.random.rand(num_samples, 5)\n        self.quality = np.dot(\n            self.features, np.array([0.3, 0.2, 0.5, 0.1, 0.4])\n        ) + np.random.normal(0, 0.1, num_samples)\n        self.processing_time = np.random.rand(num_samples) * 0.5 + 0.5\n\n    def __len__(self):\n        return len(self.features)\n\n    def __getitem__(self, idx):\n        return {\n            \"features\": torch.tensor(self.features[idx], dtype=torch.float32),\n            \"quality\": torch.tensor(self.quality[idx], dtype=torch.float32),\n            \"processing_time\": torch.tensor(\n                self.processing_time[idx], dtype=torch.float32\n            ),\n        }\n\n\nclass QualityPredictor(nn.Module):\n    def __init__(self):\n        super(QualityPredictor, self).__init__()\n        self.linear = nn.Linear(5, 1)\n\n    def forward(self, x):\n        return self.linear(x)\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\ndataset = QueryResponseDataset()\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\nlearning_rates = [0.001, 0.01, 0.1]\nexperiment_data = {\n    \"hyperparam_tuning_learning_rate\": {\n        \"quality_route\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n    },\n}\n\nfor lr in learning_rates:\n    model = QualityPredictor().to(device)\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n\n    for epoch in range(50):\n        model.train()\n        total_loss = 0\n        for batch in train_loader:\n            features = batch[\"features\"].to(device)\n            quality = batch[\"quality\"].to(device)\n            optimizer.zero_grad()\n            outputs = model(features)\n            loss = criterion(outputs.squeeze(), quality)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        avg_train_loss = total_loss / len(train_loader)\n        experiment_data[\"hyperparam_tuning_learning_rate\"][\"quality_route\"][\"losses\"][\n            \"train\"\n        ].append(avg_train_loss)\n\n        model.eval()\n        val_loss = 0\n        total_quality = 0\n        total_processing_time = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                features = batch[\"features\"].to(device)\n                quality = batch[\"quality\"].to(device)\n                processing_time = batch[\"processing_time\"].to(device)\n                outputs = model(features)\n                val_loss += criterion(outputs.squeeze(), quality).item()\n                total_quality += outputs.sum().item()\n                total_processing_time += processing_time.sum().item()\n\n        avg_val_loss = val_loss / len(val_loader)\n        experiment_data[\"hyperparam_tuning_learning_rate\"][\"quality_route\"][\"losses\"][\n            \"val\"\n        ].append(avg_val_loss)\n        quality_speed_tradeoff = total_quality / total_processing_time\n        experiment_data[\"hyperparam_tuning_learning_rate\"][\"quality_route\"][\"metrics\"][\n            \"val\"\n        ].append(quality_speed_tradeoff)\n\n        print(\n            f\"Learning Rate: {lr}, Epoch {epoch+1}: train_loss = {avg_train_loss:.4f}, validation_loss = {avg_val_loss:.4f}, quality_speed_tradeoff = {quality_speed_tradeoff:.4f}\"\n        )\n\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset, random_split\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n\n# Synthetic dataset generation\nclass QueryResponseDataset(Dataset):\n    def __init__(self, num_samples=1000):\n        self.features = np.random.rand(num_samples, 5)  # 5 features\n        self.quality = np.dot(\n            self.features, np.array([0.3, 0.2, 0.5, 0.1, 0.4])\n        ) + np.random.normal(0, 0.1, num_samples)\n        self.processing_time = (\n            np.random.rand(num_samples) * 0.5 + 0.5\n        )  # Simulated processing time between 0.5 and 1.0 seconds\n\n    def __len__(self):\n        return len(self.features)\n\n    def __getitem__(self, idx):\n        return {\n            \"features\": torch.tensor(self.features[idx], dtype=torch.float32),\n            \"quality\": torch.tensor(self.quality[idx], dtype=torch.float32),\n            \"processing_time\": torch.tensor(\n                self.processing_time[idx], dtype=torch.float32\n            ),\n        }\n\n\n# Model definition\nclass QualityPredictor(nn.Module):\n    def __init__(self):\n        super(QualityPredictor, self).__init__()\n        self.linear = nn.Linear(5, 1)\n\n    def forward(self, x):\n        return self.linear(x)\n\n\n# Training and evaluation\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\ndataset = QueryResponseDataset()\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\n# Hyperparameter tuning for batch_size\nbatch_sizes = [16, 32, 64]  # List of batch sizes to try\nexperiment_data = {\"batch_size_tuning\": {}}\n\nfor batch_size in batch_sizes:\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\n    model = QualityPredictor().to(device)\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.01)\n\n    experiment_data[\"batch_size_tuning\"][f\"batch_size_{batch_size}\"] = {\n        \"metrics\": {\"train\": [], \"val\": []},\n        \"losses\": {\"train\": [], \"val\": []},\n        \"predictions\": [],\n        \"ground_truth\": [],\n    }\n\n    # Training loop\n    for epoch in range(50):\n        model.train()\n        total_loss = 0\n        for batch in train_loader:\n            features = batch[\"features\"].to(device)\n            quality = batch[\"quality\"].to(device)\n            optimizer.zero_grad()\n            outputs = model(features)\n            loss = criterion(outputs.squeeze(), quality)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        avg_train_loss = total_loss / len(train_loader)\n        experiment_data[\"batch_size_tuning\"][f\"batch_size_{batch_size}\"][\"losses\"][\n            \"train\"\n        ].append(avg_train_loss)\n\n        # Validation phase\n        model.eval()\n        val_loss = 0\n        total_quality = 0\n        total_processing_time = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                features = batch[\"features\"].to(device)\n                quality = batch[\"quality\"].to(device)\n                processing_time = batch[\"processing_time\"].to(device)\n                outputs = model(features)\n                val_loss += criterion(outputs.squeeze(), quality).item()\n                total_quality += outputs.sum().item()\n                total_processing_time += processing_time.sum().item()\n\n        avg_val_loss = val_loss / len(val_loader)\n        experiment_data[\"batch_size_tuning\"][f\"batch_size_{batch_size}\"][\"losses\"][\n            \"val\"\n        ].append(avg_val_loss)\n        quality_speed_tradeoff = (\n            total_quality / total_processing_time\n        )  # Simplified metric\n        experiment_data[\"batch_size_tuning\"][f\"batch_size_{batch_size}\"][\"metrics\"][\n            \"val\"\n        ].append(quality_speed_tradeoff)\n\n        print(\n            f\"Batch size {batch_size}, Epoch {epoch+1}: train_loss = {avg_train_loss:.4f}, validation_loss = {avg_val_loss:.4f}, quality_speed_tradeoff = {quality_speed_tradeoff:.4f}\"\n        )\n\n# Saving experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset, random_split\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n\n# Synthetic dataset generation\nclass QueryResponseDataset(Dataset):\n    def __init__(self, num_samples=1000):\n        self.features = np.random.rand(num_samples, 5)  # 5 features\n        self.quality = np.dot(\n            self.features, np.array([0.3, 0.2, 0.5, 0.1, 0.4])\n        ) + np.random.normal(0, 0.1, num_samples)\n        self.processing_time = (\n            np.random.rand(num_samples) * 0.5 + 0.5\n        )  # Simulated processing time between 0.5 and 1.0 seconds\n\n    def __len__(self):\n        return len(self.features)\n\n    def __getitem__(self, idx):\n        return {\n            \"features\": torch.tensor(self.features[idx], dtype=torch.float32),\n            \"quality\": torch.tensor(self.quality[idx], dtype=torch.float32),\n            \"processing_time\": torch.tensor(\n                self.processing_time[idx], dtype=torch.float32\n            ),\n        }\n\n\n# Model definition\nclass QualityPredictor(nn.Module):\n    def __init__(self):\n        super(QualityPredictor, self).__init__()\n        self.linear = nn.Linear(5, 1)\n\n    def forward(self, x):\n        return self.linear(x)\n\n\n# Training and evaluation\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\ndataset = QueryResponseDataset()\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\nmodel = QualityPredictor().to(device)\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.01)\n\nexperiment_data = {\n    \"hyperparam_tuning_epochs\": {\n        \"quality_route\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n    },\n}\n\n# Hyperparameter tuning for num_epochs\nepoch_values = [10, 20, 30, 40, 50]  # Different epoch values to test\nfor num_epochs in epoch_values:\n    print(f\"Training for {num_epochs} epochs...\")\n\n    for epoch in range(num_epochs):\n        model.train()\n        total_loss = 0\n        for batch in train_loader:\n            features = batch[\"features\"].to(device)\n            quality = batch[\"quality\"].to(device)\n            optimizer.zero_grad()\n            outputs = model(features)\n            loss = criterion(outputs.squeeze(), quality)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        avg_train_loss = total_loss / len(train_loader)\n        experiment_data[\"hyperparam_tuning_epochs\"][\"quality_route\"][\"losses\"][\n            \"train\"\n        ].append(avg_train_loss)\n\n        # Validation phase\n        model.eval()\n        val_loss = 0\n        total_quality = 0\n        total_processing_time = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                features = batch[\"features\"].to(device)\n                quality = batch[\"quality\"].to(device)\n                processing_time = batch[\"processing_time\"].to(device)\n                outputs = model(features)\n                val_loss += criterion(outputs.squeeze(), quality).item()\n                total_quality += outputs.sum().item()\n                total_processing_time += processing_time.sum().item()\n\n        avg_val_loss = val_loss / len(val_loader)\n        experiment_data[\"hyperparam_tuning_epochs\"][\"quality_route\"][\"losses\"][\n            \"val\"\n        ].append(avg_val_loss)\n        quality_speed_tradeoff = (\n            total_quality / total_processing_time\n        )  # Simplified metric\n        experiment_data[\"hyperparam_tuning_epochs\"][\"quality_route\"][\"metrics\"][\n            \"val\"\n        ].append(quality_speed_tradeoff)\n\n        print(\n            f\"Epoch {epoch+1}: train_loss = {avg_train_loss:.4f}, validation_loss = {avg_val_loss:.4f}, quality_speed_tradeoff = {quality_speed_tradeoff:.4f}\"\n        )\n\n# Saving experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset, random_split\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n\n# Synthetic dataset generation\nclass QueryResponseDataset(Dataset):\n    def __init__(self, num_samples=1000):\n        self.features = np.random.rand(num_samples, 5)  # 5 features\n        self.quality = np.dot(\n            self.features, np.array([0.3, 0.2, 0.5, 0.1, 0.4])\n        ) + np.random.normal(0, 0.1, num_samples)\n        self.processing_time = (\n            np.random.rand(num_samples) * 0.5 + 0.5\n        )  # Simulated processing time between 0.5 and 1.0 seconds\n\n    def __len__(self):\n        return len(self.features)\n\n    def __getitem__(self, idx):\n        return {\n            \"features\": torch.tensor(self.features[idx], dtype=torch.float32),\n            \"quality\": torch.tensor(self.quality[idx], dtype=torch.float32),\n            \"processing_time\": torch.tensor(\n                self.processing_time[idx], dtype=torch.float32\n            ),\n        }\n\n\n# Model definition\nclass QualityPredictor(nn.Module):\n    def __init__(self):\n        super(QualityPredictor, self).__init__()\n        self.linear = nn.Linear(5, 1)\n\n    def forward(self, x):\n        return self.linear(x)\n\n\n# Training and evaluation\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\ndataset = QueryResponseDataset()\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\nweight_decays = [0.0, 0.01, 0.001, 0.0001]  # Different weight decay values\nexperiment_data = {\n    \"weight_decay_tuning\": {\n        \"query_response_dataset\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n    },\n}\n\nfor wd in weight_decays:\n    model = QualityPredictor().to(device)\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=wd)\n\n    for epoch in range(50):\n        model.train()\n        total_loss = 0\n        for batch in train_loader:\n            features = batch[\"features\"].to(device)\n            quality = batch[\"quality\"].to(device)\n            optimizer.zero_grad()\n            outputs = model(features)\n            loss = criterion(outputs.squeeze(), quality)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        avg_train_loss = total_loss / len(train_loader)\n        experiment_data[\"weight_decay_tuning\"][\"query_response_dataset\"][\"losses\"][\n            \"train\"\n        ].append(avg_train_loss)\n\n        # Validation phase\n        model.eval()\n        val_loss = 0\n        total_quality = 0\n        total_processing_time = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                features = batch[\"features\"].to(device)\n                quality = batch[\"quality\"].to(device)\n                processing_time = batch[\"processing_time\"].to(device)\n                outputs = model(features)\n                val_loss += criterion(outputs.squeeze(), quality).item()\n                total_quality += outputs.sum().item()\n                total_processing_time += processing_time.sum().item()\n\n        avg_val_loss = val_loss / len(val_loader)\n        experiment_data[\"weight_decay_tuning\"][\"query_response_dataset\"][\"losses\"][\n            \"val\"\n        ].append(avg_val_loss)\n        quality_speed_tradeoff = (\n            total_quality / total_processing_time\n        )  # Simplified metric\n        experiment_data[\"weight_decay_tuning\"][\"query_response_dataset\"][\"metrics\"][\n            \"val\"\n        ].append(quality_speed_tradeoff)\n\n        print(\n            f\"Weight Decay {wd}: Epoch {epoch+1}: train_loss = {avg_train_loss:.4f}, validation_loss = {avg_val_loss:.4f}, quality_speed_tradeoff = {quality_speed_tradeoff:.4f}\"\n        )\n\n# Saving experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset, random_split\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n\n# Synthetic dataset generation\nclass QueryResponseDataset(Dataset):\n    def __init__(self, num_samples=1000):\n        self.features = np.random.rand(num_samples, 5)  # 5 features\n        self.quality = np.dot(\n            self.features, np.array([0.3, 0.2, 0.5, 0.1, 0.4])\n        ) + np.random.normal(0, 0.1, num_samples)\n        self.processing_time = (\n            np.random.rand(num_samples) * 0.5 + 0.5\n        )  # Simulated processing time between 0.5 and 1.0 seconds\n\n    def __len__(self):\n        return len(self.features)\n\n    def __getitem__(self, idx):\n        return {\n            \"features\": torch.tensor(self.features[idx], dtype=torch.float32),\n            \"quality\": torch.tensor(self.quality[idx], dtype=torch.float32),\n            \"processing_time\": torch.tensor(\n                self.processing_time[idx], dtype=torch.float32\n            ),\n        }\n\n\n# Model definition with dropout\nclass QualityPredictor(nn.Module):\n    def __init__(self, dropout_rate=0.0):\n        super(QualityPredictor, self).__init__()\n        self.dropout = nn.Dropout(dropout_rate)\n        self.linear = nn.Linear(5, 1)\n\n    def forward(self, x):\n        x = self.dropout(x)\n        return self.linear(x)\n\n\n# Training and evaluation function\ndef train_and_evaluate(dropout_rate):\n    model = QualityPredictor(dropout_rate).to(device)\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.01)\n\n    for epoch in range(50):\n        model.train()\n        total_loss = 0\n        for batch in train_loader:\n            features = batch[\"features\"].to(device)\n            quality = batch[\"quality\"].to(device)\n            optimizer.zero_grad()\n            outputs = model(features)\n            loss = criterion(outputs.squeeze(), quality)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        avg_train_loss = total_loss / len(train_loader)\n        experiment_data[\"dropout_tuning\"][\"dropout_rate_\" + str(dropout_rate)][\n            \"losses\"\n        ][\"train\"].append(avg_train_loss)\n\n        # Validation phase\n        model.eval()\n        val_loss = 0\n        total_quality = 0\n        total_processing_time = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                features = batch[\"features\"].to(device)\n                quality = batch[\"quality\"].to(device)\n                processing_time = batch[\"processing_time\"].to(device)\n                outputs = model(features)\n                val_loss += criterion(outputs.squeeze(), quality).item()\n                total_quality += outputs.sum().item()\n                total_processing_time += processing_time.sum().item()\n\n        avg_val_loss = val_loss / len(val_loader)\n        experiment_data[\"dropout_tuning\"][\"dropout_rate_\" + str(dropout_rate)][\n            \"losses\"\n        ][\"val\"].append(avg_val_loss)\n        quality_speed_tradeoff = (\n            total_quality / total_processing_time\n        )  # Simplified metric\n        experiment_data[\"dropout_tuning\"][\"dropout_rate_\" + str(dropout_rate)][\n            \"metrics\"\n        ][\"val\"].append(quality_speed_tradeoff)\n\n        print(\n            f\"Dropout {dropout_rate} Epoch {epoch+1}: train_loss = {avg_train_loss:.4f}, validation_loss = {avg_val_loss:.4f}, quality_speed_tradeoff = {quality_speed_tradeoff:.4f}\"\n        )\n\n\n# Device configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Dataset preparation\ndataset = QueryResponseDataset()\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\n# Experiment data structure\nexperiment_data = {\n    \"dropout_tuning\": {\n        \"dropout_rate_0.0\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n        \"dropout_rate_0.2\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n        \"dropout_rate_0.5\": {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        },\n    }\n}\n\n# Train and evaluate for different dropout rates\nfor rate in [0.0, 0.2, 0.5]:\n    train_and_evaluate(rate)\n\n# Saving experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset, random_split\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n\n# Synthetic dataset generation\nclass QueryResponseDataset(Dataset):\n    def __init__(self, num_samples=1000):\n        self.features = np.random.rand(num_samples, 5)  # 5 features\n        self.quality = np.dot(\n            self.features, np.array([0.3, 0.2, 0.5, 0.1, 0.4])\n        ) + np.random.normal(0, 0.1, num_samples)\n        self.processing_time = (\n            np.random.rand(num_samples) * 0.5 + 0.5\n        )  # Simulated processing time between 0.5 and 1.0 seconds\n\n    def __len__(self):\n        return len(self.features)\n\n    def __getitem__(self, idx):\n        return {\n            \"features\": torch.tensor(self.features[idx], dtype=torch.float32),\n            \"quality\": torch.tensor(self.quality[idx], dtype=torch.float32),\n            \"processing_time\": torch.tensor(\n                self.processing_time[idx], dtype=torch.float32\n            ),\n        }\n\n\n# Model definition\nclass QualityPredictor(nn.Module):\n    def __init__(self):\n        super(QualityPredictor, self).__init__()\n        self.linear = nn.Linear(5, 1)\n\n    def forward(self, x):\n        return self.linear(x)\n\n\n# Training and evaluation\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\ndataset = QueryResponseDataset()\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\nmomentum_values = [0.0, 0.5, 0.9]  # Hyperparameter tuning for momentum\nexperiment_data = {\n    \"hyperparam_tuning_momentum\": {\n        str(momentum): {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n        for momentum in momentum_values\n    }\n}\n\nfor momentum in momentum_values:\n    model = QualityPredictor().to(device)\n    criterion = nn.MSELoss()\n    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=momentum)\n\n    for epoch in range(50):\n        model.train()\n        total_loss = 0\n        for batch in train_loader:\n            features = batch[\"features\"].to(device)\n            quality = batch[\"quality\"].to(device)\n            optimizer.zero_grad()\n            outputs = model(features)\n            loss = criterion(outputs.squeeze(), quality)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        avg_train_loss = total_loss / len(train_loader)\n        experiment_data[\"hyperparam_tuning_momentum\"][str(momentum)][\"losses\"][\n            \"train\"\n        ].append(avg_train_loss)\n\n        # Validation phase\n        model.eval()\n        val_loss = 0\n        total_quality = 0\n        total_processing_time = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                features = batch[\"features\"].to(device)\n                quality = batch[\"quality\"].to(device)\n                processing_time = batch[\"processing_time\"].to(device)\n                outputs = model(features)\n                val_loss += criterion(outputs.squeeze(), quality).item()\n                total_quality += outputs.sum().item()\n                total_processing_time += processing_time.sum().item()\n\n        avg_val_loss = val_loss / len(val_loader)\n        experiment_data[\"hyperparam_tuning_momentum\"][str(momentum)][\"losses\"][\n            \"val\"\n        ].append(avg_val_loss)\n        quality_speed_tradeoff = (\n            total_quality / total_processing_time\n        )  # Simplified metric\n        experiment_data[\"hyperparam_tuning_momentum\"][str(momentum)][\"metrics\"][\n            \"val\"\n        ].append(quality_speed_tradeoff)\n\n        print(\n            f\"Momentum {momentum}, Epoch {epoch+1}: train_loss = {avg_train_loss:.4f}, validation_loss = {avg_val_loss:.4f}, quality_speed_tradeoff = {quality_speed_tradeoff:.4f}\"\n        )\n\n# Saving experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset, random_split\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n\n# Synthetic dataset generation\nclass QueryResponseDataset(Dataset):\n    def __init__(self, num_samples=1000):\n        self.features = np.random.rand(num_samples, 5)  # 5 features\n        self.quality = np.dot(\n            self.features, np.array([0.3, 0.2, 0.5, 0.1, 0.4])\n        ) + np.random.normal(0, 0.1, num_samples)\n        self.processing_time = (\n            np.random.rand(num_samples) * 0.5 + 0.5\n        )  # Simulated processing time between 0.5 and 1.0 seconds\n\n    def __len__(self):\n        return len(self.features)\n\n    def __getitem__(self, idx):\n        return {\n            \"features\": torch.tensor(self.features[idx], dtype=torch.float32),\n            \"quality\": torch.tensor(self.quality[idx], dtype=torch.float32),\n            \"processing_time\": torch.tensor(\n                self.processing_time[idx], dtype=torch.float32\n            ),\n        }\n\n\n# Model definition\nclass QualityPredictor(nn.Module):\n    def __init__(self):\n        super(QualityPredictor, self).__init__()\n        self.linear = nn.Linear(5, 1)\n\n    def forward(self, x):\n        return self.linear(x)\n\n\n# Training and evaluation\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\ndataset = QueryResponseDataset()\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\nmomentum_values = [0.0, 0.5, 0.9]  # Hyperparameter tuning for momentum\nexperiment_data = {\n    \"hyperparam_tuning_momentum\": {\n        str(momentum): {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n        for momentum in momentum_values\n    }\n}\n\nfor momentum in momentum_values:\n    model = QualityPredictor().to(device)\n    criterion = nn.MSELoss()\n    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=momentum)\n\n    for epoch in range(50):\n        model.train()\n        total_loss = 0\n        for batch in train_loader:\n            features = batch[\"features\"].to(device)\n            quality = batch[\"quality\"].to(device)\n            optimizer.zero_grad()\n            outputs = model(features)\n            loss = criterion(outputs.squeeze(), quality)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        avg_train_loss = total_loss / len(train_loader)\n        experiment_data[\"hyperparam_tuning_momentum\"][str(momentum)][\"losses\"][\n            \"train\"\n        ].append(avg_train_loss)\n\n        # Validation phase\n        model.eval()\n        val_loss = 0\n        total_quality = 0\n        total_processing_time = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                features = batch[\"features\"].to(device)\n                quality = batch[\"quality\"].to(device)\n                processing_time = batch[\"processing_time\"].to(device)\n                outputs = model(features)\n                val_loss += criterion(outputs.squeeze(), quality).item()\n                total_quality += outputs.sum().item()\n                total_processing_time += processing_time.sum().item()\n\n        avg_val_loss = val_loss / len(val_loader)\n        experiment_data[\"hyperparam_tuning_momentum\"][str(momentum)][\"losses\"][\n            \"val\"\n        ].append(avg_val_loss)\n        quality_speed_tradeoff = (\n            total_quality / total_processing_time\n        )  # Simplified metric\n        experiment_data[\"hyperparam_tuning_momentum\"][str(momentum)][\"metrics\"][\n            \"val\"\n        ].append(quality_speed_tradeoff)\n\n        print(\n            f\"Momentum {momentum}, Epoch {epoch+1}: train_loss = {avg_train_loss:.4f}, validation_loss = {avg_val_loss:.4f}, quality_speed_tradeoff = {quality_speed_tradeoff:.4f}\"\n        )\n\n# Saving experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n", "# Set random seed\nimport random\nimport numpy as np\nimport torch\n\nseed = 1\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset, random_split\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\n\n# Synthetic dataset generation\nclass QueryResponseDataset(Dataset):\n    def __init__(self, num_samples=1000):\n        self.features = np.random.rand(num_samples, 5)  # 5 features\n        self.quality = np.dot(\n            self.features, np.array([0.3, 0.2, 0.5, 0.1, 0.4])\n        ) + np.random.normal(0, 0.1, num_samples)\n        self.processing_time = (\n            np.random.rand(num_samples) * 0.5 + 0.5\n        )  # Simulated processing time between 0.5 and 1.0 seconds\n\n    def __len__(self):\n        return len(self.features)\n\n    def __getitem__(self, idx):\n        return {\n            \"features\": torch.tensor(self.features[idx], dtype=torch.float32),\n            \"quality\": torch.tensor(self.quality[idx], dtype=torch.float32),\n            \"processing_time\": torch.tensor(\n                self.processing_time[idx], dtype=torch.float32\n            ),\n        }\n\n\n# Model definition\nclass QualityPredictor(nn.Module):\n    def __init__(self):\n        super(QualityPredictor, self).__init__()\n        self.linear = nn.Linear(5, 1)\n\n    def forward(self, x):\n        return self.linear(x)\n\n\n# Training and evaluation\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\ndataset = QueryResponseDataset()\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\nmomentum_values = [0.0, 0.5, 0.9]  # Hyperparameter tuning for momentum\nexperiment_data = {\n    \"hyperparam_tuning_momentum\": {\n        str(momentum): {\n            \"metrics\": {\"train\": [], \"val\": []},\n            \"losses\": {\"train\": [], \"val\": []},\n            \"predictions\": [],\n            \"ground_truth\": [],\n        }\n        for momentum in momentum_values\n    }\n}\n\nfor momentum in momentum_values:\n    model = QualityPredictor().to(device)\n    criterion = nn.MSELoss()\n    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=momentum)\n\n    for epoch in range(50):\n        model.train()\n        total_loss = 0\n        for batch in train_loader:\n            features = batch[\"features\"].to(device)\n            quality = batch[\"quality\"].to(device)\n            optimizer.zero_grad()\n            outputs = model(features)\n            loss = criterion(outputs.squeeze(), quality)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        avg_train_loss = total_loss / len(train_loader)\n        experiment_data[\"hyperparam_tuning_momentum\"][str(momentum)][\"losses\"][\n            \"train\"\n        ].append(avg_train_loss)\n\n        # Validation phase\n        model.eval()\n        val_loss = 0\n        total_quality = 0\n        total_processing_time = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                features = batch[\"features\"].to(device)\n                quality = batch[\"quality\"].to(device)\n                processing_time = batch[\"processing_time\"].to(device)\n                outputs = model(features)\n                val_loss += criterion(outputs.squeeze(), quality).item()\n                total_quality += outputs.sum().item()\n                total_processing_time += processing_time.sum().item()\n\n        avg_val_loss = val_loss / len(val_loader)\n        experiment_data[\"hyperparam_tuning_momentum\"][str(momentum)][\"losses\"][\n            \"val\"\n        ].append(avg_val_loss)\n        quality_speed_tradeoff = (\n            total_quality / total_processing_time\n        )  # Simplified metric\n        experiment_data[\"hyperparam_tuning_momentum\"][str(momentum)][\"metrics\"][\n            \"val\"\n        ].append(quality_speed_tradeoff)\n\n        print(\n            f\"Momentum {momentum}, Epoch {epoch+1}: train_loss = {avg_train_loss:.4f}, validation_loss = {avg_val_loss:.4f}, quality_speed_tradeoff = {quality_speed_tradeoff:.4f}\"\n        )\n\n# Saving experiment data\nnp.save(os.path.join(working_dir, \"experiment_data.npy\"), experiment_data)\n"], "term_out": ["['Using device: cpu', '\\n', 'Epoch 1: train_loss = 0.0881, validation_loss =\n0.0683, quality_speed_tradeoff = 1.1763', '\\n', 'Epoch 2: train_loss = 0.0484,\nvalidation_loss = 0.0474, quality_speed_tradeoff = 1.0278', '\\n', 'Epoch 3:\ntrain_loss = 0.0344, validation_loss = 0.0332, quality_speed_tradeoff = 1.0663',\n'\\n', 'Epoch 4: train_loss = 0.0254, validation_loss = 0.0247,\nquality_speed_tradeoff = 1.0635', '\\n', 'Epoch 5: train_loss = 0.0200,\nvalidation_loss = 0.0195, quality_speed_tradeoff = 1.0427', '\\n', 'Epoch 6:\ntrain_loss = 0.0168, validation_loss = 0.0160, quality_speed_tradeoff = 1.0446',\n'\\n', 'Epoch 7: train_loss = 0.0146, validation_loss = 0.0135,\nquality_speed_tradeoff = 1.0622', '\\n', 'Epoch 8: train_loss = 0.0131,\nvalidation_loss = 0.0120, quality_speed_tradeoff = 1.0662', '\\n', 'Epoch 9:\ntrain_loss = 0.0122, validation_loss = 0.0110, quality_speed_tradeoff = 1.0703',\n'\\n', 'Epoch 10: train_loss = 0.0113, validation_loss = 0.0101,\nquality_speed_tradeoff = 1.0602', '\\n', 'Epoch 11: train_loss = 0.0107,\nvalidation_loss = 0.0098, quality_speed_tradeoff = 1.0778', '\\n', 'Epoch 12:\ntrain_loss = 0.0105, validation_loss = 0.0091, quality_speed_tradeoff = 1.0553',\n'\\n', 'Epoch 13: train_loss = 0.0101, validation_loss = 0.0088,\nquality_speed_tradeoff = 1.0538', '\\n', 'Epoch 14: train_loss = 0.0100,\nvalidation_loss = 0.0087, quality_speed_tradeoff = 1.0635', '\\n', 'Epoch 15:\ntrain_loss = 0.0098, validation_loss = 0.0086, quality_speed_tradeoff = 1.0622',\n'\\n', 'Epoch 16: train_loss = 0.0099, validation_loss = 0.0085,\nquality_speed_tradeoff = 1.0627', '\\n', 'Epoch 17: train_loss = 0.0098,\nvalidation_loss = 0.0084, quality_speed_tradeoff = 1.0613', '\\n', 'Epoch 18:\ntrain_loss = 0.0097, validation_loss = 0.0084, quality_speed_tradeoff = 1.0624',\n'\\n', 'Epoch 19: train_loss = 0.0098, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0443', '\\n', 'Epoch 20: train_loss = 0.0098,\nvalidation_loss = 0.0085, quality_speed_tradeoff = 1.0330', '\\n', 'Epoch 21:\ntrain_loss = 0.0098, validation_loss = 0.0082, quality_speed_tradeoff = 1.0526',\n'\\n', 'Epoch 22: train_loss = 0.0096, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0607', '\\n', 'Epoch 23: train_loss = 0.0098,\nvalidation_loss = 0.0082, quality_speed_tradeoff = 1.0467', '\\n', 'Epoch 24:\ntrain_loss = 0.0099, validation_loss = 0.0084, quality_speed_tradeoff = 1.0690',\n'\\n', 'Epoch 25: train_loss = 0.0098, validation_loss = 0.0087,\nquality_speed_tradeoff = 1.0792', '\\n', 'Epoch 26: train_loss = 0.0097,\nvalidation_loss = 0.0083, quality_speed_tradeoff = 1.0399', '\\n', 'Epoch 27:\ntrain_loss = 0.0098, validation_loss = 0.0082, quality_speed_tradeoff = 1.0432',\n'\\n', 'Epoch 28: train_loss = 0.0101, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0543', '\\n', 'Epoch 29: train_loss = 0.0097,\nvalidation_loss = 0.0082, quality_speed_tradeoff = 1.0482', '\\n', 'Epoch 30:\ntrain_loss = 0.0097, validation_loss = 0.0082, quality_speed_tradeoff = 1.0476',\n'\\n', 'Epoch 31: train_loss = 0.0098, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0654', '\\n', 'Epoch 32: train_loss = 0.0099,\nvalidation_loss = 0.0082, quality_speed_tradeoff = 1.0497', '\\n', 'Epoch 33:\ntrain_loss = 0.0097, validation_loss = 0.0086, quality_speed_tradeoff = 1.0781',\n'\\n', 'Epoch 34: train_loss = 0.0097, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0665', '\\n', 'Epoch 35: train_loss = 0.0097,\nvalidation_loss = 0.0085, quality_speed_tradeoff = 1.0713', '\\n', 'Epoch 36:\ntrain_loss = 0.0097, validation_loss = 0.0083, quality_speed_tradeoff = 1.0400',\n'\\n', 'Epoch 37: train_loss = 0.0100, validation_loss = 0.0084,\nquality_speed_tradeoff = 1.0686', '\\n', 'Epoch 38: train_loss = 0.0098,\nvalidation_loss = 0.0083, quality_speed_tradeoff = 1.0569', '\\n', 'Epoch 39:\ntrain_loss = 0.0097, validation_loss = 0.0082, quality_speed_tradeoff = 1.0441',\n'\\n', 'Epoch 40: train_loss = 0.0098, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0474', '\\n', 'Epoch 41: train_loss = 0.0097,\nvalidation_loss = 0.0086, quality_speed_tradeoff = 1.0775', '\\n', 'Epoch 42:\ntrain_loss = 0.0098, validation_loss = 0.0084, quality_speed_tradeoff = 1.0646',\n'\\n', 'Epoch 43: train_loss = 0.0097, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0581', '\\n', 'Epoch 44: train_loss = 0.0097,\nvalidation_loss = 0.0083, quality_speed_tradeoff = 1.0406', '\\n', 'Epoch 45:\ntrain_loss = 0.0100, validation_loss = 0.0082, quality_speed_tradeoff = 1.0577',\n'\\n', 'Epoch 46: train_loss = 0.0099, validation_loss = 0.0081,\nquality_speed_tradeoff = 1.0480', '\\n', 'Epoch 47: train_loss = 0.0097,\nvalidation_loss = 0.0082, quality_speed_tradeoff = 1.0589', '\\n', 'Epoch 48:\ntrain_loss = 0.0098, validation_loss = 0.0082, quality_speed_tradeoff = 1.0464',\n'\\n', 'Epoch 49: train_loss = 0.0097, validation_loss = 0.0088,\nquality_speed_tradeoff = 1.0833', '\\n', 'Epoch 50: train_loss = 0.0099,\nvalidation_loss = 0.0083, quality_speed_tradeoff = 1.0348', '\\n', 'Execution\ntime: 2 seconds seconds (time limit is an hour).']", "['Using device: cpu', '\\n', 'Learning Rate: 0.001, Epoch 1: train_loss = 0.1934,\nvalidation_loss = 0.1894, quality_speed_tradeoff = 0.6290', '\\n', 'Learning\nRate: 0.001, Epoch 2: train_loss = 0.1402, validation_loss = 0.1403,\nquality_speed_tradeoff = 0.7352', '\\n', 'Learning Rate: 0.001, Epoch 3:\ntrain_loss = 0.1046, validation_loss = 0.1092, quality_speed_tradeoff = 0.8235',\n'\\n', 'Learning Rate: 0.001, Epoch 4: train_loss = 0.0828, validation_loss =\n0.0907, quality_speed_tradeoff = 0.8933', '\\n', 'Learning Rate: 0.001, Epoch 5:\ntrain_loss = 0.0708, validation_loss = 0.0796, quality_speed_tradeoff = 0.9489',\n'\\n', 'Learning Rate: 0.001, Epoch 6: train_loss = 0.0640, validation_loss =\n0.0734, quality_speed_tradeoff = 0.9875', '\\n', 'Learning Rate: 0.001, Epoch 7:\ntrain_loss = 0.0602, validation_loss = 0.0700, quality_speed_tradeoff = 1.0102',\n'\\n', 'Learning Rate: 0.001, Epoch 8: train_loss = 0.0580, validation_loss =\n0.0673, quality_speed_tradeoff = 1.0277', '\\n', 'Learning Rate: 0.001, Epoch 9:\ntrain_loss = 0.0562, validation_loss = 0.0651, quality_speed_tradeoff = 1.0403',\n'\\n', 'Learning Rate: 0.001, Epoch 10: train_loss = 0.0547, validation_loss =\n0.0632, quality_speed_tradeoff = 1.0454', '\\n', 'Learning Rate: 0.001, Epoch 11:\ntrain_loss = 0.0532, validation_loss = 0.0614, quality_speed_tradeoff = 1.0462',\n'\\n', 'Learning Rate: 0.001, Epoch 12: train_loss = 0.0517, validation_loss =\n0.0597, quality_speed_tradeoff = 1.0470', '\\n', 'Learning Rate: 0.001, Epoch 13:\ntrain_loss = 0.0502, validation_loss = 0.0578, quality_speed_tradeoff = 1.0531',\n'\\n', 'Learning Rate: 0.001, Epoch 14: train_loss = 0.0488, validation_loss =\n0.0561, quality_speed_tradeoff = 1.0512', '\\n', 'Learning Rate: 0.001, Epoch 15:\ntrain_loss = 0.0473, validation_loss = 0.0544, quality_speed_tradeoff = 1.0518',\n'\\n', 'Learning Rate: 0.001, Epoch 16: train_loss = 0.0459, validation_loss =\n0.0527, quality_speed_tradeoff = 1.0517', '\\n', 'Learning Rate: 0.001, Epoch 17:\ntrain_loss = 0.0445, validation_loss = 0.0510, quality_speed_tradeoff = 1.0525',\n'\\n', 'Learning Rate: 0.001, Epoch 18: train_loss = 0.0432, validation_loss =\n0.0495, quality_speed_tradeoff = 1.0494', '\\n', 'Learning Rate: 0.001, Epoch 19:\ntrain_loss = 0.0418, validation_loss = 0.0479, quality_speed_tradeoff = 1.0537',\n'\\n', 'Learning Rate: 0.001, Epoch 20: train_loss = 0.0405, validation_loss =\n0.0463, quality_speed_tradeoff = 1.0518', '\\n', 'Learning Rate: 0.001, Epoch 21:\ntrain_loss = 0.0393, validation_loss = 0.0448, quality_speed_tradeoff = 1.0528',\n'\\n', 'Learning Rate: 0.001, Epoch 22: train_loss = 0.0380, validation_loss =\n0.0434, quality_speed_tradeoff = 1.0534', '\\n', 'Learning Rate: 0.001, Epoch 23:\ntrain_loss = 0.0368, validation_loss = 0.0419, quality_speed_tradeoff = 1.0533',\n'\\n', 'Learning Rate: 0.001, Epoch 24: train_loss = 0.0357, validation_loss =\n0.0406, quality_speed_tradeoff = 1.0526', '\\n', 'Learning Rate: 0.001, Epoch 25:\ntrain_loss = 0.0346, validation_loss = 0.0393, quality_speed_tradeoff = 1.0502',\n'\\n', 'Learning Rate: 0.001, Epoch 26: train_loss = 0.0335, validation_loss =\n0.0380, quality_speed_tradeoff = 1.0535', '\\n', 'Learning Rate: 0.001, Epoch 27:\ntrain_loss = 0.0324, validation_loss = 0.0368, quality_speed_tradeoff = 1.0529',\n'\\n', 'Learning Rate: 0.001, Epoch 28: train_loss = 0.0315, validation_loss =\n0.0356, quality_speed_tradeoff = 1.0513', '\\n', 'Learning Rate: 0.001, Epoch 29:\ntrain_loss = 0.0305, validation_loss = 0.0344, quality_speed_tradeoff = 1.0560',\n'\\n', 'Learning Rate: 0.001, Epoch 30: train_loss = 0.0296, validation_loss =\n0.0333, quality_speed_tradeoff = 1.0534', '\\n', 'Learning Rate: 0.001, Epoch 31:\ntrain_loss = 0.0287, validation_loss = 0.0323, quality_speed_tradeoff = 1.0518',\n'\\n', 'Learning Rate: 0.001, Epoch 32: train_loss = 0.0278, validation_loss =\n0.0312, quality_speed_tradeoff = 1.0549', '\\n', 'Learning Rate: 0.001, Epoch 33:\ntrain_loss = 0.0270, validation_loss = 0.0302, quality_speed_tradeoff = 1.0547',\n'\\n', 'Learning Rate: 0.001, Epoch 34: train_loss = 0.0263, validation_loss =\n0.0293, quality_speed_tradeoff = 1.0535', '\\n', 'Learning Rate: 0.001, Epoch 35:\ntrain_loss = 0.0255, validation_loss = 0.0284, quality_speed_tradeoff = 1.0545',\n'\\n', 'Learning Rate: 0.001, Epoch 36: train_loss = 0.0248, validation_loss =\n0.0275, quality_speed_tradeoff = 1.0558', '\\n', 'Learning Rate: 0.001, Epoch 37:\ntrain_loss = 0.0241, validation_loss = 0.0267, quality_speed_tradeoff = 1.0548',\n'\\n', 'Learning Rate: 0.001, Epoch 38: train_loss = 0.0235, validation_loss =\n0.0260, quality_speed_tradeoff = 1.0517', '\\n', 'Learning Rate: 0.001, Epoch 39:\ntrain_loss = 0.0229, validation_loss = 0.0251, quality_speed_tradeoff = 1.0563',\n'\\n', 'Learning Rate: 0.001, Epoch 40: train_loss = 0.0223, validation_loss =\n0.0245, quality_speed_tradeoff = 1.0537', '\\n', 'Learning Rate: 0.001, Epoch 41:\ntrain_loss = 0.0217, validation_loss = 0.0238, quality_speed_tradeoff = 1.0534',\n'\\n', 'Learning Rate: 0.001, Epoch 42: train_loss = 0.0212, validation_loss =\n0.0231, quality_speed_tradeoff = 1.0552', '\\n', 'Learning Rate: 0.001, Epoch 43:\ntrain_loss = 0.0207, validation_loss = 0.0224, quality_speed_tradeoff = 1.0555',\n'\\n', 'Learning Rate: 0.001, Epoch 44: train_loss = 0.0202, validation_loss =\n0.0219, quality_speed_tradeoff = 1.0551', '\\n', 'Learning Rate: 0.001, Epoch 45:\ntrain_loss = 0.0197, validation_loss = 0.0212, quality_speed_tradeoff = 1.0578',\n'\\n', 'Learning Rate: 0.001, Epoch 46: train_loss = 0.0193, validation_loss =\n0.0207, quality_speed_tradeoff = 1.0534', '\\n', 'Learning Rate: 0.001, Epoch 47:\ntrain_loss = 0.0188, validation_loss = 0.0202, quality_speed_tradeoff = 1.0542',\n'\\n', 'Learning Rate: 0.001, Epoch 48: train_loss = 0.0184, validation_loss =\n0.0197, quality_speed_tradeoff = 1.0555', '\\n', 'Learning Rate: 0.001, Epoch 49:\ntrain_loss = 0.0181, validation_loss = 0.0192, quality_speed_tradeoff = 1.0529',\n'\\n', 'Learning Rate: 0.001, Epoch 50: train_loss = 0.0177, validation_loss =\n0.0187, quality_speed_tradeoff = 1.0566', '\\n', 'Learning Rate: 0.01, Epoch 1:\ntrain_loss = 0.9038, validation_loss = 0.2618, quality_speed_tradeoff = 0.4270',\n'\\n', 'Learning Rate: 0.01, Epoch 2: train_loss = 0.1174, validation_loss =\n0.0383, quality_speed_tradeoff = 1.0475', '\\n', 'Learning Rate: 0.01, Epoch 3:\ntrain_loss = 0.0451, validation_loss = 0.0367, quality_speed_tradeoff = 1.1133',\n'\\n', 'Learning Rate: 0.01, Epoch 4: train_loss = 0.0392, validation_loss =\n0.0302, quality_speed_tradeoff = 1.0739', '\\n', 'Learning Rate: 0.01, Epoch 5:\ntrain_loss = 0.0340, validation_loss = 0.0258, quality_speed_tradeoff = 1.0546',\n'\\n', 'Learning Rate: 0.01, Epoch 6: train_loss = 0.0291, validation_loss =\n0.0224, quality_speed_tradeoff = 1.0709', '\\n', 'Learning Rate: 0.01, Epoch 7:\ntrain_loss = 0.0251, validation_loss = 0.0193, quality_speed_tradeoff = 1.0691',\n'\\n', 'Learning Rate: 0.01, Epoch 8: train_loss = 0.0216, validation_loss =\n0.0167, quality_speed_tradeoff = 1.0613', '\\n', 'Learning Rate: 0.01, Epoch 9:\ntrain_loss = 0.0188, validation_loss = 0.0147, quality_speed_tradeoff = 1.0611',\n'\\n', 'Learning Rate: 0.01, Epoch 10: train_loss = 0.0166, validation_loss =\n0.0131, quality_speed_tradeoff = 1.0651', '\\n', 'Learning Rate: 0.01, Epoch 11:\ntrain_loss = 0.0148, validation_loss = 0.0119, quality_speed_tradeoff = 1.0590',\n'\\n', 'Learning Rate: 0.01, Epoch 12: train_loss = 0.0135, validation_loss =\n0.0110, quality_speed_tradeoff = 1.0596', '\\n', 'Learning Rate: 0.01, Epoch 13:\ntrain_loss = 0.0125, validation_loss = 0.0103, quality_speed_tradeoff = 1.0555',\n'\\n', 'Learning Rate: 0.01, Epoch 14: train_loss = 0.0118, validation_loss =\n0.0098, quality_speed_tradeoff = 1.0585', '\\n', 'Learning Rate: 0.01, Epoch 15:\ntrain_loss = 0.0112, validation_loss = 0.0094, quality_speed_tradeoff = 1.0585',\n'\\n', 'Learning Rate: 0.01, Epoch 16: train_loss = 0.0108, validation_loss =\n0.0092, quality_speed_tradeoff = 1.0537', '\\n', 'Learning Rate: 0.01, Epoch 17:\ntrain_loss = 0.0106, validation_loss = 0.0090, quality_speed_tradeoff = 1.0564',\n'\\n', 'Learning Rate: 0.01, Epoch 18: train_loss = 0.0103, validation_loss =\n0.0089, quality_speed_tradeoff = 1.0593', '\\n', 'Learning Rate: 0.01, Epoch 19:\ntrain_loss = 0.0102, validation_loss = 0.0088, quality_speed_tradeoff = 1.0505',\n'\\n', 'Learning Rate: 0.01, Epoch 20: train_loss = 0.0101, validation_loss =\n0.0087, quality_speed_tradeoff = 1.0523', '\\n', 'Learning Rate: 0.01, Epoch 21:\ntrain_loss = 0.0100, validation_loss = 0.0086, quality_speed_tradeoff = 1.0554',\n'\\n', 'Learning Rate: 0.01, Epoch 22: train_loss = 0.0100, validation_loss =\n0.0086, quality_speed_tradeoff = 1.0539', '\\n', 'Learning Rate: 0.01, Epoch 23:\ntrain_loss = 0.0099, validation_loss = 0.0086, quality_speed_tradeoff = 1.0556',\n'\\n', 'Learning Rate: 0.01, Epoch 24: train_loss = 0.0098, validation_loss =\n0.0085, quality_speed_tradeoff = 1.0555', '\\n', 'Learning Rate: 0.01, Epoch 25:\ntrain_loss = 0.0098, validation_loss = 0.0085, quality_speed_tradeoff = 1.0488',\n'\\n', 'Learning Rate: 0.01, Epoch 26: train_loss = 0.0098, validation_loss =\n0.0085, quality_speed_tradeoff = 1.0550', '\\n', 'Learning Rate: 0.01, Epoch 27:\ntrain_loss = 0.0097, validation_loss = 0.0084, quality_speed_tradeoff = 1.0550',\n'\\n', 'Learning Rate: 0.01, Epoch 28: train_loss = 0.0098, validation_loss =\n0.0084, quality_speed_tradeoff = 1.0593', '\\n', 'Learning Rate: 0.01, Epoch 29:\ntrain_loss = 0.0098, validation_loss = 0.0084, quality_speed_tradeoff = 1.0487',\n'\\n', 'Learning Rate: 0.01, Epoch 30: train_loss = 0.0097, validation_loss =\n0.0084, quality_speed_tradeoff = 1.0450', '\\n', 'Learning Rate: 0.01, Epoch 31:\ntrain_loss = 0.0097, validation_loss = 0.0084, quality_speed_tradeoff = 1.0641',\n'\\n', 'Learning Rate: 0.01, Epoch 32: train_loss = 0.0097, validation_loss =\n0.0083, quality_speed_tradeoff = 1.0531', '\\n', 'Learning Rate: 0.01, Epoch 33:\ntrain_loss = 0.0097, validation_loss = 0.0084, quality_speed_tradeoff = 1.0611',\n'\\n', 'Learning Rate: 0.01, Epoch 34: train_loss = 0.0097, validation_loss =\n0.0083, quality_speed_tradeoff = 1.0535', '\\n', 'Learning Rate: 0.01, Epoch 35:\ntrain_loss = 0.0096, validation_loss = 0.0083, quality_speed_tradeoff = 1.0520',\n'\\n', 'Learning Rate: 0.01, Epoch 36: train_loss = 0.0097, validation_loss =\n0.0083, quality_speed_tradeoff = 1.0514', '\\n', 'Learning Rate: 0.01, Epoch 37:\ntrain_loss = 0.0097, validation_loss = 0.0083, quality_speed_tradeoff = 1.0466',\n'\\n', 'Learning Rate: 0.01, Epoch 38: train_loss = 0.0097, validation_loss =\n0.0083, quality_speed_tradeoff = 1.0437', '\\n', 'Learning Rate: 0.01, Epoch 39:\ntrain_loss = 0.0097, validation_loss = 0.0083, quality_speed_tradeoff = 1.0492',\n'\\n', 'Learning Rate: 0.01, Epoch 40: train_loss = 0.0097, validation_loss =\n0.0083, quality_speed_tradeoff = 1.0622', '\\n', 'Learning Rate: 0.01, Epoch 41:\ntrain_loss = 0.0096, validation_loss = 0.0083, quality_speed_tradeoff = 1.0450',\n'\\n', 'Learning Rate: 0.01, Epoch 42: train_loss = 0.0096, validation_loss =\n0.0082, quality_speed_tradeoff = 1.0574', '\\n', 'Learning Rate: 0.01, Epoch 43:\ntrain_loss = 0.0096, validation_loss = 0.0083, quality_speed_tradeoff = 1.0448',\n'\\n', 'Learning Rate: 0.01, Epoch 44: train_loss = 0.0096, validation_loss =\n0.0083, quality_speed_tradeoff = 1.0565', '\\n', 'Learning Rate: 0.01, Epoch 45:\ntrain_loss = 0.0097, validation_loss = 0.0083, quality_speed_tradeoff = 1.0421',\n'\\n', 'Learning Rate: 0.01, Epoch 46: train_loss = 0.0097, validation_loss =\n0.0082, quality_speed_tradeoff = 1.0486', '\\n', 'Learning Rate: 0.01, Epoch 47:\ntrain_loss = 0.0096, validation_loss = 0.0082, quality_speed_tradeoff = 1.0428',\n'\\n', 'Learning Rate: 0.01, Epoch 48: train_loss = 0.0097, validation_loss =\n0.0082, quality_speed_tradeoff = 1.0585', '\\n', 'Learning Rate: 0.01, Epoch 49:\ntrain_loss = 0.0097, validation_loss = 0.0083, quality_speed_tradeoff = 1.0621',\n'\\n', 'Learning Rate: 0.01, Epoch 50: train_loss = 0.0097, validation_loss =\n0.0083, quality_speed_tradeoff = 1.0357', '\\n', 'Learning Rate: 0.1, Epoch 1:\ntrain_loss = 0.1360, validation_loss = 0.0347, quality_speed_tradeoff = 1.2604',\n'\\n', 'Learning Rate: 0.1, Epoch 2: train_loss = 0.0163, validation_loss =\n0.0132, quality_speed_tradeoff = 0.9640', '\\n', 'Learning Rate: 0.1, Epoch 3:\ntrain_loss = 0.0109, validation_loss = 0.0085, quality_speed_tradeoff = 1.0625',\n'\\n', 'Learning Rate: 0.1, Epoch 4: train_loss = 0.0099, validation_loss =\n0.0082, quality_speed_tradeoff = 1.0384', '\\n', 'Learning Rate: 0.1, Epoch 5:\ntrain_loss = 0.0099, validation_loss = 0.0083, quality_speed_tradeoff = 1.0667',\n'\\n', 'Learning Rate: 0.1, Epoch 6: train_loss = 0.0100, validation_loss =\n0.0099, quality_speed_tradeoff = 1.1044', '\\n', 'Learning Rate: 0.1, Epoch 7:\ntrain_loss = 0.0101, validation_loss = 0.0091, quality_speed_tradeoff = 1.0111',\n'\\n', 'Learning Rate: 0.1, Epoch 8: train_loss = 0.0101, validation_loss =\n0.0083, quality_speed_tradeoff = 1.0344', '\\n', 'Learning Rate: 0.1, Epoch 9:\ntrain_loss = 0.0099, validation_loss = 0.0083, quality_speed_tradeoff = 1.0339',\n'\\n', 'Learning Rate: 0.1, Epoch 10: train_loss = 0.0098, validation_loss =\n0.0084, quality_speed_tradeoff = 1.0326', '\\n', 'Learning Rate: 0.1, Epoch 11:\ntrain_loss = 0.0103, validation_loss = 0.0109, quality_speed_tradeoff = 1.1190',\n'\\n', 'Learning Rate: 0.1, Epoch 12: train_loss = 0.0104, validation_loss =\n0.0082, quality_speed_tradeoff = 1.0476', '\\n', 'Learning Rate: 0.1, Epoch 13:\ntrain_loss = 0.0111, validation_loss = 0.0092, quality_speed_tradeoff = 1.0913',\n'\\n', 'Learning Rate: 0.1, Epoch 14: train_loss = 0.0106, validation_loss =\n0.0095, quality_speed_tradeoff = 1.0023', '\\n', 'Learning Rate: 0.1, Epoch 15:\ntrain_loss = 0.0100, validation_loss = 0.0081, quality_speed_tradeoff = 1.0502',\n'\\n', 'Learning Rate: 0.1, Epoch 16: train_loss = 0.0100, validation_loss =\n0.0087, quality_speed_tradeoff = 1.0777', '\\n', 'Learning Rate: 0.1, Epoch 17:\ntrain_loss = 0.0099, validation_loss = 0.0083, quality_speed_tradeoff = 1.0449',\n'\\n', 'Learning Rate: 0.1, Epoch 18: train_loss = 0.0104, validation_loss =\n0.0083, quality_speed_tradeoff = 1.0361', '\\n', 'Learning Rate: 0.1, Epoch 19:\ntrain_loss = 0.0101, validation_loss = 0.0089, quality_speed_tradeoff = 1.0801',\n'\\n', 'Learning Rate: 0.1, Epoch 20: train_loss = 0.0106, validation_loss =\n0.0089, quality_speed_tradeoff = 1.0844', '\\n', 'Learning Rate: 0.1, Epoch 21:\ntrain_loss = 0.0108, validation_loss = 0.0082, quality_speed_tradeoff = 1.0595',\n'\\n', 'Learning Rate: 0.1, Epoch 22: train_loss = 0.0105, validation_loss =\n0.0091, quality_speed_tradeoff = 1.0108', '\\n', 'Learning Rate: 0.1, Epoch 23:\ntrain_loss = 0.0110, validation_loss = 0.0096, quality_speed_tradeoff = 1.0004',\n'\\n', 'Learning Rate: 0.1, Epoch 24: train_loss = 0.0105, validation_loss =\n0.0084, quality_speed_tradeoff = 1.0309', '\\n', 'Learning Rate: 0.1, Epoch 25:\ntrain_loss = 0.0102, validation_loss = 0.0084, quality_speed_tradeoff = 1.0585',\n'\\n', 'Learning Rate: 0.1, Epoch 26: train_loss = 0.0104, validation_loss =\n0.0096, quality_speed_tradeoff = 1.0016', '\\n', 'Learning Rate: 0.1, Epoch 27:\ntrain_loss = 0.0104, validation_loss = 0.0086, quality_speed_tradeoff = 1.0596',\n'\\n', 'Learning Rate: 0.1, Epoch 28: train_loss = 0.0132, validation_loss =\n0.0095, quality_speed_tradeoff = 1.0038', '\\n', 'Learning Rate: 0.1, Epoch 29:\ntrain_loss = 0.0103, validation_loss = 0.0104, quality_speed_tradeoff = 1.1115',\n'\\n', 'Learning Rate: 0.1, Epoch 30: train_loss = 0.0108, validation_loss =\n0.0104, quality_speed_tradeoff = 1.1081', '\\n', 'Learning Rate: 0.1, Epoch 31:\ntrain_loss = 0.0120, validation_loss = 0.0127, quality_speed_tradeoff = 0.9677',\n'\\n', 'Learning Rate: 0.1, Epoch 32: train_loss = 0.0125, validation_loss =\n0.0094, quality_speed_tradeoff = 1.0012', '\\n', 'Learning Rate: 0.1, Epoch 33:\ntrain_loss = 0.0112, validation_loss = 0.0113, quality_speed_tradeoff = 1.1110',\n'\\n', 'Learning Rate: 0.1, Epoch 34: train_loss = 0.0112, validation_loss =\n0.0090, quality_speed_tradeoff = 1.0161', '\\n', 'Learning Rate: 0.1, Epoch 35:\ntrain_loss = 0.0103, validation_loss = 0.0082, quality_speed_tradeoff = 1.0576',\n'\\n', 'Learning Rate: 0.1, Epoch 36: train_loss = 0.0103, validation_loss =\n0.0086, quality_speed_tradeoff = 1.0287', '\\n', 'Learning Rate: 0.1, Epoch 37:\ntrain_loss = 0.0106, validation_loss = 0.0081, quality_speed_tradeoff = 1.0469',\n'\\n', 'Learning Rate: 0.1, Epoch 38: train_loss = 0.0106, validation_loss =\n0.0089, quality_speed_tradeoff = 1.0329', '\\n', 'Learning Rate: 0.1, Epoch 39:\ntrain_loss = 0.0103, validation_loss = 0.0095, quality_speed_tradeoff = 1.0997',\n'\\n', 'Learning Rate: 0.1, Epoch 40: train_loss = 0.0106, validation_loss =\n0.0104, quality_speed_tradeoff = 1.1032', '\\n', 'Learning Rate: 0.1, Epoch 41:\ntrain_loss = 0.0113, validation_loss = 0.0095, quality_speed_tradeoff = 1.0976',\n'\\n', 'Learning Rate: 0.1, Epoch 42: train_loss = 0.0111, validation_loss =\n0.0085, quality_speed_tradeoff = 1.0427', '\\n', 'Learning Rate: 0.1, Epoch 43:\ntrain_loss = 0.0102, validation_loss = 0.0099, quality_speed_tradeoff = 0.9964',\n'\\n', 'Learning Rate: 0.1, Epoch 44: train_loss = 0.0109, validation_loss =\n0.0084, quality_speed_tradeoff = 1.0559', '\\n', 'Learning Rate: 0.1, Epoch 45:\ntrain_loss = 0.0120, validation_loss = 0.0092, quality_speed_tradeoff = 1.0875',\n'\\n', 'Learning Rate: 0.1, Epoch 46: train_loss = 0.0102, validation_loss =\n0.0108, quality_speed_tradeoff = 0.9882', '\\n', 'Learning Rate: 0.1, Epoch 47:\ntrain_loss = 0.0117, validation_loss = 0.0082, quality_speed_tradeoff = 1.0367',\n'\\n', 'Learning Rate: 0.1, Epoch 48: train_loss = 0.0126, validation_loss =\n0.0116, quality_speed_tradeoff = 1.1236', '\\n', 'Learning Rate: 0.1, Epoch 49:\ntrain_loss = 0.0119, validation_loss = 0.0101, quality_speed_tradeoff = 0.9961',\n'\\n', 'Learning Rate: 0.1, Epoch 50: train_loss = 0.0138, validation_loss =\n0.0115, quality_speed_tradeoff = 1.1238', '\\n', 'Execution time: 3 seconds\nseconds (time limit is an hour).']", "['Using device: cpu', '\\n', 'Batch size 16, Epoch 1: train_loss = 0.0680,\nvalidation_loss = 0.0449, quality_speed_tradeoff = 1.0536', '\\n', 'Batch size\n16, Epoch 2: train_loss = 0.0309, validation_loss = 0.0255,\nquality_speed_tradeoff = 1.0195', '\\n', 'Batch size 16, Epoch 3: train_loss =\n0.0191, validation_loss = 0.0156, quality_speed_tradeoff = 1.0679', '\\n', 'Batch\nsize 16, Epoch 4: train_loss = 0.0145, validation_loss = 0.0122,\nquality_speed_tradeoff = 1.0864', '\\n', 'Batch size 16, Epoch 5: train_loss =\n0.0121, validation_loss = 0.0099, quality_speed_tradeoff = 1.0429', '\\n', 'Batch\nsize 16, Epoch 6: train_loss = 0.0109, validation_loss = 0.0090,\nquality_speed_tradeoff = 1.0379', '\\n', 'Batch size 16, Epoch 7: train_loss =\n0.0104, validation_loss = 0.0084, quality_speed_tradeoff = 1.0646', '\\n', 'Batch\nsize 16, Epoch 8: train_loss = 0.0103, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0289', '\\n', 'Batch size 16, Epoch 9: train_loss =\n0.0100, validation_loss = 0.0082, quality_speed_tradeoff = 1.0227', '\\n', 'Batch\nsize 16, Epoch 10: train_loss = 0.0099, validation_loss = 0.0079,\nquality_speed_tradeoff = 1.0355', '\\n', 'Batch size 16, Epoch 11: train_loss =\n0.0100, validation_loss = 0.0079, quality_speed_tradeoff = 1.0602', '\\n', 'Batch\nsize 16, Epoch 12: train_loss = 0.0100, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0750', '\\n', 'Batch size 16, Epoch 13: train_loss =\n0.0098, validation_loss = 0.0080, quality_speed_tradeoff = 1.0657', '\\n', 'Batch\nsize 16, Epoch 14: train_loss = 0.0098, validation_loss = 0.0078,\nquality_speed_tradeoff = 1.0528', '\\n', 'Batch size 16, Epoch 15: train_loss =\n0.0098, validation_loss = 0.0078, quality_speed_tradeoff = 1.0475', '\\n', 'Batch\nsize 16, Epoch 16: train_loss = 0.0102, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0730', '\\n', 'Batch size 16, Epoch 17: train_loss =\n0.0098, validation_loss = 0.0079, quality_speed_tradeoff = 1.0308', '\\n', 'Batch\nsize 16, Epoch 18: train_loss = 0.0101, validation_loss = 0.0080,\nquality_speed_tradeoff = 1.0254', '\\n', 'Batch size 16, Epoch 19: train_loss =\n0.0100, validation_loss = 0.0078, quality_speed_tradeoff = 1.0405', '\\n', 'Batch\nsize 16, Epoch 20: train_loss = 0.0098, validation_loss = 0.0078,\nquality_speed_tradeoff = 1.0494', '\\n', 'Batch size 16, Epoch 21: train_loss =\n0.0098, validation_loss = 0.0080, quality_speed_tradeoff = 1.0656', '\\n', 'Batch\nsize 16, Epoch 22: train_loss = 0.0100, validation_loss = 0.0077,\nquality_speed_tradeoff = 1.0449', '\\n', 'Batch size 16, Epoch 23: train_loss =\n0.0098, validation_loss = 0.0080, quality_speed_tradeoff = 1.0661', '\\n', 'Batch\nsize 16, Epoch 24: train_loss = 0.0099, validation_loss = 0.0080,\nquality_speed_tradeoff = 1.0626', '\\n', 'Batch size 16, Epoch 25: train_loss =\n0.0100, validation_loss = 0.0083, quality_speed_tradeoff = 1.0766', '\\n', 'Batch\nsize 16, Epoch 26: train_loss = 0.0105, validation_loss = 0.0081,\nquality_speed_tradeoff = 1.0196', '\\n', 'Batch size 16, Epoch 27: train_loss =\n0.0103, validation_loss = 0.0081, quality_speed_tradeoff = 1.0721', '\\n', 'Batch\nsize 16, Epoch 28: train_loss = 0.0100, validation_loss = 0.0089,\nquality_speed_tradeoff = 1.0896', '\\n', 'Batch size 16, Epoch 29: train_loss =\n0.0100, validation_loss = 0.0079, quality_speed_tradeoff = 1.0293', '\\n', 'Batch\nsize 16, Epoch 30: train_loss = 0.0101, validation_loss = 0.0079,\nquality_speed_tradeoff = 1.0635', '\\n', 'Batch size 16, Epoch 31: train_loss =\n0.0098, validation_loss = 0.0078, quality_speed_tradeoff = 1.0551', '\\n', 'Batch\nsize 16, Epoch 32: train_loss = 0.0099, validation_loss = 0.0079,\nquality_speed_tradeoff = 1.0528', '\\n', 'Batch size 16, Epoch 33: train_loss =\n0.0099, validation_loss = 0.0081, quality_speed_tradeoff = 1.0684', '\\n', 'Batch\nsize 16, Epoch 34: train_loss = 0.0101, validation_loss = 0.0079,\nquality_speed_tradeoff = 1.0508', '\\n', 'Batch size 16, Epoch 35: train_loss =\n0.0101, validation_loss = 0.0079, quality_speed_tradeoff = 1.0560', '\\n', 'Batch\nsize 16, Epoch 36: train_loss = 0.0099, validation_loss = 0.0080,\nquality_speed_tradeoff = 1.0253', '\\n', 'Batch size 16, Epoch 37: train_loss =\n0.0101, validation_loss = 0.0080, quality_speed_tradeoff = 1.0537', '\\n', 'Batch\nsize 16, Epoch 38: train_loss = 0.0103, validation_loss = 0.0079,\nquality_speed_tradeoff = 1.0597', '\\n', 'Batch size 16, Epoch 39: train_loss =\n0.0100, validation_loss = 0.0079, quality_speed_tradeoff = 1.0616', '\\n', 'Batch\nsize 16, Epoch 40: train_loss = 0.0098, validation_loss = 0.0079,\nquality_speed_tradeoff = 1.0593', '\\n', 'Batch size 16, Epoch 41: train_loss =\n0.0099, validation_loss = 0.0080, quality_speed_tradeoff = 1.0618', '\\n', 'Batch\nsize 16, Epoch 42: train_loss = 0.0102, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0696', '\\n', 'Batch size 16, Epoch 43: train_loss =\n0.0102, validation_loss = 0.0079, quality_speed_tradeoff = 1.0606', '\\n', 'Batch\nsize 16, Epoch 44: train_loss = 0.0102, validation_loss = 0.0080,\nquality_speed_tradeoff = 1.0631', '\\n', 'Batch size 16, Epoch 45: train_loss =\n0.0100, validation_loss = 0.0089, quality_speed_tradeoff = 1.0009', '\\n', 'Batch\nsize 16, Epoch 46: train_loss = 0.0102, validation_loss = 0.0079,\nquality_speed_tradeoff = 1.0630', '\\n', 'Batch size 16, Epoch 47: train_loss =\n0.0100, validation_loss = 0.0084, quality_speed_tradeoff = 1.0766', '\\n', 'Batch\nsize 16, Epoch 48: train_loss = 0.0101, validation_loss = 0.0078,\nquality_speed_tradeoff = 1.0383', '\\n', 'Batch size 16, Epoch 49: train_loss =\n0.0097, validation_loss = 0.0078, quality_speed_tradeoff = 1.0524', '\\n', 'Batch\nsize 16, Epoch 50: train_loss = 0.0102, validation_loss = 0.0094,\nquality_speed_tradeoff = 1.0976', '\\n', 'Batch size 32, Epoch 1: train_loss =\n0.9038, validation_loss = 0.2618, quality_speed_tradeoff = 0.4270', '\\n', 'Batch\nsize 32, Epoch 2: train_loss = 0.1174, validation_loss = 0.0383,\nquality_speed_tradeoff = 1.0475', '\\n', 'Batch size 32, Epoch 3: train_loss =\n0.0451, validation_loss = 0.0367, quality_speed_tradeoff = 1.1133', '\\n', 'Batch\nsize 32, Epoch 4: train_loss = 0.0392, validation_loss = 0.0302,\nquality_speed_tradeoff = 1.0739', '\\n', 'Batch size 32, Epoch 5: train_loss =\n0.0340, validation_loss = 0.0258, quality_speed_tradeoff = 1.0546', '\\n', 'Batch\nsize 32, Epoch 6: train_loss = 0.0291, validation_loss = 0.0224,\nquality_speed_tradeoff = 1.0709', '\\n', 'Batch size 32, Epoch 7: train_loss =\n0.0251, validation_loss = 0.0193, quality_speed_tradeoff = 1.0691', '\\n', 'Batch\nsize 32, Epoch 8: train_loss = 0.0216, validation_loss = 0.0167,\nquality_speed_tradeoff = 1.0613', '\\n', 'Batch size 32, Epoch 9: train_loss =\n0.0188, validation_loss = 0.0147, quality_speed_tradeoff = 1.0611', '\\n', 'Batch\nsize 32, Epoch 10: train_loss = 0.0166, validation_loss = 0.0131,\nquality_speed_tradeoff = 1.0651', '\\n', 'Batch size 32, Epoch 11: train_loss =\n0.0148, validation_loss = 0.0119, quality_speed_tradeoff = 1.0590', '\\n', 'Batch\nsize 32, Epoch 12: train_loss = 0.0135, validation_loss = 0.0110,\nquality_speed_tradeoff = 1.0596', '\\n', 'Batch size 32, Epoch 13: train_loss =\n0.0125, validation_loss = 0.0103, quality_speed_tradeoff = 1.0555', '\\n', 'Batch\nsize 32, Epoch 14: train_loss = 0.0118, validation_loss = 0.0098,\nquality_speed_tradeoff = 1.0585', '\\n', 'Batch size 32, Epoch 15: train_loss =\n0.0112, validation_loss = 0.0094, quality_speed_tradeoff = 1.0585', '\\n', 'Batch\nsize 32, Epoch 16: train_loss = 0.0108, validation_loss = 0.0092,\nquality_speed_tradeoff = 1.0537', '\\n', 'Batch size 32, Epoch 17: train_loss =\n0.0106, validation_loss = 0.0090, quality_speed_tradeoff = 1.0564', '\\n', 'Batch\nsize 32, Epoch 18: train_loss = 0.0103, validation_loss = 0.0089,\nquality_speed_tradeoff = 1.0593', '\\n', 'Batch size 32, Epoch 19: train_loss =\n0.0102, validation_loss = 0.0088, quality_speed_tradeoff = 1.0505', '\\n', 'Batch\nsize 32, Epoch 20: train_loss = 0.0101, validation_loss = 0.0087,\nquality_speed_tradeoff = 1.0523', '\\n', 'Batch size 32, Epoch 21: train_loss =\n0.0100, validation_loss = 0.0086, quality_speed_tradeoff = 1.0554', '\\n', 'Batch\nsize 32, Epoch 22: train_loss = 0.0100, validation_loss = 0.0086,\nquality_speed_tradeoff = 1.0539', '\\n', 'Batch size 32, Epoch 23: train_loss =\n0.0099, validation_loss = 0.0086, quality_speed_tradeoff = 1.0556', '\\n', 'Batch\nsize 32, Epoch 24: train_loss = 0.0098, validation_loss = 0.0085,\nquality_speed_tradeoff = 1.0555', '\\n', 'Batch size 32, Epoch 25: train_loss =\n0.0098, validation_loss = 0.0085, quality_speed_tradeoff = 1.0488', '\\n', 'Batch\nsize 32, Epoch 26: train_loss = 0.0098, validation_loss = 0.0085,\nquality_speed_tradeoff = 1.0550', '\\n', 'Batch size 32, Epoch 27: train_loss =\n0.0097, validation_loss = 0.0084, quality_speed_tradeoff = 1.0550', '\\n', 'Batch\nsize 32, Epoch 28: train_loss = 0.0098, validation_loss = 0.0084,\nquality_speed_tradeoff = 1.0593', '\\n', 'Batch size 32, Epoch 29: train_loss =\n0.0098, validation_loss = 0.0084, quality_speed_tradeoff = 1.0487', '\\n', 'Batch\nsize 32, Epoch 30: train_loss = 0.0097, validation_loss = 0.0084,\nquality_speed_tradeoff = 1.0450', '\\n', 'Batch size 32, Epoch 31: train_loss =\n0.0097, validation_loss = 0.0084, quality_speed_tradeoff = 1.0641', '\\n', 'Batch\nsize 32, Epoch 32: train_loss = 0.0097, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0531', '\\n', 'Batch size 32, Epoch 33: train_loss =\n0.0097, validation_loss = 0.0084, quality_speed_tradeoff = 1.0611', '\\n', 'Batch\nsize 32, Epoch 34: train_loss = 0.0097, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0535', '\\n', 'Batch size 32, Epoch 35: train_loss =\n0.0096, validation_loss = 0.0083, quality_speed_tradeoff = 1.0520', '\\n', 'Batch\nsize 32, Epoch 36: train_loss = 0.0097, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0514', '\\n', 'Batch size 32, Epoch 37: train_loss =\n0.0097, validation_loss = 0.0083, quality_speed_tradeoff = 1.0466', '\\n', 'Batch\nsize 32, Epoch 38: train_loss = 0.0097, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0437', '\\n', 'Batch size 32, Epoch 39: train_loss =\n0.0097, validation_loss = 0.0083, quality_speed_tradeoff = 1.0492', '\\n', 'Batch\nsize 32, Epoch 40: train_loss = 0.0097, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0622', '\\n', 'Batch size 32, Epoch 41: train_loss =\n0.0096, validation_loss = 0.0083, quality_speed_tradeoff = 1.0450', '\\n', 'Batch\nsize 32, Epoch 42: train_loss = 0.0096, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0574', '\\n', 'Batch size 32, Epoch 43: train_loss =\n0.0096, validation_loss = 0.0083, quality_speed_tradeoff = 1.0448', '\\n', 'Batch\nsize 32, Epoch 44: train_loss = 0.0096, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0565', '\\n', 'Batch size 32, Epoch 45: train_loss =\n0.0097, validation_loss = 0.0083, quality_speed_tradeoff = 1.0421', '\\n', 'Batch\nsize 32, Epoch 46: train_loss = 0.0097, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0486', '\\n', 'Batch size 32, Epoch 47: train_loss =\n0.0096, validation_loss = 0.0082, quality_speed_tradeoff = 1.0428', '\\n', 'Batch\nsize 32, Epoch 48: train_loss = 0.0097, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0585', '\\n', 'Batch size 32, Epoch 49: train_loss =\n0.0097, validation_loss = 0.0083, quality_speed_tradeoff = 1.0621', '\\n', 'Batch\nsize 32, Epoch 50: train_loss = 0.0097, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0357', '\\n', 'Batch size 64, Epoch 1: train_loss =\n0.6307, validation_loss = 0.3675, quality_speed_tradeoff = 0.3159', '\\n', 'Batch\nsize 64, Epoch 2: train_loss = 0.1656, validation_loss = 0.0760,\nquality_speed_tradeoff = 0.8109', '\\n', 'Batch size 64, Epoch 3: train_loss =\n0.0413, validation_loss = 0.0349, quality_speed_tradeoff = 1.0722', '\\n', 'Batch\nsize 64, Epoch 4: train_loss = 0.0372, validation_loss = 0.0333,\nquality_speed_tradeoff = 1.1101', '\\n', 'Batch size 64, Epoch 5: train_loss =\n0.0334, validation_loss = 0.0299, quality_speed_tradeoff = 1.0574', '\\n', 'Batch\nsize 64, Epoch 6: train_loss = 0.0295, validation_loss = 0.0291,\nquality_speed_tradeoff = 1.0129', '\\n', 'Batch size 64, Epoch 7: train_loss =\n0.0265, validation_loss = 0.0264, quality_speed_tradeoff = 1.0152', '\\n', 'Batch\nsize 64, Epoch 8: train_loss = 0.0245, validation_loss = 0.0235,\nquality_speed_tradeoff = 1.0257', '\\n', 'Batch size 64, Epoch 9: train_loss =\n0.0229, validation_loss = 0.0212, quality_speed_tradeoff = 1.0298', '\\n', 'Batch\nsize 64, Epoch 10: train_loss = 0.0209, validation_loss = 0.0191,\nquality_speed_tradeoff = 1.0332', '\\n', 'Batch size 64, Epoch 11: train_loss =\n0.0190, validation_loss = 0.0174, quality_speed_tradeoff = 1.0335', '\\n', 'Batch\nsize 64, Epoch 12: train_loss = 0.0177, validation_loss = 0.0157,\nquality_speed_tradeoff = 1.0404', '\\n', 'Batch size 64, Epoch 13: train_loss =\n0.0164, validation_loss = 0.0146, quality_speed_tradeoff = 1.0347', '\\n', 'Batch\nsize 64, Epoch 14: train_loss = 0.0152, validation_loss = 0.0135,\nquality_speed_tradeoff = 1.0372', '\\n', 'Batch size 64, Epoch 15: train_loss =\n0.0142, validation_loss = 0.0124, quality_speed_tradeoff = 1.0420', '\\n', 'Batch\nsize 64, Epoch 16: train_loss = 0.0134, validation_loss = 0.0116,\nquality_speed_tradeoff = 1.0426', '\\n', 'Batch size 64, Epoch 17: train_loss =\n0.0128, validation_loss = 0.0110, quality_speed_tradeoff = 1.0450', '\\n', 'Batch\nsize 64, Epoch 18: train_loss = 0.0121, validation_loss = 0.0105,\nquality_speed_tradeoff = 1.0430', '\\n', 'Batch size 64, Epoch 19: train_loss =\n0.0117, validation_loss = 0.0101, quality_speed_tradeoff = 1.0445', '\\n', 'Batch\nsize 64, Epoch 20: train_loss = 0.0112, validation_loss = 0.0098,\nquality_speed_tradeoff = 1.0478', '\\n', 'Batch size 64, Epoch 21: train_loss =\n0.0108, validation_loss = 0.0096, quality_speed_tradeoff = 1.0460', '\\n', 'Batch\nsize 64, Epoch 22: train_loss = 0.0107, validation_loss = 0.0093,\nquality_speed_tradeoff = 1.0513', '\\n', 'Batch size 64, Epoch 23: train_loss =\n0.0104, validation_loss = 0.0092, quality_speed_tradeoff = 1.0471', '\\n', 'Batch\nsize 64, Epoch 24: train_loss = 0.0102, validation_loss = 0.0092,\nquality_speed_tradeoff = 1.0456', '\\n', 'Batch size 64, Epoch 25: train_loss =\n0.0102, validation_loss = 0.0091, quality_speed_tradeoff = 1.0489', '\\n', 'Batch\nsize 64, Epoch 26: train_loss = 0.0101, validation_loss = 0.0089,\nquality_speed_tradeoff = 1.0563', '\\n', 'Batch size 64, Epoch 27: train_loss =\n0.0100, validation_loss = 0.0091, quality_speed_tradeoff = 1.0458', '\\n', 'Batch\nsize 64, Epoch 28: train_loss = 0.0099, validation_loss = 0.0090,\nquality_speed_tradeoff = 1.0500', '\\n', 'Batch size 64, Epoch 29: train_loss =\n0.0099, validation_loss = 0.0090, quality_speed_tradeoff = 1.0509', '\\n', 'Batch\nsize 64, Epoch 30: train_loss = 0.0098, validation_loss = 0.0089,\nquality_speed_tradeoff = 1.0528', '\\n', 'Batch size 64, Epoch 31: train_loss =\n0.0097, validation_loss = 0.0090, quality_speed_tradeoff = 1.0514', '\\n', 'Batch\nsize 64, Epoch 32: train_loss = 0.0096, validation_loss = 0.0090,\nquality_speed_tradeoff = 1.0481', '\\n', 'Batch size 64, Epoch 33: train_loss =\n0.0097, validation_loss = 0.0090, quality_speed_tradeoff = 1.0520', '\\n', 'Batch\nsize 64, Epoch 34: train_loss = 0.0098, validation_loss = 0.0089,\nquality_speed_tradeoff = 1.0553', '\\n', 'Batch size 64, Epoch 35: train_loss =\n0.0096, validation_loss = 0.0090, quality_speed_tradeoff = 1.0484', '\\n', 'Batch\nsize 64, Epoch 36: train_loss = 0.0096, validation_loss = 0.0089,\nquality_speed_tradeoff = 1.0546', '\\n', 'Batch size 64, Epoch 37: train_loss =\n0.0096, validation_loss = 0.0090, quality_speed_tradeoff = 1.0540', '\\n', 'Batch\nsize 64, Epoch 38: train_loss = 0.0098, validation_loss = 0.0090,\nquality_speed_tradeoff = 1.0535', '\\n', 'Batch size 64, Epoch 39: train_loss =\n0.0096, validation_loss = 0.0090, quality_speed_tradeoff = 1.0490', '\\n', 'Batch\nsize 64, Epoch 40: train_loss = 0.0097, validation_loss = 0.0089,\nquality_speed_tradeoff = 1.0562', '\\n', 'Batch size 64, Epoch 41: train_loss =\n0.0097, validation_loss = 0.0090, quality_speed_tradeoff = 1.0502', '\\n', 'Batch\nsize 64, Epoch 42: train_loss = 0.0098, validation_loss = 0.0089,\nquality_speed_tradeoff = 1.0558', '\\n', 'Batch size 64, Epoch 43: train_loss =\n0.0095, validation_loss = 0.0089, quality_speed_tradeoff = 1.0524', '\\n', 'Batch\nsize 64, Epoch 44: train_loss = 0.0098, validation_loss = 0.0090,\nquality_speed_tradeoff = 1.0488', '\\n', 'Batch size 64, Epoch 45: train_loss =\n0.0096, validation_loss = 0.0089, quality_speed_tradeoff = 1.0556', '\\n', 'Batch\nsize 64, Epoch 46: train_loss = 0.0096, validation_loss = 0.0089,\nquality_speed_tradeoff = 1.0529', '\\n', 'Batch size 64, Epoch 47: train_loss =\n0.0096, validation_loss = 0.0089, quality_speed_tradeoff = 1.0544', '\\n', 'Batch\nsize 64, Epoch 48: train_loss = 0.0097, validation_loss = 0.0089,\nquality_speed_tradeoff = 1.0508', '\\n', 'Batch size 64, Epoch 49: train_loss =\n0.0097, validation_loss = 0.0090, quality_speed_tradeoff = 1.0476', '\\n', 'Batch\nsize 64, Epoch 50: train_loss = 0.0097, validation_loss = 0.0089,\nquality_speed_tradeoff = 1.0586', '\\n', 'Execution time: 3 seconds seconds (time\nlimit is an hour).']", "['Using device: cpu', '\\n', 'Training for 10 epochs...', '\\n', 'Epoch 1:\ntrain_loss = 0.0881, validation_loss = 0.0683, quality_speed_tradeoff = 1.1763',\n'\\n', 'Epoch 2: train_loss = 0.0484, validation_loss = 0.0474,\nquality_speed_tradeoff = 1.0278', '\\n', 'Epoch 3: train_loss = 0.0344,\nvalidation_loss = 0.0332, quality_speed_tradeoff = 1.0663', '\\n', 'Epoch 4:\ntrain_loss = 0.0254, validation_loss = 0.0247, quality_speed_tradeoff = 1.0635',\n'\\n', 'Epoch 5: train_loss = 0.0200, validation_loss = 0.0195,\nquality_speed_tradeoff = 1.0427', '\\n', 'Epoch 6: train_loss = 0.0168,\nvalidation_loss = 0.0160, quality_speed_tradeoff = 1.0446', '\\n', 'Epoch 7:\ntrain_loss = 0.0146, validation_loss = 0.0135, quality_speed_tradeoff = 1.0622',\n'\\n', 'Epoch 8: train_loss = 0.0131, validation_loss = 0.0120,\nquality_speed_tradeoff = 1.0662', '\\n', 'Epoch 9: train_loss = 0.0122,\nvalidation_loss = 0.0110, quality_speed_tradeoff = 1.0703', '\\n', 'Epoch 10:\ntrain_loss = 0.0113, validation_loss = 0.0101, quality_speed_tradeoff = 1.0602',\n'\\n', 'Training for 20 epochs...', '\\n', 'Epoch 1: train_loss = 0.0107,\nvalidation_loss = 0.0098, quality_speed_tradeoff = 1.0778', '\\n', 'Epoch 2:\ntrain_loss = 0.0105, validation_loss = 0.0091, quality_speed_tradeoff = 1.0553',\n'\\n', 'Epoch 3: train_loss = 0.0101, validation_loss = 0.0088,\nquality_speed_tradeoff = 1.0538', '\\n', 'Epoch 4: train_loss = 0.0100,\nvalidation_loss = 0.0087, quality_speed_tradeoff = 1.0635', '\\n', 'Epoch 5:\ntrain_loss = 0.0098, validation_loss = 0.0086, quality_speed_tradeoff = 1.0622',\n'\\n', 'Epoch 6: train_loss = 0.0099, validation_loss = 0.0085,\nquality_speed_tradeoff = 1.0627', '\\n', 'Epoch 7: train_loss = 0.0098,\nvalidation_loss = 0.0084, quality_speed_tradeoff = 1.0613', '\\n', 'Epoch 8:\ntrain_loss = 0.0097, validation_loss = 0.0084, quality_speed_tradeoff = 1.0624',\n'\\n', 'Epoch 9: train_loss = 0.0098, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0443', '\\n', 'Epoch 10: train_loss = 0.0098,\nvalidation_loss = 0.0085, quality_speed_tradeoff = 1.0330', '\\n', 'Epoch 11:\ntrain_loss = 0.0098, validation_loss = 0.0082, quality_speed_tradeoff = 1.0526',\n'\\n', 'Epoch 12: train_loss = 0.0096, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0607', '\\n', 'Epoch 13: train_loss = 0.0098,\nvalidation_loss = 0.0082, quality_speed_tradeoff = 1.0467', '\\n', 'Epoch 14:\ntrain_loss = 0.0099, validation_loss = 0.0084, quality_speed_tradeoff = 1.0690',\n'\\n', 'Epoch 15: train_loss = 0.0098, validation_loss = 0.0087,\nquality_speed_tradeoff = 1.0792', '\\n', 'Epoch 16: train_loss = 0.0097,\nvalidation_loss = 0.0083, quality_speed_tradeoff = 1.0399', '\\n', 'Epoch 17:\ntrain_loss = 0.0098, validation_loss = 0.0082, quality_speed_tradeoff = 1.0432',\n'\\n', 'Epoch 18: train_loss = 0.0101, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0543', '\\n', 'Epoch 19: train_loss = 0.0097,\nvalidation_loss = 0.0082, quality_speed_tradeoff = 1.0482', '\\n', 'Epoch 20:\ntrain_loss = 0.0097, validation_loss = 0.0082, quality_speed_tradeoff = 1.0476',\n'\\n', 'Training for 30 epochs...', '\\n', 'Epoch 1: train_loss = 0.0098,\nvalidation_loss = 0.0083, quality_speed_tradeoff = 1.0654', '\\n', 'Epoch 2:\ntrain_loss = 0.0099, validation_loss = 0.0082, quality_speed_tradeoff = 1.0497',\n'\\n', 'Epoch 3: train_loss = 0.0097, validation_loss = 0.0086,\nquality_speed_tradeoff = 1.0781', '\\n', 'Epoch 4: train_loss = 0.0097,\nvalidation_loss = 0.0083, quality_speed_tradeoff = 1.0665', '\\n', 'Epoch 5:\ntrain_loss = 0.0097, validation_loss = 0.0085, quality_speed_tradeoff = 1.0713',\n'\\n', 'Epoch 6: train_loss = 0.0097, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0400', '\\n', 'Epoch 7: train_loss = 0.0100,\nvalidation_loss = 0.0084, quality_speed_tradeoff = 1.0686', '\\n', 'Epoch 8:\ntrain_loss = 0.0098, validation_loss = 0.0083, quality_speed_tradeoff = 1.0569',\n'\\n', 'Epoch 9: train_loss = 0.0097, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0441', '\\n', 'Epoch 10: train_loss = 0.0098,\nvalidation_loss = 0.0082, quality_speed_tradeoff = 1.0474', '\\n', 'Epoch 11:\ntrain_loss = 0.0097, validation_loss = 0.0086, quality_speed_tradeoff = 1.0775',\n'\\n', 'Epoch 12: train_loss = 0.0098, validation_loss = 0.0084,\nquality_speed_tradeoff = 1.0646', '\\n', 'Epoch 13: train_loss = 0.0097,\nvalidation_loss = 0.0082, quality_speed_tradeoff = 1.0581', '\\n', 'Epoch 14:\ntrain_loss = 0.0097, validation_loss = 0.0083, quality_speed_tradeoff = 1.0406',\n'\\n', 'Epoch 15: train_loss = 0.0100, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0577', '\\n', 'Epoch 16: train_loss = 0.0099,\nvalidation_loss = 0.0081, quality_speed_tradeoff = 1.0480', '\\n', 'Epoch 17:\ntrain_loss = 0.0097, validation_loss = 0.0082, quality_speed_tradeoff = 1.0589',\n'\\n', 'Epoch 18: train_loss = 0.0098, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0464', '\\n', 'Epoch 19: train_loss = 0.0097,\nvalidation_loss = 0.0088, quality_speed_tradeoff = 1.0833', '\\n', 'Epoch 20:\ntrain_loss = 0.0099, validation_loss = 0.0083, quality_speed_tradeoff = 1.0348',\n'\\n', 'Epoch 21: train_loss = 0.0097, validation_loss = 0.0085,\nquality_speed_tradeoff = 1.0284', '\\n', 'Epoch 22: train_loss = 0.0098,\nvalidation_loss = 0.0082, quality_speed_tradeoff = 1.0577', '\\n', 'Epoch 23:\ntrain_loss = 0.0097, validation_loss = 0.0082, quality_speed_tradeoff = 1.0462',\n'\\n', 'Epoch 24: train_loss = 0.0099, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0530', '\\n', 'Epoch 25: train_loss = 0.0098,\nvalidation_loss = 0.0082, quality_speed_tradeoff = 1.0446', '\\n', 'Epoch 26:\ntrain_loss = 0.0103, validation_loss = 0.0090, quality_speed_tradeoff = 1.0874',\n'\\n', 'Epoch 27: train_loss = 0.0103, validation_loss = 0.0084,\nquality_speed_tradeoff = 1.0329', '\\n', 'Epoch 28: train_loss = 0.0098,\nvalidation_loss = 0.0082, quality_speed_tradeoff = 1.0544', '\\n', 'Epoch 29:\ntrain_loss = 0.0097, validation_loss = 0.0082, quality_speed_tradeoff = 1.0425',\n'\\n', 'Epoch 30: train_loss = 0.0097, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0672', '\\n', 'Training for 40 epochs...', '\\n',\n'Epoch 1: train_loss = 0.0099, validation_loss = 0.0083, quality_speed_tradeoff\n= 1.0504', '\\n', 'Epoch 2: train_loss = 0.0097, validation_loss = 0.0088,\nquality_speed_tradeoff = 1.0161', '\\n', 'Epoch 3: train_loss = 0.0100,\nvalidation_loss = 0.0082, quality_speed_tradeoff = 1.0553', '\\n', 'Epoch 4:\ntrain_loss = 0.0098, validation_loss = 0.0084, quality_speed_tradeoff = 1.0648',\n'\\n', 'Epoch 5: train_loss = 0.0098, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0608', '\\n', 'Epoch 6: train_loss = 0.0099,\nvalidation_loss = 0.0082, quality_speed_tradeoff = 1.0549', '\\n', 'Epoch 7:\ntrain_loss = 0.0098, validation_loss = 0.0085, quality_speed_tradeoff = 1.0267',\n'\\n', 'Epoch 8: train_loss = 0.0098, validation_loss = 0.0086,\nquality_speed_tradeoff = 1.0745', '\\n', 'Epoch 9: train_loss = 0.0098,\nvalidation_loss = 0.0088, quality_speed_tradeoff = 1.0181', '\\n', 'Epoch 10:\ntrain_loss = 0.0103, validation_loss = 0.0086, quality_speed_tradeoff = 1.0733',\n'\\n', 'Epoch 11: train_loss = 0.0101, validation_loss = 0.0084,\nquality_speed_tradeoff = 1.0710', '\\n', 'Epoch 12: train_loss = 0.0097,\nvalidation_loss = 0.0084, quality_speed_tradeoff = 1.0707', '\\n', 'Epoch 13:\ntrain_loss = 0.0101, validation_loss = 0.0088, quality_speed_tradeoff = 1.0159',\n'\\n', 'Epoch 14: train_loss = 0.0097, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0427', '\\n', 'Epoch 15: train_loss = 0.0098,\nvalidation_loss = 0.0082, quality_speed_tradeoff = 1.0578', '\\n', 'Epoch 16:\ntrain_loss = 0.0098, validation_loss = 0.0084, quality_speed_tradeoff = 1.0323',\n'\\n', 'Epoch 17: train_loss = 0.0098, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0540', '\\n', 'Epoch 18: train_loss = 0.0098,\nvalidation_loss = 0.0083, quality_speed_tradeoff = 1.0344', '\\n', 'Epoch 19:\ntrain_loss = 0.0098, validation_loss = 0.0086, quality_speed_tradeoff = 1.0779',\n'\\n', 'Epoch 20: train_loss = 0.0097, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0560', '\\n', 'Epoch 21: train_loss = 0.0097,\nvalidation_loss = 0.0081, quality_speed_tradeoff = 1.0495', '\\n', 'Epoch 22:\ntrain_loss = 0.0097, validation_loss = 0.0083, quality_speed_tradeoff = 1.0628',\n'\\n', 'Epoch 23: train_loss = 0.0098, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0494', '\\n', 'Epoch 24: train_loss = 0.0100,\nvalidation_loss = 0.0085, quality_speed_tradeoff = 1.0761', '\\n', 'Epoch 25:\ntrain_loss = 0.0100, validation_loss = 0.0088, quality_speed_tradeoff = 1.0184',\n'\\n', 'Epoch 26: train_loss = 0.0098, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0577', '\\n', 'Epoch 27: train_loss = 0.0099,\nvalidation_loss = 0.0082, quality_speed_tradeoff = 1.0531', '\\n', 'Epoch 28:\ntrain_loss = 0.0100, validation_loss = 0.0084, quality_speed_tradeoff = 1.0613',\n'\\n', 'Epoch 29: train_loss = 0.0098, validation_loss = 0.0081,\nquality_speed_tradeoff = 1.0474', '\\n', 'Epoch 30: train_loss = 0.0097,\nvalidation_loss = 0.0082, quality_speed_tradeoff = 1.0431', '\\n', 'Epoch 31:\ntrain_loss = 0.0098, validation_loss = 0.0082, quality_speed_tradeoff = 1.0432',\n'\\n', 'Epoch 32: train_loss = 0.0097, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0614', '\\n', 'Epoch 33: train_loss = 0.0099,\nvalidation_loss = 0.0084, quality_speed_tradeoff = 1.0292', '\\n', 'Epoch 34:\ntrain_loss = 0.0099, validation_loss = 0.0085, quality_speed_tradeoff = 1.0705',\n'\\n', 'Epoch 35: train_loss = 0.0097, validation_loss = 0.0084,\nquality_speed_tradeoff = 1.0721', '\\n', 'Epoch 36: train_loss = 0.0097,\nvalidation_loss = 0.0088, quality_speed_tradeoff = 1.0825', '\\n', 'Epoch 37:\ntrain_loss = 0.0098, validation_loss = 0.0087, quality_speed_tradeoff = 1.0817',\n'\\n', 'Epoch 38: train_loss = 0.0100, validation_loss = 0.0095,\nquality_speed_tradeoff = 1.0022', '\\n', 'Epoch 39: train_loss = 0.0101,\nvalidation_loss = 0.0082, quality_speed_tradeoff = 1.0459', '\\n', 'Epoch 40:\ntrain_loss = 0.0098, validation_loss = 0.0082, quality_speed_tradeoff = 1.0456',\n'\\n', 'Training for 50 epochs...', '\\n', 'Epoch 1: train_loss = 0.0099,\nvalidation_loss = 0.0081, quality_speed_tradeoff = 1.0477', '\\n', 'Epoch 2:\ntrain_loss = 0.0099, validation_loss = 0.0082, quality_speed_tradeoff = 1.0439',\n'\\n', 'Epoch 3: train_loss = 0.0097, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0520', '\\n', 'Epoch 4: train_loss = 0.0098,\nvalidation_loss = 0.0085, quality_speed_tradeoff = 1.0298', '\\n', 'Epoch 5:\ntrain_loss = 0.0098, validation_loss = 0.0083, quality_speed_tradeoff = 1.0599',\n'\\n', 'Epoch 6: train_loss = 0.0097, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0344', '\\n', 'Epoch 7: train_loss = 0.0099,\nvalidation_loss = 0.0083, quality_speed_tradeoff = 1.0655', '\\n', 'Epoch 8:\ntrain_loss = 0.0098, validation_loss = 0.0088, quality_speed_tradeoff = 1.0821',\n'\\n', 'Epoch 9: train_loss = 0.0099, validation_loss = 0.0085,\nquality_speed_tradeoff = 1.0287', '\\n', 'Epoch 10: train_loss = 0.0099,\nvalidation_loss = 0.0083, quality_speed_tradeoff = 1.0648', '\\n', 'Epoch 11:\ntrain_loss = 0.0098, validation_loss = 0.0084, quality_speed_tradeoff = 1.0707',\n'\\n', 'Epoch 12: train_loss = 0.0097, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0608', '\\n', 'Epoch 13: train_loss = 0.0100,\nvalidation_loss = 0.0082, quality_speed_tradeoff = 1.0516', '\\n', 'Epoch 14:\ntrain_loss = 0.0097, validation_loss = 0.0086, quality_speed_tradeoff = 1.0773',\n'\\n', 'Epoch 15: train_loss = 0.0098, validation_loss = 0.0084,\nquality_speed_tradeoff = 1.0734', '\\n', 'Epoch 16: train_loss = 0.0099,\nvalidation_loss = 0.0083, quality_speed_tradeoff = 1.0594', '\\n', 'Epoch 17:\ntrain_loss = 0.0098, validation_loss = 0.0083, quality_speed_tradeoff = 1.0659',\n'\\n', 'Epoch 18: train_loss = 0.0097, validation_loss = 0.0086,\nquality_speed_tradeoff = 1.0757', '\\n', 'Epoch 19: train_loss = 0.0098,\nvalidation_loss = 0.0082, quality_speed_tradeoff = 1.0501', '\\n', 'Epoch 20:\ntrain_loss = 0.0098, validation_loss = 0.0082, quality_speed_tradeoff = 1.0550',\n'\\n', 'Epoch 21: train_loss = 0.0098, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0701', '\\n', 'Epoch 22: train_loss = 0.0099,\nvalidation_loss = 0.0089, quality_speed_tradeoff = 1.0165', '\\n', 'Epoch 23:\ntrain_loss = 0.0098, validation_loss = 0.0085, quality_speed_tradeoff = 1.0723',\n'\\n', 'Epoch 24: train_loss = 0.0097, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0609', '\\n', 'Epoch 25: train_loss = 0.0097,\nvalidation_loss = 0.0083, quality_speed_tradeoff = 1.0361', '\\n', 'Epoch 26:\ntrain_loss = 0.0105, validation_loss = 0.0082, quality_speed_tradeoff = 1.0501',\n'\\n', 'Epoch 27: train_loss = 0.0104, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0591', '\\n', 'Epoch 28: train_loss = 0.0098,\nvalidation_loss = 0.0084, quality_speed_tradeoff = 1.0669', '\\n', 'Epoch 29:\ntrain_loss = 0.0099, validation_loss = 0.0087, quality_speed_tradeoff = 1.0815',\n'\\n', 'Epoch 30: train_loss = 0.0098, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0534', '\\n', 'Epoch 31: train_loss = 0.0098,\nvalidation_loss = 0.0086, quality_speed_tradeoff = 1.0742', '\\n', 'Epoch 32:\ntrain_loss = 0.0102, validation_loss = 0.0087, quality_speed_tradeoff = 1.0200',\n'\\n', 'Epoch 33: train_loss = 0.0098, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0433', '\\n', 'Epoch 34: train_loss = 0.0097,\nvalidation_loss = 0.0089, quality_speed_tradeoff = 1.0862', '\\n', 'Epoch 35:\ntrain_loss = 0.0104, validation_loss = 0.0082, quality_speed_tradeoff = 1.0377',\n'\\n', 'Epoch 36: train_loss = 0.0100, validation_loss = 0.0086,\nquality_speed_tradeoff = 1.0219', '\\n', 'Epoch 37: train_loss = 0.0099,\nvalidation_loss = 0.0094, quality_speed_tradeoff = 1.0945', '\\n', 'Epoch 38:\ntrain_loss = 0.0099, validation_loss = 0.0082, quality_speed_tradeoff = 1.0579',\n'\\n', 'Epoch 39: train_loss = 0.0100, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0366', '\\n', 'Epoch 40: train_loss = 0.0097,\nvalidation_loss = 0.0082, quality_speed_tradeoff = 1.0512', '\\n', 'Epoch 41:\ntrain_loss = 0.0097, validation_loss = 0.0083, quality_speed_tradeoff = 1.0470',\n'\\n', 'Epoch 42: train_loss = 0.0099, validation_loss = 0.0090,\nquality_speed_tradeoff = 1.0128', '\\n', 'Epoch 43: train_loss = 0.0103,\nvalidation_loss = 0.0092, quality_speed_tradeoff = 1.0911', '\\n', 'Epoch 44:\ntrain_loss = 0.0101, validation_loss = 0.0091, quality_speed_tradeoff = 1.0085',\n'\\n', 'Epoch 45: train_loss = 0.0101, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0604', '\\n', 'Epoch 46: train_loss = 0.0099,\nvalidation_loss = 0.0085, quality_speed_tradeoff = 1.0705', '\\n', 'Epoch 47:\ntrain_loss = 0.0098, validation_loss = 0.0082, quality_speed_tradeoff = 1.0449',\n'\\n', 'Epoch 48: train_loss = 0.0098, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0392', '\\n', 'Epoch 49: train_loss = 0.0099,\nvalidation_loss = 0.0084, quality_speed_tradeoff = 1.0363', '\\n', 'Epoch 50:\ntrain_loss = 0.0098, validation_loss = 0.0082, quality_speed_tradeoff = 1.0430',\n'\\n', 'Execution time: 3 seconds seconds (time limit is an hour).']", "['Using device: cpu', '\\n', 'Weight Decay 0.0: Epoch 1: train_loss = 0.0881,\nvalidation_loss = 0.0683, quality_speed_tradeoff = 1.1763', '\\n', 'Weight Decay\n0.0: Epoch 2: train_loss = 0.0484, validation_loss = 0.0474,\nquality_speed_tradeoff = 1.0278', '\\n', 'Weight Decay 0.0: Epoch 3: train_loss =\n0.0344, validation_loss = 0.0332, quality_speed_tradeoff = 1.0663', '\\n',\n'Weight Decay 0.0: Epoch 4: train_loss = 0.0254, validation_loss = 0.0247,\nquality_speed_tradeoff = 1.0635', '\\n', 'Weight Decay 0.0: Epoch 5: train_loss =\n0.0200, validation_loss = 0.0195, quality_speed_tradeoff = 1.0427', '\\n',\n'Weight Decay 0.0: Epoch 6: train_loss = 0.0168, validation_loss = 0.0160,\nquality_speed_tradeoff = 1.0446', '\\n', 'Weight Decay 0.0: Epoch 7: train_loss =\n0.0146, validation_loss = 0.0135, quality_speed_tradeoff = 1.0622', '\\n',\n'Weight Decay 0.0: Epoch 8: train_loss = 0.0131, validation_loss = 0.0120,\nquality_speed_tradeoff = 1.0662', '\\n', 'Weight Decay 0.0: Epoch 9: train_loss =\n0.0122, validation_loss = 0.0110, quality_speed_tradeoff = 1.0703', '\\n',\n'Weight Decay 0.0: Epoch 10: train_loss = 0.0113, validation_loss = 0.0101,\nquality_speed_tradeoff = 1.0602', '\\n', 'Weight Decay 0.0: Epoch 11: train_loss\n= 0.0107, validation_loss = 0.0098, quality_speed_tradeoff = 1.0778', '\\n',\n'Weight Decay 0.0: Epoch 12: train_loss = 0.0105, validation_loss = 0.0091,\nquality_speed_tradeoff = 1.0553', '\\n', 'Weight Decay 0.0: Epoch 13: train_loss\n= 0.0101, validation_loss = 0.0088, quality_speed_tradeoff = 1.0538', '\\n',\n'Weight Decay 0.0: Epoch 14: train_loss = 0.0100, validation_loss = 0.0087,\nquality_speed_tradeoff = 1.0635', '\\n', 'Weight Decay 0.0: Epoch 15: train_loss\n= 0.0098, validation_loss = 0.0086, quality_speed_tradeoff = 1.0622', '\\n',\n'Weight Decay 0.0: Epoch 16: train_loss = 0.0099, validation_loss = 0.0085,\nquality_speed_tradeoff = 1.0627', '\\n', 'Weight Decay 0.0: Epoch 17: train_loss\n= 0.0098, validation_loss = 0.0084, quality_speed_tradeoff = 1.0613', '\\n',\n'Weight Decay 0.0: Epoch 18: train_loss = 0.0097, validation_loss = 0.0084,\nquality_speed_tradeoff = 1.0624', '\\n', 'Weight Decay 0.0: Epoch 19: train_loss\n= 0.0098, validation_loss = 0.0083, quality_speed_tradeoff = 1.0443', '\\n',\n'Weight Decay 0.0: Epoch 20: train_loss = 0.0098, validation_loss = 0.0085,\nquality_speed_tradeoff = 1.0330', '\\n', 'Weight Decay 0.0: Epoch 21: train_loss\n= 0.0098, validation_loss = 0.0082, quality_speed_tradeoff = 1.0526', '\\n',\n'Weight Decay 0.0: Epoch 22: train_loss = 0.0096, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0607', '\\n', 'Weight Decay 0.0: Epoch 23: train_loss\n= 0.0098, validation_loss = 0.0082, quality_speed_tradeoff = 1.0467', '\\n',\n'Weight Decay 0.0: Epoch 24: train_loss = 0.0099, validation_loss = 0.0084,\nquality_speed_tradeoff = 1.0690', '\\n', 'Weight Decay 0.0: Epoch 25: train_loss\n= 0.0098, validation_loss = 0.0087, quality_speed_tradeoff = 1.0792', '\\n',\n'Weight Decay 0.0: Epoch 26: train_loss = 0.0097, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0399', '\\n', 'Weight Decay 0.0: Epoch 27: train_loss\n= 0.0098, validation_loss = 0.0082, quality_speed_tradeoff = 1.0432', '\\n',\n'Weight Decay 0.0: Epoch 28: train_loss = 0.0101, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0543', '\\n', 'Weight Decay 0.0: Epoch 29: train_loss\n= 0.0097, validation_loss = 0.0082, quality_speed_tradeoff = 1.0482', '\\n',\n'Weight Decay 0.0: Epoch 30: train_loss = 0.0097, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0476', '\\n', 'Weight Decay 0.0: Epoch 31: train_loss\n= 0.0098, validation_loss = 0.0083, quality_speed_tradeoff = 1.0654', '\\n',\n'Weight Decay 0.0: Epoch 32: train_loss = 0.0099, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0497', '\\n', 'Weight Decay 0.0: Epoch 33: train_loss\n= 0.0097, validation_loss = 0.0086, quality_speed_tradeoff = 1.0781', '\\n',\n'Weight Decay 0.0: Epoch 34: train_loss = 0.0097, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0665', '\\n', 'Weight Decay 0.0: Epoch 35: train_loss\n= 0.0097, validation_loss = 0.0085, quality_speed_tradeoff = 1.0713', '\\n',\n'Weight Decay 0.0: Epoch 36: train_loss = 0.0097, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0400', '\\n', 'Weight Decay 0.0: Epoch 37: train_loss\n= 0.0100, validation_loss = 0.0084, quality_speed_tradeoff = 1.0686', '\\n',\n'Weight Decay 0.0: Epoch 38: train_loss = 0.0098, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0569', '\\n', 'Weight Decay 0.0: Epoch 39: train_loss\n= 0.0097, validation_loss = 0.0082, quality_speed_tradeoff = 1.0441', '\\n',\n'Weight Decay 0.0: Epoch 40: train_loss = 0.0098, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0474', '\\n', 'Weight Decay 0.0: Epoch 41: train_loss\n= 0.0097, validation_loss = 0.0086, quality_speed_tradeoff = 1.0775', '\\n',\n'Weight Decay 0.0: Epoch 42: train_loss = 0.0098, validation_loss = 0.0084,\nquality_speed_tradeoff = 1.0646', '\\n', 'Weight Decay 0.0: Epoch 43: train_loss\n= 0.0097, validation_loss = 0.0082, quality_speed_tradeoff = 1.0581', '\\n',\n'Weight Decay 0.0: Epoch 44: train_loss = 0.0097, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0406', '\\n', 'Weight Decay 0.0: Epoch 45: train_loss\n= 0.0100, validation_loss = 0.0082, quality_speed_tradeoff = 1.0577', '\\n',\n'Weight Decay 0.0: Epoch 46: train_loss = 0.0099, validation_loss = 0.0081,\nquality_speed_tradeoff = 1.0480', '\\n', 'Weight Decay 0.0: Epoch 47: train_loss\n= 0.0097, validation_loss = 0.0082, quality_speed_tradeoff = 1.0589', '\\n',\n'Weight Decay 0.0: Epoch 48: train_loss = 0.0098, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0464', '\\n', 'Weight Decay 0.0: Epoch 49: train_loss\n= 0.0097, validation_loss = 0.0088, quality_speed_tradeoff = 1.0833', '\\n',\n'Weight Decay 0.0: Epoch 50: train_loss = 0.0099, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0348', '\\n', 'Weight Decay 0.01: Epoch 1: train_loss\n= 0.9038, validation_loss = 0.2619, quality_speed_tradeoff = 0.4268', '\\n',\n'Weight Decay 0.01: Epoch 2: train_loss = 0.1175, validation_loss = 0.0382,\nquality_speed_tradeoff = 1.0458', '\\n', 'Weight Decay 0.01: Epoch 3: train_loss\n= 0.0447, validation_loss = 0.0360, quality_speed_tradeoff = 1.1100', '\\n',\n'Weight Decay 0.01: Epoch 4: train_loss = 0.0386, validation_loss = 0.0296,\nquality_speed_tradeoff = 1.0703', '\\n', 'Weight Decay 0.01: Epoch 5: train_loss\n= 0.0334, validation_loss = 0.0251, quality_speed_tradeoff = 1.0513', '\\n',\n'Weight Decay 0.01: Epoch 6: train_loss = 0.0284, validation_loss = 0.0217,\nquality_speed_tradeoff = 1.0674', '\\n', 'Weight Decay 0.01: Epoch 7: train_loss\n= 0.0243, validation_loss = 0.0186, quality_speed_tradeoff = 1.0654', '\\n',\n'Weight Decay 0.01: Epoch 8: train_loss = 0.0208, validation_loss = 0.0161,\nquality_speed_tradeoff = 1.0577', '\\n', 'Weight Decay 0.01: Epoch 9: train_loss\n= 0.0182, validation_loss = 0.0142, quality_speed_tradeoff = 1.0575', '\\n',\n'Weight Decay 0.01: Epoch 10: train_loss = 0.0160, validation_loss = 0.0127,\nquality_speed_tradeoff = 1.0613', '\\n', 'Weight Decay 0.01: Epoch 11: train_loss\n= 0.0144, validation_loss = 0.0116, quality_speed_tradeoff = 1.0554', '\\n',\n'Weight Decay 0.01: Epoch 12: train_loss = 0.0132, validation_loss = 0.0108,\nquality_speed_tradeoff = 1.0559', '\\n', 'Weight Decay 0.01: Epoch 13: train_loss\n= 0.0123, validation_loss = 0.0102, quality_speed_tradeoff = 1.0521', '\\n',\n'Weight Decay 0.01: Epoch 14: train_loss = 0.0117, validation_loss = 0.0098,\nquality_speed_tradeoff = 1.0547', '\\n', 'Weight Decay 0.01: Epoch 15: train_loss\n= 0.0112, validation_loss = 0.0095, quality_speed_tradeoff = 1.0549', '\\n',\n'Weight Decay 0.01: Epoch 16: train_loss = 0.0109, validation_loss = 0.0093,\nquality_speed_tradeoff = 1.0498', '\\n', 'Weight Decay 0.01: Epoch 17: train_loss\n= 0.0107, validation_loss = 0.0092, quality_speed_tradeoff = 1.0531', '\\n',\n'Weight Decay 0.01: Epoch 18: train_loss = 0.0104, validation_loss = 0.0091,\nquality_speed_tradeoff = 1.0557', '\\n', 'Weight Decay 0.01: Epoch 19: train_loss\n= 0.0104, validation_loss = 0.0090, quality_speed_tradeoff = 1.0472', '\\n',\n'Weight Decay 0.01: Epoch 20: train_loss = 0.0103, validation_loss = 0.0090,\nquality_speed_tradeoff = 1.0486', '\\n', 'Weight Decay 0.01: Epoch 21: train_loss\n= 0.0102, validation_loss = 0.0089, quality_speed_tradeoff = 1.0521', '\\n',\n'Weight Decay 0.01: Epoch 22: train_loss = 0.0101, validation_loss = 0.0089,\nquality_speed_tradeoff = 1.0505', '\\n', 'Weight Decay 0.01: Epoch 23: train_loss\n= 0.0101, validation_loss = 0.0089, quality_speed_tradeoff = 1.0522', '\\n',\n'Weight Decay 0.01: Epoch 24: train_loss = 0.0101, validation_loss = 0.0088,\nquality_speed_tradeoff = 1.0524', '\\n', 'Weight Decay 0.01: Epoch 25: train_loss\n= 0.0100, validation_loss = 0.0089, quality_speed_tradeoff = 1.0457', '\\n',\n'Weight Decay 0.01: Epoch 26: train_loss = 0.0100, validation_loss = 0.0088,\nquality_speed_tradeoff = 1.0519', '\\n', 'Weight Decay 0.01: Epoch 27: train_loss\n= 0.0099, validation_loss = 0.0088, quality_speed_tradeoff = 1.0514', '\\n',\n'Weight Decay 0.01: Epoch 28: train_loss = 0.0100, validation_loss = 0.0088,\nquality_speed_tradeoff = 1.0566', '\\n', 'Weight Decay 0.01: Epoch 29: train_loss\n= 0.0100, validation_loss = 0.0088, quality_speed_tradeoff = 1.0452', '\\n',\n'Weight Decay 0.01: Epoch 30: train_loss = 0.0099, validation_loss = 0.0088,\nquality_speed_tradeoff = 1.0415', '\\n', 'Weight Decay 0.01: Epoch 31: train_loss\n= 0.0099, validation_loss = 0.0087, quality_speed_tradeoff = 1.0612', '\\n',\n'Weight Decay 0.01: Epoch 32: train_loss = 0.0099, validation_loss = 0.0087,\nquality_speed_tradeoff = 1.0501', '\\n', 'Weight Decay 0.01: Epoch 33: train_loss\n= 0.0099, validation_loss = 0.0087, quality_speed_tradeoff = 1.0572', '\\n',\n'Weight Decay 0.01: Epoch 34: train_loss = 0.0099, validation_loss = 0.0087,\nquality_speed_tradeoff = 1.0512', '\\n', 'Weight Decay 0.01: Epoch 35: train_loss\n= 0.0098, validation_loss = 0.0086, quality_speed_tradeoff = 1.0484', '\\n',\n'Weight Decay 0.01: Epoch 36: train_loss = 0.0099, validation_loss = 0.0086,\nquality_speed_tradeoff = 1.0485', '\\n', 'Weight Decay 0.01: Epoch 37: train_loss\n= 0.0099, validation_loss = 0.0087, quality_speed_tradeoff = 1.0423', '\\n',\n'Weight Decay 0.01: Epoch 38: train_loss = 0.0099, validation_loss = 0.0087,\nquality_speed_tradeoff = 1.0394', '\\n', 'Weight Decay 0.01: Epoch 39: train_loss\n= 0.0099, validation_loss = 0.0086, quality_speed_tradeoff = 1.0471', '\\n',\n'Weight Decay 0.01: Epoch 40: train_loss = 0.0098, validation_loss = 0.0086,\nquality_speed_tradeoff = 1.0587', '\\n', 'Weight Decay 0.01: Epoch 41: train_loss\n= 0.0098, validation_loss = 0.0087, quality_speed_tradeoff = 1.0415', '\\n',\n'Weight Decay 0.01: Epoch 42: train_loss = 0.0098, validation_loss = 0.0085,\nquality_speed_tradeoff = 1.0548', '\\n', 'Weight Decay 0.01: Epoch 43: train_loss\n= 0.0098, validation_loss = 0.0086, quality_speed_tradeoff = 1.0421', '\\n',\n'Weight Decay 0.01: Epoch 44: train_loss = 0.0098, validation_loss = 0.0086,\nquality_speed_tradeoff = 1.0528', '\\n', 'Weight Decay 0.01: Epoch 45: train_loss\n= 0.0099, validation_loss = 0.0087, quality_speed_tradeoff = 1.0393', '\\n',\n'Weight Decay 0.01: Epoch 46: train_loss = 0.0098, validation_loss = 0.0086,\nquality_speed_tradeoff = 1.0444', '\\n', 'Weight Decay 0.01: Epoch 47: train_loss\n= 0.0098, validation_loss = 0.0086, quality_speed_tradeoff = 1.0400', '\\n',\n'Weight Decay 0.01: Epoch 48: train_loss = 0.0099, validation_loss = 0.0085,\nquality_speed_tradeoff = 1.0561', '\\n', 'Weight Decay 0.01: Epoch 49: train_loss\n= 0.0098, validation_loss = 0.0086, quality_speed_tradeoff = 1.0604', '\\n',\n'Weight Decay 0.01: Epoch 50: train_loss = 0.0098, validation_loss = 0.0088,\nquality_speed_tradeoff = 1.0322', '\\n', 'Weight Decay 0.001: Epoch 1: train_loss\n= 0.4057, validation_loss = 0.0784, quality_speed_tradeoff = 0.7811', '\\n',\n'Weight Decay 0.001: Epoch 2: train_loss = 0.0415, validation_loss = 0.0327,\nquality_speed_tradeoff = 1.1191', '\\n', 'Weight Decay 0.001: Epoch 3: train_loss\n= 0.0325, validation_loss = 0.0265, quality_speed_tradeoff = 1.0173', '\\n',\n'Weight Decay 0.001: Epoch 4: train_loss = 0.0263, validation_loss = 0.0220,\nquality_speed_tradeoff = 1.0254', '\\n', 'Weight Decay 0.001: Epoch 5: train_loss\n= 0.0223, validation_loss = 0.0180, quality_speed_tradeoff = 1.0343', '\\n',\n'Weight Decay 0.001: Epoch 6: train_loss = 0.0189, validation_loss = 0.0153,\nquality_speed_tradeoff = 1.0262', '\\n', 'Weight Decay 0.001: Epoch 7: train_loss\n= 0.0163, validation_loss = 0.0127, quality_speed_tradeoff = 1.0388', '\\n',\n'Weight Decay 0.001: Epoch 8: train_loss = 0.0143, validation_loss = 0.0111,\nquality_speed_tradeoff = 1.0390', '\\n', 'Weight Decay 0.001: Epoch 9: train_loss\n= 0.0128, validation_loss = 0.0099, quality_speed_tradeoff = 1.0458', '\\n',\n'Weight Decay 0.001: Epoch 10: train_loss = 0.0118, validation_loss = 0.0092,\nquality_speed_tradeoff = 1.0451', '\\n', 'Weight Decay 0.001: Epoch 11:\ntrain_loss = 0.0110, validation_loss = 0.0087, quality_speed_tradeoff = 1.0478',\n'\\n', 'Weight Decay 0.001: Epoch 12: train_loss = 0.0106, validation_loss =\n0.0085, quality_speed_tradeoff = 1.0439', '\\n', 'Weight Decay 0.001: Epoch 13:\ntrain_loss = 0.0102, validation_loss = 0.0084, quality_speed_tradeoff = 1.0461',\n'\\n', 'Weight Decay 0.001: Epoch 14: train_loss = 0.0100, validation_loss =\n0.0083, quality_speed_tradeoff = 1.0535', '\\n', 'Weight Decay 0.001: Epoch 15:\ntrain_loss = 0.0099, validation_loss = 0.0083, quality_speed_tradeoff = 1.0531',\n'\\n', 'Weight Decay 0.001: Epoch 16: train_loss = 0.0098, validation_loss =\n0.0083, quality_speed_tradeoff = 1.0498', '\\n', 'Weight Decay 0.001: Epoch 17:\ntrain_loss = 0.0097, validation_loss = 0.0083, quality_speed_tradeoff = 1.0522',\n'\\n', 'Weight Decay 0.001: Epoch 18: train_loss = 0.0097, validation_loss =\n0.0083, quality_speed_tradeoff = 1.0484', '\\n', 'Weight Decay 0.001: Epoch 19:\ntrain_loss = 0.0097, validation_loss = 0.0083, quality_speed_tradeoff = 1.0502',\n'\\n', 'Weight Decay 0.001: Epoch 20: train_loss = 0.0097, validation_loss =\n0.0083, quality_speed_tradeoff = 1.0529', '\\n', 'Weight Decay 0.001: Epoch 21:\ntrain_loss = 0.0097, validation_loss = 0.0084, quality_speed_tradeoff = 1.0636',\n'\\n', 'Weight Decay 0.001: Epoch 22: train_loss = 0.0097, validation_loss =\n0.0085, quality_speed_tradeoff = 1.0340', '\\n', 'Weight Decay 0.001: Epoch 23:\ntrain_loss = 0.0098, validation_loss = 0.0083, quality_speed_tradeoff = 1.0463',\n'\\n', 'Weight Decay 0.001: Epoch 24: train_loss = 0.0097, validation_loss =\n0.0083, quality_speed_tradeoff = 1.0501', '\\n', 'Weight Decay 0.001: Epoch 25:\ntrain_loss = 0.0097, validation_loss = 0.0083, quality_speed_tradeoff = 1.0538',\n'\\n', 'Weight Decay 0.001: Epoch 26: train_loss = 0.0096, validation_loss =\n0.0083, quality_speed_tradeoff = 1.0459', '\\n', 'Weight Decay 0.001: Epoch 27:\ntrain_loss = 0.0097, validation_loss = 0.0083, quality_speed_tradeoff = 1.0448',\n'\\n', 'Weight Decay 0.001: Epoch 28: train_loss = 0.0097, validation_loss =\n0.0084, quality_speed_tradeoff = 1.0372', '\\n', 'Weight Decay 0.001: Epoch 29:\ntrain_loss = 0.0098, validation_loss = 0.0083, quality_speed_tradeoff = 1.0424',\n'\\n', 'Weight Decay 0.001: Epoch 30: train_loss = 0.0097, validation_loss =\n0.0083, quality_speed_tradeoff = 1.0483', '\\n', 'Weight Decay 0.001: Epoch 31:\ntrain_loss = 0.0098, validation_loss = 0.0083, quality_speed_tradeoff = 1.0395',\n'\\n', 'Weight Decay 0.001: Epoch 32: train_loss = 0.0097, validation_loss =\n0.0083, quality_speed_tradeoff = 1.0539', '\\n', 'Weight Decay 0.001: Epoch 33:\ntrain_loss = 0.0097, validation_loss = 0.0082, quality_speed_tradeoff = 1.0465',\n'\\n', 'Weight Decay 0.001: Epoch 34: train_loss = 0.0096, validation_loss =\n0.0083, quality_speed_tradeoff = 1.0388', '\\n', 'Weight Decay 0.001: Epoch 35:\ntrain_loss = 0.0097, validation_loss = 0.0083, quality_speed_tradeoff = 1.0606',\n'\\n', 'Weight Decay 0.001: Epoch 36: train_loss = 0.0096, validation_loss =\n0.0083, quality_speed_tradeoff = 1.0442', '\\n', 'Weight Decay 0.001: Epoch 37:\ntrain_loss = 0.0097, validation_loss = 0.0083, quality_speed_tradeoff = 1.0622',\n'\\n', 'Weight Decay 0.001: Epoch 38: train_loss = 0.0096, validation_loss =\n0.0083, quality_speed_tradeoff = 1.0431', '\\n', 'Weight Decay 0.001: Epoch 39:\ntrain_loss = 0.0097, validation_loss = 0.0083, quality_speed_tradeoff = 1.0453',\n'\\n', 'Weight Decay 0.001: Epoch 40: train_loss = 0.0097, validation_loss =\n0.0083, quality_speed_tradeoff = 1.0596', '\\n', 'Weight Decay 0.001: Epoch 41:\ntrain_loss = 0.0097, validation_loss = 0.0082, quality_speed_tradeoff = 1.0542',\n'\\n', 'Weight Decay 0.001: Epoch 42: train_loss = 0.0097, validation_loss =\n0.0082, quality_speed_tradeoff = 1.0567', '\\n', 'Weight Decay 0.001: Epoch 43:\ntrain_loss = 0.0097, validation_loss = 0.0082, quality_speed_tradeoff = 1.0543',\n'\\n', 'Weight Decay 0.001: Epoch 44: train_loss = 0.0097, validation_loss =\n0.0083, quality_speed_tradeoff = 1.0492', '\\n', 'Weight Decay 0.001: Epoch 45:\ntrain_loss = 0.0096, validation_loss = 0.0083, quality_speed_tradeoff = 1.0426',\n'\\n', 'Weight Decay 0.001: Epoch 46: train_loss = 0.0097, validation_loss =\n0.0084, quality_speed_tradeoff = 1.0686', '\\n', 'Weight Decay 0.001: Epoch 47:\ntrain_loss = 0.0098, validation_loss = 0.0083, quality_speed_tradeoff = 1.0637',\n'\\n', 'Weight Decay 0.001: Epoch 48: train_loss = 0.0097, validation_loss =\n0.0086, quality_speed_tradeoff = 1.0248', '\\n', 'Weight Decay 0.001: Epoch 49:\ntrain_loss = 0.0097, validation_loss = 0.0082, quality_speed_tradeoff = 1.0539',\n'\\n', 'Weight Decay 0.001: Epoch 50: train_loss = 0.0097, validation_loss =\n0.0082, quality_speed_tradeoff = 1.0595', '\\n', 'Weight Decay 0.0001: Epoch 1:\ntrain_loss = 0.4113, validation_loss = 0.0563, quality_speed_tradeoff = 0.7711',\n'\\n', 'Weight Decay 0.0001: Epoch 2: train_loss = 0.0207, validation_loss =\n0.0167, quality_speed_tradeoff = 1.1378', '\\n', 'Weight Decay 0.0001: Epoch 3:\ntrain_loss = 0.0163, validation_loss = 0.0111, quality_speed_tradeoff = 1.0460',\n'\\n', 'Weight Decay 0.0001: Epoch 4: train_loss = 0.0134, validation_loss =\n0.0104, quality_speed_tradeoff = 1.0374', '\\n', 'Weight Decay 0.0001: Epoch 5:\ntrain_loss = 0.0126, validation_loss = 0.0096, quality_speed_tradeoff = 1.0469',\n'\\n', 'Weight Decay 0.0001: Epoch 6: train_loss = 0.0119, validation_loss =\n0.0091, quality_speed_tradeoff = 1.0462', '\\n', 'Weight Decay 0.0001: Epoch 7:\ntrain_loss = 0.0113, validation_loss = 0.0087, quality_speed_tradeoff = 1.0494',\n'\\n', 'Weight Decay 0.0001: Epoch 8: train_loss = 0.0109, validation_loss =\n0.0085, quality_speed_tradeoff = 1.0517', '\\n', 'Weight Decay 0.0001: Epoch 9:\ntrain_loss = 0.0105, validation_loss = 0.0082, quality_speed_tradeoff = 1.0520',\n'\\n', 'Weight Decay 0.0001: Epoch 10: train_loss = 0.0103, validation_loss =\n0.0081, quality_speed_tradeoff = 1.0441', '\\n', 'Weight Decay 0.0001: Epoch 11:\ntrain_loss = 0.0101, validation_loss = 0.0081, quality_speed_tradeoff = 1.0537',\n'\\n', 'Weight Decay 0.0001: Epoch 12: train_loss = 0.0100, validation_loss =\n0.0080, quality_speed_tradeoff = 1.0487', '\\n', 'Weight Decay 0.0001: Epoch 13:\ntrain_loss = 0.0099, validation_loss = 0.0080, quality_speed_tradeoff = 1.0525',\n'\\n', 'Weight Decay 0.0001: Epoch 14: train_loss = 0.0098, validation_loss =\n0.0080, quality_speed_tradeoff = 1.0559', '\\n', 'Weight Decay 0.0001: Epoch 15:\ntrain_loss = 0.0098, validation_loss = 0.0081, quality_speed_tradeoff = 1.0404',\n'\\n', 'Weight Decay 0.0001: Epoch 16: train_loss = 0.0098, validation_loss =\n0.0081, quality_speed_tradeoff = 1.0595', '\\n', 'Weight Decay 0.0001: Epoch 17:\ntrain_loss = 0.0097, validation_loss = 0.0081, quality_speed_tradeoff = 1.0524',\n'\\n', 'Weight Decay 0.0001: Epoch 18: train_loss = 0.0097, validation_loss =\n0.0081, quality_speed_tradeoff = 1.0427', '\\n', 'Weight Decay 0.0001: Epoch 19:\ntrain_loss = 0.0097, validation_loss = 0.0081, quality_speed_tradeoff = 1.0545',\n'\\n', 'Weight Decay 0.0001: Epoch 20: train_loss = 0.0097, validation_loss =\n0.0081, quality_speed_tradeoff = 1.0536', '\\n', 'Weight Decay 0.0001: Epoch 21:\ntrain_loss = 0.0097, validation_loss = 0.0081, quality_speed_tradeoff = 1.0553',\n'\\n', 'Weight Decay 0.0001: Epoch 22: train_loss = 0.0096, validation_loss =\n0.0081, quality_speed_tradeoff = 1.0420', '\\n', 'Weight Decay 0.0001: Epoch 23:\ntrain_loss = 0.0097, validation_loss = 0.0084, quality_speed_tradeoff = 1.0698',\n'\\n', 'Weight Decay 0.0001: Epoch 24: train_loss = 0.0098, validation_loss =\n0.0081, quality_speed_tradeoff = 1.0513', '\\n', 'Weight Decay 0.0001: Epoch 25:\ntrain_loss = 0.0097, validation_loss = 0.0083, quality_speed_tradeoff = 1.0640',\n'\\n', 'Weight Decay 0.0001: Epoch 26: train_loss = 0.0097, validation_loss =\n0.0082, quality_speed_tradeoff = 1.0565', '\\n', 'Weight Decay 0.0001: Epoch 27:\ntrain_loss = 0.0096, validation_loss = 0.0081, quality_speed_tradeoff = 1.0504',\n'\\n', 'Weight Decay 0.0001: Epoch 28: train_loss = 0.0097, validation_loss =\n0.0082, quality_speed_tradeoff = 1.0602', '\\n', 'Weight Decay 0.0001: Epoch 29:\ntrain_loss = 0.0097, validation_loss = 0.0082, quality_speed_tradeoff = 1.0452',\n'\\n', 'Weight Decay 0.0001: Epoch 30: train_loss = 0.0096, validation_loss =\n0.0082, quality_speed_tradeoff = 1.0576', '\\n', 'Weight Decay 0.0001: Epoch 31:\ntrain_loss = 0.0096, validation_loss = 0.0082, quality_speed_tradeoff = 1.0579',\n'\\n', 'Weight Decay 0.0001: Epoch 32: train_loss = 0.0096, validation_loss =\n0.0082, quality_speed_tradeoff = 1.0495', '\\n', 'Weight Decay 0.0001: Epoch 33:\ntrain_loss = 0.0097, validation_loss = 0.0082, quality_speed_tradeoff = 1.0490',\n'\\n', 'Weight Decay 0.0001: Epoch 34: train_loss = 0.0096, validation_loss =\n0.0082, quality_speed_tradeoff = 1.0602', '\\n', 'Weight Decay 0.0001: Epoch 35:\ntrain_loss = 0.0096, validation_loss = 0.0082, quality_speed_tradeoff = 1.0532',\n'\\n', 'Weight Decay 0.0001: Epoch 36: train_loss = 0.0097, validation_loss =\n0.0082, quality_speed_tradeoff = 1.0607', '\\n', 'Weight Decay 0.0001: Epoch 37:\ntrain_loss = 0.0097, validation_loss = 0.0084, quality_speed_tradeoff = 1.0683',\n'\\n', 'Weight Decay 0.0001: Epoch 38: train_loss = 0.0097, validation_loss =\n0.0083, quality_speed_tradeoff = 1.0624', '\\n', 'Weight Decay 0.0001: Epoch 39:\ntrain_loss = 0.0099, validation_loss = 0.0083, quality_speed_tradeoff = 1.0658',\n'\\n', 'Weight Decay 0.0001: Epoch 40: train_loss = 0.0096, validation_loss =\n0.0082, quality_speed_tradeoff = 1.0523', '\\n', 'Weight Decay 0.0001: Epoch 41:\ntrain_loss = 0.0096, validation_loss = 0.0083, quality_speed_tradeoff = 1.0660',\n'\\n', 'Weight Decay 0.0001: Epoch 42: train_loss = 0.0097, validation_loss =\n0.0083, quality_speed_tradeoff = 1.0349', '\\n', 'Weight Decay 0.0001: Epoch 43:\ntrain_loss = 0.0097, validation_loss = 0.0083, quality_speed_tradeoff = 1.0362',\n'\\n', 'Weight Decay 0.0001: Epoch 44: train_loss = 0.0098, validation_loss =\n0.0082, quality_speed_tradeoff = 1.0453', '\\n', 'Weight Decay 0.0001: Epoch 45:\ntrain_loss = 0.0097, validation_loss = 0.0082, quality_speed_tradeoff = 1.0491',\n'\\n', 'Weight Decay 0.0001: Epoch 46: train_loss = 0.0096, validation_loss =\n0.0082, quality_speed_tradeoff = 1.0504', '\\n', 'Weight Decay 0.0001: Epoch 47:\ntrain_loss = 0.0096, validation_loss = 0.0082, quality_speed_tradeoff = 1.0526',\n'\\n', 'Weight Decay 0.0001: Epoch 48: train_loss = 0.0096, validation_loss =\n0.0082, quality_speed_tradeoff = 1.0581', '\\n', 'Weight Decay 0.0001: Epoch 49:\ntrain_loss = 0.0097, validation_loss = 0.0082, quality_speed_tradeoff = 1.0571',\n'\\n', 'Weight Decay 0.0001: Epoch 50: train_loss = 0.0097, validation_loss =\n0.0082, quality_speed_tradeoff = 1.0434', '\\n', 'Execution time: 4 seconds\nseconds (time limit is an hour).']", "['Using device: cpu', '\\n', 'Dropout 0.0 Epoch 1: train_loss = 0.0881,\nvalidation_loss = 0.0683, quality_speed_tradeoff = 1.1763', '\\n', 'Dropout 0.0\nEpoch 2: train_loss = 0.0484, validation_loss = 0.0474, quality_speed_tradeoff =\n1.0278', '\\n', 'Dropout 0.0 Epoch 3: train_loss = 0.0344, validation_loss =\n0.0332, quality_speed_tradeoff = 1.0663', '\\n', 'Dropout 0.0 Epoch 4: train_loss\n= 0.0254, validation_loss = 0.0247, quality_speed_tradeoff = 1.0635', '\\n',\n'Dropout 0.0 Epoch 5: train_loss = 0.0200, validation_loss = 0.0195,\nquality_speed_tradeoff = 1.0427', '\\n', 'Dropout 0.0 Epoch 6: train_loss =\n0.0168, validation_loss = 0.0160, quality_speed_tradeoff = 1.0446', '\\n',\n'Dropout 0.0 Epoch 7: train_loss = 0.0146, validation_loss = 0.0135,\nquality_speed_tradeoff = 1.0622', '\\n', 'Dropout 0.0 Epoch 8: train_loss =\n0.0131, validation_loss = 0.0120, quality_speed_tradeoff = 1.0662', '\\n',\n'Dropout 0.0 Epoch 9: train_loss = 0.0122, validation_loss = 0.0110,\nquality_speed_tradeoff = 1.0703', '\\n', 'Dropout 0.0 Epoch 10: train_loss =\n0.0113, validation_loss = 0.0101, quality_speed_tradeoff = 1.0602', '\\n',\n'Dropout 0.0 Epoch 11: train_loss = 0.0107, validation_loss = 0.0098,\nquality_speed_tradeoff = 1.0778', '\\n', 'Dropout 0.0 Epoch 12: train_loss =\n0.0105, validation_loss = 0.0091, quality_speed_tradeoff = 1.0553', '\\n',\n'Dropout 0.0 Epoch 13: train_loss = 0.0101, validation_loss = 0.0088,\nquality_speed_tradeoff = 1.0538', '\\n', 'Dropout 0.0 Epoch 14: train_loss =\n0.0100, validation_loss = 0.0087, quality_speed_tradeoff = 1.0635', '\\n',\n'Dropout 0.0 Epoch 15: train_loss = 0.0098, validation_loss = 0.0086,\nquality_speed_tradeoff = 1.0622', '\\n', 'Dropout 0.0 Epoch 16: train_loss =\n0.0099, validation_loss = 0.0085, quality_speed_tradeoff = 1.0627', '\\n',\n'Dropout 0.0 Epoch 17: train_loss = 0.0098, validation_loss = 0.0084,\nquality_speed_tradeoff = 1.0613', '\\n', 'Dropout 0.0 Epoch 18: train_loss =\n0.0097, validation_loss = 0.0084, quality_speed_tradeoff = 1.0624', '\\n',\n'Dropout 0.0 Epoch 19: train_loss = 0.0098, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0443', '\\n', 'Dropout 0.0 Epoch 20: train_loss =\n0.0098, validation_loss = 0.0085, quality_speed_tradeoff = 1.0330', '\\n',\n'Dropout 0.0 Epoch 21: train_loss = 0.0098, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0526', '\\n', 'Dropout 0.0 Epoch 22: train_loss =\n0.0096, validation_loss = 0.0083, quality_speed_tradeoff = 1.0607', '\\n',\n'Dropout 0.0 Epoch 23: train_loss = 0.0098, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0467', '\\n', 'Dropout 0.0 Epoch 24: train_loss =\n0.0099, validation_loss = 0.0084, quality_speed_tradeoff = 1.0690', '\\n',\n'Dropout 0.0 Epoch 25: train_loss = 0.0098, validation_loss = 0.0087,\nquality_speed_tradeoff = 1.0792', '\\n', 'Dropout 0.0 Epoch 26: train_loss =\n0.0097, validation_loss = 0.0083, quality_speed_tradeoff = 1.0399', '\\n',\n'Dropout 0.0 Epoch 27: train_loss = 0.0098, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0432', '\\n', 'Dropout 0.0 Epoch 28: train_loss =\n0.0101, validation_loss = 0.0082, quality_speed_tradeoff = 1.0543', '\\n',\n'Dropout 0.0 Epoch 29: train_loss = 0.0097, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0482', '\\n', 'Dropout 0.0 Epoch 30: train_loss =\n0.0097, validation_loss = 0.0082, quality_speed_tradeoff = 1.0476', '\\n',\n'Dropout 0.0 Epoch 31: train_loss = 0.0098, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0654', '\\n', 'Dropout 0.0 Epoch 32: train_loss =\n0.0099, validation_loss = 0.0082, quality_speed_tradeoff = 1.0497', '\\n',\n'Dropout 0.0 Epoch 33: train_loss = 0.0097, validation_loss = 0.0086,\nquality_speed_tradeoff = 1.0781', '\\n', 'Dropout 0.0 Epoch 34: train_loss =\n0.0097, validation_loss = 0.0083, quality_speed_tradeoff = 1.0665', '\\n',\n'Dropout 0.0 Epoch 35: train_loss = 0.0097, validation_loss = 0.0085,\nquality_speed_tradeoff = 1.0713', '\\n', 'Dropout 0.0 Epoch 36: train_loss =\n0.0097, validation_loss = 0.0083, quality_speed_tradeoff = 1.0400', '\\n',\n'Dropout 0.0 Epoch 37: train_loss = 0.0100, validation_loss = 0.0084,\nquality_speed_tradeoff = 1.0686', '\\n', 'Dropout 0.0 Epoch 38: train_loss =\n0.0098, validation_loss = 0.0083, quality_speed_tradeoff = 1.0569', '\\n',\n'Dropout 0.0 Epoch 39: train_loss = 0.0097, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0441', '\\n', 'Dropout 0.0 Epoch 40: train_loss =\n0.0098, validation_loss = 0.0082, quality_speed_tradeoff = 1.0474', '\\n',\n'Dropout 0.0 Epoch 41: train_loss = 0.0097, validation_loss = 0.0086,\nquality_speed_tradeoff = 1.0775', '\\n', 'Dropout 0.0 Epoch 42: train_loss =\n0.0098, validation_loss = 0.0084, quality_speed_tradeoff = 1.0646', '\\n',\n'Dropout 0.0 Epoch 43: train_loss = 0.0097, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0581', '\\n', 'Dropout 0.0 Epoch 44: train_loss =\n0.0097, validation_loss = 0.0083, quality_speed_tradeoff = 1.0406', '\\n',\n'Dropout 0.0 Epoch 45: train_loss = 0.0100, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0577', '\\n', 'Dropout 0.0 Epoch 46: train_loss =\n0.0099, validation_loss = 0.0081, quality_speed_tradeoff = 1.0480', '\\n',\n'Dropout 0.0 Epoch 47: train_loss = 0.0097, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0589', '\\n', 'Dropout 0.0 Epoch 48: train_loss =\n0.0098, validation_loss = 0.0082, quality_speed_tradeoff = 1.0464', '\\n',\n'Dropout 0.0 Epoch 49: train_loss = 0.0097, validation_loss = 0.0088,\nquality_speed_tradeoff = 1.0833', '\\n', 'Dropout 0.0 Epoch 50: train_loss =\n0.0099, validation_loss = 0.0083, quality_speed_tradeoff = 1.0348', '\\n',\n'Dropout 0.2 Epoch 1: train_loss = 0.9580, validation_loss = 0.2707,\nquality_speed_tradeoff = 0.4143', '\\n', 'Dropout 0.2 Epoch 2: train_loss =\n0.1797, validation_loss = 0.0369, quality_speed_tradeoff = 1.0086', '\\n',\n'Dropout 0.2 Epoch 3: train_loss = 0.0942, validation_loss = 0.0292,\nquality_speed_tradeoff = 1.0603', '\\n', 'Dropout 0.2 Epoch 4: train_loss =\n0.0753, validation_loss = 0.0243, quality_speed_tradeoff = 1.0052', '\\n',\n'Dropout 0.2 Epoch 5: train_loss = 0.0680, validation_loss = 0.0198,\nquality_speed_tradeoff = 1.0165', '\\n', 'Dropout 0.2 Epoch 6: train_loss =\n0.0571, validation_loss = 0.0166, quality_speed_tradeoff = 1.0299', '\\n',\n'Dropout 0.2 Epoch 7: train_loss = 0.0475, validation_loss = 0.0158,\nquality_speed_tradeoff = 1.0149', '\\n', 'Dropout 0.2 Epoch 8: train_loss =\n0.0427, validation_loss = 0.0148, quality_speed_tradeoff = 1.0275', '\\n',\n'Dropout 0.2 Epoch 9: train_loss = 0.0396, validation_loss = 0.0154,\nquality_speed_tradeoff = 1.0121', '\\n', 'Dropout 0.2 Epoch 10: train_loss =\n0.0346, validation_loss = 0.0156, quality_speed_tradeoff = 1.0134', '\\n',\n'Dropout 0.2 Epoch 11: train_loss = 0.0356, validation_loss = 0.0157,\nquality_speed_tradeoff = 1.0178', '\\n', 'Dropout 0.2 Epoch 12: train_loss =\n0.0408, validation_loss = 0.0160, quality_speed_tradeoff = 1.0276', '\\n',\n'Dropout 0.2 Epoch 13: train_loss = 0.0345, validation_loss = 0.0168,\nquality_speed_tradeoff = 1.0243', '\\n', 'Dropout 0.2 Epoch 14: train_loss =\n0.0299, validation_loss = 0.0178, quality_speed_tradeoff = 1.0152', '\\n',\n'Dropout 0.2 Epoch 15: train_loss = 0.0340, validation_loss = 0.0179,\nquality_speed_tradeoff = 1.0265', '\\n', 'Dropout 0.2 Epoch 16: train_loss =\n0.0317, validation_loss = 0.0195, quality_speed_tradeoff = 1.0068', '\\n',\n'Dropout 0.2 Epoch 17: train_loss = 0.0306, validation_loss = 0.0192,\nquality_speed_tradeoff = 1.0143', '\\n', 'Dropout 0.2 Epoch 18: train_loss =\n0.0302, validation_loss = 0.0184, quality_speed_tradeoff = 1.0357', '\\n',\n'Dropout 0.2 Epoch 19: train_loss = 0.0321, validation_loss = 0.0195,\nquality_speed_tradeoff = 1.0182', '\\n', 'Dropout 0.2 Epoch 20: train_loss =\n0.0295, validation_loss = 0.0198, quality_speed_tradeoff = 1.0196', '\\n',\n'Dropout 0.2 Epoch 21: train_loss = 0.0324, validation_loss = 0.0196,\nquality_speed_tradeoff = 1.0294', '\\n', 'Dropout 0.2 Epoch 22: train_loss =\n0.0323, validation_loss = 0.0203, quality_speed_tradeoff = 1.0266', '\\n',\n'Dropout 0.2 Epoch 23: train_loss = 0.0334, validation_loss = 0.0212,\nquality_speed_tradeoff = 1.0140', '\\n', 'Dropout 0.2 Epoch 24: train_loss =\n0.0319, validation_loss = 0.0203, quality_speed_tradeoff = 1.0313', '\\n',\n'Dropout 0.2 Epoch 25: train_loss = 0.0354, validation_loss = 0.0201,\nquality_speed_tradeoff = 1.0429', '\\n', 'Dropout 0.2 Epoch 26: train_loss =\n0.0339, validation_loss = 0.0215, quality_speed_tradeoff = 1.0212', '\\n',\n'Dropout 0.2 Epoch 27: train_loss = 0.0328, validation_loss = 0.0223,\nquality_speed_tradeoff = 1.0155', '\\n', 'Dropout 0.2 Epoch 28: train_loss =\n0.0316, validation_loss = 0.0219, quality_speed_tradeoff = 1.0223', '\\n',\n'Dropout 0.2 Epoch 29: train_loss = 0.0319, validation_loss = 0.0219,\nquality_speed_tradeoff = 1.0219', '\\n', 'Dropout 0.2 Epoch 30: train_loss =\n0.0319, validation_loss = 0.0218, quality_speed_tradeoff = 1.0268', '\\n',\n'Dropout 0.2 Epoch 31: train_loss = 0.0314, validation_loss = 0.0224,\nquality_speed_tradeoff = 1.0174', '\\n', 'Dropout 0.2 Epoch 32: train_loss =\n0.0317, validation_loss = 0.0213, quality_speed_tradeoff = 1.0430', '\\n',\n'Dropout 0.2 Epoch 33: train_loss = 0.0325, validation_loss = 0.0226,\nquality_speed_tradeoff = 1.0152', '\\n', 'Dropout 0.2 Epoch 34: train_loss =\n0.0309, validation_loss = 0.0213, quality_speed_tradeoff = 1.0431', '\\n',\n'Dropout 0.2 Epoch 35: train_loss = 0.0327, validation_loss = 0.0221,\nquality_speed_tradeoff = 1.0284', '\\n', 'Dropout 0.2 Epoch 36: train_loss =\n0.0319, validation_loss = 0.0223, quality_speed_tradeoff = 1.0251', '\\n',\n'Dropout 0.2 Epoch 37: train_loss = 0.0309, validation_loss = 0.0222,\nquality_speed_tradeoff = 1.0248', '\\n', 'Dropout 0.2 Epoch 38: train_loss =\n0.0341, validation_loss = 0.0226, quality_speed_tradeoff = 1.0230', '\\n',\n'Dropout 0.2 Epoch 39: train_loss = 0.0322, validation_loss = 0.0232,\nquality_speed_tradeoff = 1.0244', '\\n', 'Dropout 0.2 Epoch 40: train_loss =\n0.0347, validation_loss = 0.0223, quality_speed_tradeoff = 1.0443', '\\n',\n'Dropout 0.2 Epoch 41: train_loss = 0.0333, validation_loss = 0.0238,\nquality_speed_tradeoff = 1.0130', '\\n', 'Dropout 0.2 Epoch 42: train_loss =\n0.0318, validation_loss = 0.0222, quality_speed_tradeoff = 1.0422', '\\n',\n'Dropout 0.2 Epoch 43: train_loss = 0.0328, validation_loss = 0.0235,\nquality_speed_tradeoff = 1.0148', '\\n', 'Dropout 0.2 Epoch 44: train_loss =\n0.0314, validation_loss = 0.0227, quality_speed_tradeoff = 1.0287', '\\n',\n'Dropout 0.2 Epoch 45: train_loss = 0.0322, validation_loss = 0.0233,\nquality_speed_tradeoff = 1.0171', '\\n', 'Dropout 0.2 Epoch 46: train_loss =\n0.0320, validation_loss = 0.0226, quality_speed_tradeoff = 1.0273', '\\n',\n'Dropout 0.2 Epoch 47: train_loss = 0.0333, validation_loss = 0.0221,\nquality_speed_tradeoff = 1.0543', '\\n', 'Dropout 0.2 Epoch 48: train_loss =\n0.0308, validation_loss = 0.0221, quality_speed_tradeoff = 1.0362', '\\n',\n'Dropout 0.2 Epoch 49: train_loss = 0.0315, validation_loss = 0.0231,\nquality_speed_tradeoff = 1.0133', '\\n', 'Dropout 0.2 Epoch 50: train_loss =\n0.0318, validation_loss = 0.0228, quality_speed_tradeoff = 1.0243', '\\n',\n'Dropout 0.5 Epoch 1: train_loss = 0.3801, validation_loss = 0.0488,\nquality_speed_tradeoff = 0.9742', '\\n', 'Dropout 0.5 Epoch 2: train_loss =\n0.1272, validation_loss = 0.0395, quality_speed_tradeoff = 0.9678', '\\n',\n'Dropout 0.5 Epoch 3: train_loss = 0.0640, validation_loss = 0.0381,\nquality_speed_tradeoff = 0.9799', '\\n', 'Dropout 0.5 Epoch 4: train_loss =\n0.0457, validation_loss = 0.0384, quality_speed_tradeoff = 0.9972', '\\n',\n'Dropout 0.5 Epoch 5: train_loss = 0.0451, validation_loss = 0.0399,\nquality_speed_tradeoff = 1.0003', '\\n', 'Dropout 0.5 Epoch 6: train_loss =\n0.0468, validation_loss = 0.0405, quality_speed_tradeoff = 1.0063', '\\n',\n'Dropout 0.5 Epoch 7: train_loss = 0.0466, validation_loss = 0.0412,\nquality_speed_tradeoff = 1.0106', '\\n', 'Dropout 0.5 Epoch 8: train_loss =\n0.0444, validation_loss = 0.0405, quality_speed_tradeoff = 1.0319', '\\n',\n'Dropout 0.5 Epoch 9: train_loss = 0.0447, validation_loss = 0.0442,\nquality_speed_tradeoff = 0.9925', '\\n', 'Dropout 0.5 Epoch 10: train_loss =\n0.0465, validation_loss = 0.0431, quality_speed_tradeoff = 1.0029', '\\n',\n'Dropout 0.5 Epoch 11: train_loss = 0.0465, validation_loss = 0.0434,\nquality_speed_tradeoff = 1.0058', '\\n', 'Dropout 0.5 Epoch 12: train_loss =\n0.0440, validation_loss = 0.0451, quality_speed_tradeoff = 0.9879', '\\n',\n'Dropout 0.5 Epoch 13: train_loss = 0.0461, validation_loss = 0.0434,\nquality_speed_tradeoff = 1.0101', '\\n', 'Dropout 0.5 Epoch 14: train_loss =\n0.0437, validation_loss = 0.0418, quality_speed_tradeoff = 1.0199', '\\n',\n'Dropout 0.5 Epoch 15: train_loss = 0.0465, validation_loss = 0.0431,\nquality_speed_tradeoff = 1.0084', '\\n', 'Dropout 0.5 Epoch 16: train_loss =\n0.0438, validation_loss = 0.0438, quality_speed_tradeoff = 1.0039', '\\n',\n'Dropout 0.5 Epoch 17: train_loss = 0.0444, validation_loss = 0.0422,\nquality_speed_tradeoff = 1.0139', '\\n', 'Dropout 0.5 Epoch 18: train_loss =\n0.0455, validation_loss = 0.0416, quality_speed_tradeoff = 1.0192', '\\n',\n'Dropout 0.5 Epoch 19: train_loss = 0.0458, validation_loss = 0.0427,\nquality_speed_tradeoff = 1.0112', '\\n', 'Dropout 0.5 Epoch 20: train_loss =\n0.0464, validation_loss = 0.0418, quality_speed_tradeoff = 1.0273', '\\n',\n'Dropout 0.5 Epoch 21: train_loss = 0.0448, validation_loss = 0.0459,\nquality_speed_tradeoff = 0.9842', '\\n', 'Dropout 0.5 Epoch 22: train_loss =\n0.0475, validation_loss = 0.0426, quality_speed_tradeoff = 1.0227', '\\n',\n'Dropout 0.5 Epoch 23: train_loss = 0.0455, validation_loss = 0.0438,\nquality_speed_tradeoff = 1.0179', '\\n', 'Dropout 0.5 Epoch 24: train_loss =\n0.0446, validation_loss = 0.0412, quality_speed_tradeoff = 1.0268', '\\n',\n'Dropout 0.5 Epoch 25: train_loss = 0.0439, validation_loss = 0.0411,\nquality_speed_tradeoff = 1.0299', '\\n', 'Dropout 0.5 Epoch 26: train_loss =\n0.0460, validation_loss = 0.0417, quality_speed_tradeoff = 1.0248', '\\n',\n'Dropout 0.5 Epoch 27: train_loss = 0.0472, validation_loss = 0.0422,\nquality_speed_tradeoff = 1.0298', '\\n', 'Dropout 0.5 Epoch 28: train_loss =\n0.0445, validation_loss = 0.0424, quality_speed_tradeoff = 1.0300', '\\n',\n'Dropout 0.5 Epoch 29: train_loss = 0.0448, validation_loss = 0.0445,\nquality_speed_tradeoff = 0.9927', '\\n', 'Dropout 0.5 Epoch 30: train_loss =\n0.0461, validation_loss = 0.0434, quality_speed_tradeoff = 1.0121', '\\n',\n'Dropout 0.5 Epoch 31: train_loss = 0.0461, validation_loss = 0.0420,\nquality_speed_tradeoff = 1.0215', '\\n', 'Dropout 0.5 Epoch 32: train_loss =\n0.0455, validation_loss = 0.0432, quality_speed_tradeoff = 1.0120', '\\n',\n'Dropout 0.5 Epoch 33: train_loss = 0.0436, validation_loss = 0.0432,\nquality_speed_tradeoff = 1.0090', '\\n', 'Dropout 0.5 Epoch 34: train_loss =\n0.0438, validation_loss = 0.0412, quality_speed_tradeoff = 1.0157', '\\n',\n'Dropout 0.5 Epoch 35: train_loss = 0.0478, validation_loss = 0.0450,\nquality_speed_tradeoff = 0.9964', '\\n', 'Dropout 0.5 Epoch 36: train_loss =\n0.0432, validation_loss = 0.0473, quality_speed_tradeoff = 0.9691', '\\n',\n'Dropout 0.5 Epoch 37: train_loss = 0.0440, validation_loss = 0.0401,\nquality_speed_tradeoff = 1.0244', '\\n', 'Dropout 0.5 Epoch 38: train_loss =\n0.0435, validation_loss = 0.0417, quality_speed_tradeoff = 1.0164', '\\n',\n'Dropout 0.5 Epoch 39: train_loss = 0.0450, validation_loss = 0.0426,\nquality_speed_tradeoff = 1.0081', '\\n', 'Dropout 0.5 Epoch 40: train_loss =\n0.0481, validation_loss = 0.0408, quality_speed_tradeoff = 1.0508', '\\n',\n'Dropout 0.5 Epoch 41: train_loss = 0.0445, validation_loss = 0.0437,\nquality_speed_tradeoff = 0.9994', '\\n', 'Dropout 0.5 Epoch 42: train_loss =\n0.0451, validation_loss = 0.0447, quality_speed_tradeoff = 0.9912', '\\n',\n'Dropout 0.5 Epoch 43: train_loss = 0.0444, validation_loss = 0.0417,\nquality_speed_tradeoff = 1.0095', '\\n', 'Dropout 0.5 Epoch 44: train_loss =\n0.0453, validation_loss = 0.0400, quality_speed_tradeoff = 1.0433', '\\n',\n'Dropout 0.5 Epoch 45: train_loss = 0.0439, validation_loss = 0.0448,\nquality_speed_tradeoff = 0.9859', '\\n', 'Dropout 0.5 Epoch 46: train_loss =\n0.0475, validation_loss = 0.0442, quality_speed_tradeoff = 1.0060', '\\n',\n'Dropout 0.5 Epoch 47: train_loss = 0.0455, validation_loss = 0.0430,\nquality_speed_tradeoff = 1.0214', '\\n', 'Dropout 0.5 Epoch 48: train_loss =\n0.0437, validation_loss = 0.0400, quality_speed_tradeoff = 1.0512', '\\n',\n'Dropout 0.5 Epoch 49: train_loss = 0.0445, validation_loss = 0.0441,\nquality_speed_tradeoff = 1.0025', '\\n', 'Dropout 0.5 Epoch 50: train_loss =\n0.0464, validation_loss = 0.0431, quality_speed_tradeoff = 1.0068', '\\n',\n'Execution time: 4 seconds seconds (time limit is an hour).']", "['Using device: cpu', '\\n', 'Momentum 0.0, Epoch 1: train_loss = 0.1276,\nvalidation_loss = 0.0922, quality_speed_tradeoff = 0.8891', '\\n', 'Momentum 0.0,\nEpoch 2: train_loss = 0.0662, validation_loss = 0.0715, quality_speed_tradeoff =\n0.9995', '\\n', 'Momentum 0.0, Epoch 3: train_loss = 0.0574, validation_loss =\n0.0655, quality_speed_tradeoff = 1.0348', '\\n', 'Momentum 0.0, Epoch 4:\ntrain_loss = 0.0538, validation_loss = 0.0615, quality_speed_tradeoff = 1.0497',\n'\\n', 'Momentum 0.0, Epoch 5: train_loss = 0.0509, validation_loss = 0.0584,\nquality_speed_tradeoff = 1.0496', '\\n', 'Momentum 0.0, Epoch 6: train_loss =\n0.0483, validation_loss = 0.0555, quality_speed_tradeoff = 1.0493', '\\n',\n'Momentum 0.0, Epoch 7: train_loss = 0.0459, validation_loss = 0.0526,\nquality_speed_tradeoff = 1.0545', '\\n', 'Momentum 0.0, Epoch 8: train_loss =\n0.0436, validation_loss = 0.0501, quality_speed_tradeoff = 1.0551', '\\n',\n'Momentum 0.0, Epoch 9: train_loss = 0.0416, validation_loss = 0.0477,\nquality_speed_tradeoff = 1.0533', '\\n', 'Momentum 0.0, Epoch 10: train_loss =\n0.0396, validation_loss = 0.0455, quality_speed_tradeoff = 1.0526', '\\n',\n'Momentum 0.0, Epoch 11: train_loss = 0.0378, validation_loss = 0.0434,\nquality_speed_tradeoff = 1.0550', '\\n', 'Momentum 0.0, Epoch 12: train_loss =\n0.0361, validation_loss = 0.0414, quality_speed_tradeoff = 1.0585', '\\n',\n'Momentum 0.0, Epoch 13: train_loss = 0.0346, validation_loss = 0.0397,\nquality_speed_tradeoff = 1.0531', '\\n', 'Momentum 0.0, Epoch 14: train_loss =\n0.0332, validation_loss = 0.0380, quality_speed_tradeoff = 1.0535', '\\n',\n'Momentum 0.0, Epoch 15: train_loss = 0.0318, validation_loss = 0.0365,\nquality_speed_tradeoff = 1.0527', '\\n', 'Momentum 0.0, Epoch 16: train_loss =\n0.0306, validation_loss = 0.0350, quality_speed_tradeoff = 1.0542', '\\n',\n'Momentum 0.0, Epoch 17: train_loss = 0.0294, validation_loss = 0.0336,\nquality_speed_tradeoff = 1.0526', '\\n', 'Momentum 0.0, Epoch 18: train_loss =\n0.0283, validation_loss = 0.0323, quality_speed_tradeoff = 1.0566', '\\n',\n'Momentum 0.0, Epoch 19: train_loss = 0.0273, validation_loss = 0.0311,\nquality_speed_tradeoff = 1.0537', '\\n', 'Momentum 0.0, Epoch 20: train_loss =\n0.0263, validation_loss = 0.0299, quality_speed_tradeoff = 1.0561', '\\n',\n'Momentum 0.0, Epoch 21: train_loss = 0.0254, validation_loss = 0.0289,\nquality_speed_tradeoff = 1.0538', '\\n', 'Momentum 0.0, Epoch 22: train_loss =\n0.0246, validation_loss = 0.0278, quality_speed_tradeoff = 1.0544', '\\n',\n'Momentum 0.0, Epoch 23: train_loss = 0.0238, validation_loss = 0.0269,\nquality_speed_tradeoff = 1.0538', '\\n', 'Momentum 0.0, Epoch 24: train_loss =\n0.0231, validation_loss = 0.0260, quality_speed_tradeoff = 1.0530', '\\n',\n'Momentum 0.0, Epoch 25: train_loss = 0.0224, validation_loss = 0.0251,\nquality_speed_tradeoff = 1.0554', '\\n', 'Momentum 0.0, Epoch 26: train_loss =\n0.0217, validation_loss = 0.0244, quality_speed_tradeoff = 1.0532', '\\n',\n'Momentum 0.0, Epoch 27: train_loss = 0.0211, validation_loss = 0.0236,\nquality_speed_tradeoff = 1.0527', '\\n', 'Momentum 0.0, Epoch 28: train_loss =\n0.0206, validation_loss = 0.0229, quality_speed_tradeoff = 1.0552', '\\n',\n'Momentum 0.0, Epoch 29: train_loss = 0.0200, validation_loss = 0.0223,\nquality_speed_tradeoff = 1.0529', '\\n', 'Momentum 0.0, Epoch 30: train_loss =\n0.0195, validation_loss = 0.0216, quality_speed_tradeoff = 1.0529', '\\n',\n'Momentum 0.0, Epoch 31: train_loss = 0.0190, validation_loss = 0.0210,\nquality_speed_tradeoff = 1.0553', '\\n', 'Momentum 0.0, Epoch 32: train_loss =\n0.0186, validation_loss = 0.0204, quality_speed_tradeoff = 1.0559', '\\n',\n'Momentum 0.0, Epoch 33: train_loss = 0.0182, validation_loss = 0.0199,\nquality_speed_tradeoff = 1.0548', '\\n', 'Momentum 0.0, Epoch 34: train_loss =\n0.0178, validation_loss = 0.0194, quality_speed_tradeoff = 1.0535', '\\n',\n'Momentum 0.0, Epoch 35: train_loss = 0.0174, validation_loss = 0.0189,\nquality_speed_tradeoff = 1.0544', '\\n', 'Momentum 0.0, Epoch 36: train_loss =\n0.0171, validation_loss = 0.0185, quality_speed_tradeoff = 1.0524', '\\n',\n'Momentum 0.0, Epoch 37: train_loss = 0.0167, validation_loss = 0.0181,\nquality_speed_tradeoff = 1.0507', '\\n', 'Momentum 0.0, Epoch 38: train_loss =\n0.0164, validation_loss = 0.0176, quality_speed_tradeoff = 1.0531', '\\n',\n'Momentum 0.0, Epoch 39: train_loss = 0.0161, validation_loss = 0.0173,\nquality_speed_tradeoff = 1.0515', '\\n', 'Momentum 0.0, Epoch 40: train_loss =\n0.0158, validation_loss = 0.0169, quality_speed_tradeoff = 1.0528', '\\n',\n'Momentum 0.0, Epoch 41: train_loss = 0.0155, validation_loss = 0.0165,\nquality_speed_tradeoff = 1.0546', '\\n', 'Momentum 0.0, Epoch 42: train_loss =\n0.0153, validation_loss = 0.0162, quality_speed_tradeoff = 1.0552', '\\n',\n'Momentum 0.0, Epoch 43: train_loss = 0.0151, validation_loss = 0.0159,\nquality_speed_tradeoff = 1.0537', '\\n', 'Momentum 0.0, Epoch 44: train_loss =\n0.0148, validation_loss = 0.0156, quality_speed_tradeoff = 1.0540', '\\n',\n'Momentum 0.0, Epoch 45: train_loss = 0.0146, validation_loss = 0.0153,\nquality_speed_tradeoff = 1.0517', '\\n', 'Momentum 0.0, Epoch 46: train_loss =\n0.0144, validation_loss = 0.0150, quality_speed_tradeoff = 1.0534', '\\n',\n'Momentum 0.0, Epoch 47: train_loss = 0.0142, validation_loss = 0.0148,\nquality_speed_tradeoff = 1.0524', '\\n', 'Momentum 0.0, Epoch 48: train_loss =\n0.0140, validation_loss = 0.0145, quality_speed_tradeoff = 1.0518', '\\n',\n'Momentum 0.0, Epoch 49: train_loss = 0.0138, validation_loss = 0.0143,\nquality_speed_tradeoff = 1.0548', '\\n', 'Momentum 0.0, Epoch 50: train_loss =\n0.0137, validation_loss = 0.0140, quality_speed_tradeoff = 1.0524', '\\n',\n'Momentum 0.5, Epoch 1: train_loss = 0.4679, validation_loss = 0.0464,\nquality_speed_tradeoff = 0.9389', '\\n', 'Momentum 0.5, Epoch 2: train_loss =\n0.0461, validation_loss = 0.0341, quality_speed_tradeoff = 1.0566', '\\n',\n'Momentum 0.5, Epoch 3: train_loss = 0.0390, validation_loss = 0.0305,\nquality_speed_tradeoff = 1.0690', '\\n', 'Momentum 0.5, Epoch 4: train_loss =\n0.0346, validation_loss = 0.0273, quality_speed_tradeoff = 1.0642', '\\n',\n'Momentum 0.5, Epoch 5: train_loss = 0.0310, validation_loss = 0.0248,\nquality_speed_tradeoff = 1.0772', '\\n', 'Momentum 0.5, Epoch 6: train_loss =\n0.0280, validation_loss = 0.0225, quality_speed_tradeoff = 1.0696', '\\n',\n'Momentum 0.5, Epoch 7: train_loss = 0.0254, validation_loss = 0.0205,\nquality_speed_tradeoff = 1.0635', '\\n', 'Momentum 0.5, Epoch 8: train_loss =\n0.0232, validation_loss = 0.0189, quality_speed_tradeoff = 1.0629', '\\n',\n'Momentum 0.5, Epoch 9: train_loss = 0.0214, validation_loss = 0.0175,\nquality_speed_tradeoff = 1.0666', '\\n', 'Momentum 0.5, Epoch 10: train_loss =\n0.0198, validation_loss = 0.0163, quality_speed_tradeoff = 1.0625', '\\n',\n'Momentum 0.5, Epoch 11: train_loss = 0.0184, validation_loss = 0.0153,\nquality_speed_tradeoff = 1.0601', '\\n', 'Momentum 0.5, Epoch 12: train_loss =\n0.0173, validation_loss = 0.0145, quality_speed_tradeoff = 1.0588', '\\n',\n'Momentum 0.5, Epoch 13: train_loss = 0.0163, validation_loss = 0.0138,\nquality_speed_tradeoff = 1.0599', '\\n', 'Momentum 0.5, Epoch 14: train_loss =\n0.0155, validation_loss = 0.0131, quality_speed_tradeoff = 1.0614', '\\n',\n'Momentum 0.5, Epoch 15: train_loss = 0.0148, validation_loss = 0.0126,\nquality_speed_tradeoff = 1.0640', '\\n', 'Momentum 0.5, Epoch 16: train_loss =\n0.0141, validation_loss = 0.0121, quality_speed_tradeoff = 1.0536', '\\n',\n'Momentum 0.5, Epoch 17: train_loss = 0.0136, validation_loss = 0.0117,\nquality_speed_tradeoff = 1.0599', '\\n', 'Momentum 0.5, Epoch 18: train_loss =\n0.0131, validation_loss = 0.0114, quality_speed_tradeoff = 1.0554', '\\n',\n'Momentum 0.5, Epoch 19: train_loss = 0.0128, validation_loss = 0.0111,\nquality_speed_tradeoff = 1.0544', '\\n', 'Momentum 0.5, Epoch 20: train_loss =\n0.0124, validation_loss = 0.0108, quality_speed_tradeoff = 1.0573', '\\n',\n'Momentum 0.5, Epoch 21: train_loss = 0.0121, validation_loss = 0.0106,\nquality_speed_tradeoff = 1.0595', '\\n', 'Momentum 0.5, Epoch 22: train_loss =\n0.0119, validation_loss = 0.0104, quality_speed_tradeoff = 1.0517', '\\n',\n'Momentum 0.5, Epoch 23: train_loss = 0.0116, validation_loss = 0.0102,\nquality_speed_tradeoff = 1.0547', '\\n', 'Momentum 0.5, Epoch 24: train_loss =\n0.0114, validation_loss = 0.0100, quality_speed_tradeoff = 1.0583', '\\n',\n'Momentum 0.5, Epoch 25: train_loss = 0.0112, validation_loss = 0.0099,\nquality_speed_tradeoff = 1.0508', '\\n', 'Momentum 0.5, Epoch 26: train_loss =\n0.0111, validation_loss = 0.0098, quality_speed_tradeoff = 1.0556', '\\n',\n'Momentum 0.5, Epoch 27: train_loss = 0.0109, validation_loss = 0.0096,\nquality_speed_tradeoff = 1.0552', '\\n', 'Momentum 0.5, Epoch 28: train_loss =\n0.0108, validation_loss = 0.0095, quality_speed_tradeoff = 1.0588', '\\n',\n'Momentum 0.5, Epoch 29: train_loss = 0.0107, validation_loss = 0.0094,\nquality_speed_tradeoff = 1.0557', '\\n', 'Momentum 0.5, Epoch 30: train_loss =\n0.0106, validation_loss = 0.0094, quality_speed_tradeoff = 1.0502', '\\n',\n'Momentum 0.5, Epoch 31: train_loss = 0.0105, validation_loss = 0.0093,\nquality_speed_tradeoff = 1.0568', '\\n', 'Momentum 0.5, Epoch 32: train_loss =\n0.0105, validation_loss = 0.0092, quality_speed_tradeoff = 1.0562', '\\n',\n'Momentum 0.5, Epoch 33: train_loss = 0.0104, validation_loss = 0.0092,\nquality_speed_tradeoff = 1.0584', '\\n', 'Momentum 0.5, Epoch 34: train_loss =\n0.0103, validation_loss = 0.0091, quality_speed_tradeoff = 1.0538', '\\n',\n'Momentum 0.5, Epoch 35: train_loss = 0.0103, validation_loss = 0.0090,\nquality_speed_tradeoff = 1.0536', '\\n', 'Momentum 0.5, Epoch 36: train_loss =\n0.0102, validation_loss = 0.0090, quality_speed_tradeoff = 1.0545', '\\n',\n'Momentum 0.5, Epoch 37: train_loss = 0.0102, validation_loss = 0.0089,\nquality_speed_tradeoff = 1.0531', '\\n', 'Momentum 0.5, Epoch 38: train_loss =\n0.0101, validation_loss = 0.0089, quality_speed_tradeoff = 1.0496', '\\n',\n'Momentum 0.5, Epoch 39: train_loss = 0.0101, validation_loss = 0.0089,\nquality_speed_tradeoff = 1.0510', '\\n', 'Momentum 0.5, Epoch 40: train_loss =\n0.0100, validation_loss = 0.0088, quality_speed_tradeoff = 1.0540', '\\n',\n'Momentum 0.5, Epoch 41: train_loss = 0.0100, validation_loss = 0.0088,\nquality_speed_tradeoff = 1.0518', '\\n', 'Momentum 0.5, Epoch 42: train_loss =\n0.0100, validation_loss = 0.0088, quality_speed_tradeoff = 1.0542', '\\n',\n'Momentum 0.5, Epoch 43: train_loss = 0.0099, validation_loss = 0.0087,\nquality_speed_tradeoff = 1.0519', '\\n', 'Momentum 0.5, Epoch 44: train_loss =\n0.0099, validation_loss = 0.0087, quality_speed_tradeoff = 1.0551', '\\n',\n'Momentum 0.5, Epoch 45: train_loss = 0.0099, validation_loss = 0.0087,\nquality_speed_tradeoff = 1.0533', '\\n', 'Momentum 0.5, Epoch 46: train_loss =\n0.0099, validation_loss = 0.0086, quality_speed_tradeoff = 1.0543', '\\n',\n'Momentum 0.5, Epoch 47: train_loss = 0.0099, validation_loss = 0.0086,\nquality_speed_tradeoff = 1.0479', '\\n', 'Momentum 0.5, Epoch 48: train_loss =\n0.0098, validation_loss = 0.0086, quality_speed_tradeoff = 1.0513', '\\n',\n'Momentum 0.5, Epoch 49: train_loss = 0.0098, validation_loss = 0.0086,\nquality_speed_tradeoff = 1.0555', '\\n', 'Momentum 0.5, Epoch 50: train_loss =\n0.0098, validation_loss = 0.0086, quality_speed_tradeoff = 1.0495', '\\n',\n'Momentum 0.9, Epoch 1: train_loss = 0.2320, validation_loss = 0.0476,\nquality_speed_tradeoff = 0.8764', '\\n', 'Momentum 0.9, Epoch 2: train_loss =\n0.0371, validation_loss = 0.0167, quality_speed_tradeoff = 1.0762', '\\n',\n'Momentum 0.9, Epoch 3: train_loss = 0.0167, validation_loss = 0.0117,\nquality_speed_tradeoff = 1.0714', '\\n', 'Momentum 0.9, Epoch 4: train_loss =\n0.0127, validation_loss = 0.0097, quality_speed_tradeoff = 1.0587', '\\n',\n'Momentum 0.9, Epoch 5: train_loss = 0.0111, validation_loss = 0.0092,\nquality_speed_tradeoff = 1.0383', '\\n', 'Momentum 0.9, Epoch 6: train_loss =\n0.0105, validation_loss = 0.0088, quality_speed_tradeoff = 1.0434', '\\n',\n'Momentum 0.9, Epoch 7: train_loss = 0.0101, validation_loss = 0.0087,\nquality_speed_tradeoff = 1.0405', '\\n', 'Momentum 0.9, Epoch 8: train_loss =\n0.0099, validation_loss = 0.0085, quality_speed_tradeoff = 1.0547', '\\n',\n'Momentum 0.9, Epoch 9: train_loss = 0.0098, validation_loss = 0.0084,\nquality_speed_tradeoff = 1.0583', '\\n', 'Momentum 0.9, Epoch 10: train_loss =\n0.0098, validation_loss = 0.0084, quality_speed_tradeoff = 1.0564', '\\n',\n'Momentum 0.9, Epoch 11: train_loss = 0.0098, validation_loss = 0.0084,\nquality_speed_tradeoff = 1.0386', '\\n', 'Momentum 0.9, Epoch 12: train_loss =\n0.0098, validation_loss = 0.0084, quality_speed_tradeoff = 1.0381', '\\n',\n'Momentum 0.9, Epoch 13: train_loss = 0.0098, validation_loss = 0.0084,\nquality_speed_tradeoff = 1.0361', '\\n', 'Momentum 0.9, Epoch 14: train_loss =\n0.0097, validation_loss = 0.0084, quality_speed_tradeoff = 1.0629', '\\n',\n'Momentum 0.9, Epoch 15: train_loss = 0.0097, validation_loss = 0.0084,\nquality_speed_tradeoff = 1.0638', '\\n', 'Momentum 0.9, Epoch 16: train_loss =\n0.0097, validation_loss = 0.0083, quality_speed_tradeoff = 1.0545', '\\n',\n'Momentum 0.9, Epoch 17: train_loss = 0.0096, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0531', '\\n', 'Momentum 0.9, Epoch 18: train_loss =\n0.0097, validation_loss = 0.0082, quality_speed_tradeoff = 1.0510', '\\n',\n'Momentum 0.9, Epoch 19: train_loss = 0.0096, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0489', '\\n', 'Momentum 0.9, Epoch 20: train_loss =\n0.0096, validation_loss = 0.0082, quality_speed_tradeoff = 1.0466', '\\n',\n'Momentum 0.9, Epoch 21: train_loss = 0.0096, validation_loss = 0.0085,\nquality_speed_tradeoff = 1.0711', '\\n', 'Momentum 0.9, Epoch 22: train_loss =\n0.0096, validation_loss = 0.0083, quality_speed_tradeoff = 1.0353', '\\n',\n'Momentum 0.9, Epoch 23: train_loss = 0.0097, validation_loss = 0.0084,\nquality_speed_tradeoff = 1.0313', '\\n', 'Momentum 0.9, Epoch 24: train_loss =\n0.0098, validation_loss = 0.0082, quality_speed_tradeoff = 1.0447', '\\n',\n'Momentum 0.9, Epoch 25: train_loss = 0.0097, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0501', '\\n', 'Momentum 0.9, Epoch 26: train_loss =\n0.0096, validation_loss = 0.0082, quality_speed_tradeoff = 1.0463', '\\n',\n'Momentum 0.9, Epoch 27: train_loss = 0.0098, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0451', '\\n', 'Momentum 0.9, Epoch 28: train_loss =\n0.0097, validation_loss = 0.0084, quality_speed_tradeoff = 1.0297', '\\n',\n'Momentum 0.9, Epoch 29: train_loss = 0.0099, validation_loss = 0.0084,\nquality_speed_tradeoff = 1.0332', '\\n', 'Momentum 0.9, Epoch 30: train_loss =\n0.0097, validation_loss = 0.0082, quality_speed_tradeoff = 1.0422', '\\n',\n'Momentum 0.9, Epoch 31: train_loss = 0.0098, validation_loss = 0.0084,\nquality_speed_tradeoff = 1.0328', '\\n', 'Momentum 0.9, Epoch 32: train_loss =\n0.0097, validation_loss = 0.0082, quality_speed_tradeoff = 1.0519', '\\n',\n'Momentum 0.9, Epoch 33: train_loss = 0.0097, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0471', '\\n', 'Momentum 0.9, Epoch 34: train_loss =\n0.0096, validation_loss = 0.0083, quality_speed_tradeoff = 1.0369', '\\n',\n'Momentum 0.9, Epoch 35: train_loss = 0.0097, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0602', '\\n', 'Momentum 0.9, Epoch 36: train_loss =\n0.0096, validation_loss = 0.0082, quality_speed_tradeoff = 1.0447', '\\n',\n'Momentum 0.9, Epoch 37: train_loss = 0.0097, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0613', '\\n', 'Momentum 0.9, Epoch 38: train_loss =\n0.0096, validation_loss = 0.0082, quality_speed_tradeoff = 1.0422', '\\n',\n'Momentum 0.9, Epoch 39: train_loss = 0.0097, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0447', '\\n', 'Momentum 0.9, Epoch 40: train_loss =\n0.0097, validation_loss = 0.0082, quality_speed_tradeoff = 1.0601', '\\n',\n'Momentum 0.9, Epoch 41: train_loss = 0.0097, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0543', '\\n', 'Momentum 0.9, Epoch 42: train_loss =\n0.0097, validation_loss = 0.0082, quality_speed_tradeoff = 1.0575', '\\n',\n'Momentum 0.9, Epoch 43: train_loss = 0.0097, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0543', '\\n', 'Momentum 0.9, Epoch 44: train_loss =\n0.0097, validation_loss = 0.0082, quality_speed_tradeoff = 1.0493', '\\n',\n'Momentum 0.9, Epoch 45: train_loss = 0.0096, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0439', '\\n', 'Momentum 0.9, Epoch 46: train_loss =\n0.0097, validation_loss = 0.0084, quality_speed_tradeoff = 1.0692', '\\n',\n'Momentum 0.9, Epoch 47: train_loss = 0.0098, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0644', '\\n', 'Momentum 0.9, Epoch 48: train_loss =\n0.0097, validation_loss = 0.0084, quality_speed_tradeoff = 1.0281', '\\n',\n'Momentum 0.9, Epoch 49: train_loss = 0.0097, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0570', '\\n', 'Momentum 0.9, Epoch 50: train_loss =\n0.0097, validation_loss = 0.0082, quality_speed_tradeoff = 1.0599', '\\n',\n'Execution time: 3 seconds seconds (time limit is an hour).']", "['Using device: cpu', '\\n', 'Momentum 0.0, Epoch 1: train_loss = 0.6131,\nvalidation_loss = 0.2086, quality_speed_tradeoff = 0.5343', '\\n', 'Momentum 0.0,\nEpoch 2: train_loss = 0.1020, validation_loss = 0.0710, quality_speed_tradeoff =\n0.8684', '\\n', 'Momentum 0.0, Epoch 3: train_loss = 0.0509, validation_loss =\n0.0524, quality_speed_tradeoff = 0.9699', '\\n', 'Momentum 0.0, Epoch 4:\ntrain_loss = 0.0441, validation_loss = 0.0473, quality_speed_tradeoff = 1.0022',\n'\\n', 'Momentum 0.0, Epoch 5: train_loss = 0.0416, validation_loss = 0.0444,\nquality_speed_tradeoff = 1.0148', '\\n', 'Momentum 0.0, Epoch 6: train_loss =\n0.0396, validation_loss = 0.0421, quality_speed_tradeoff = 1.0166', '\\n',\n'Momentum 0.0, Epoch 7: train_loss = 0.0378, validation_loss = 0.0399,\nquality_speed_tradeoff = 1.0225', '\\n', 'Momentum 0.0, Epoch 8: train_loss =\n0.0362, validation_loss = 0.0381, quality_speed_tradeoff = 1.0200', '\\n',\n'Momentum 0.0, Epoch 9: train_loss = 0.0346, validation_loss = 0.0364,\nquality_speed_tradeoff = 1.0173', '\\n', 'Momentum 0.0, Epoch 10: train_loss =\n0.0332, validation_loss = 0.0348, quality_speed_tradeoff = 1.0171', '\\n',\n'Momentum 0.0, Epoch 11: train_loss = 0.0318, validation_loss = 0.0331,\nquality_speed_tradeoff = 1.0202', '\\n', 'Momentum 0.0, Epoch 12: train_loss =\n0.0305, validation_loss = 0.0316, quality_speed_tradeoff = 1.0224', '\\n',\n'Momentum 0.0, Epoch 13: train_loss = 0.0294, validation_loss = 0.0303,\nquality_speed_tradeoff = 1.0205', '\\n', 'Momentum 0.0, Epoch 14: train_loss =\n0.0283, validation_loss = 0.0291, quality_speed_tradeoff = 1.0206', '\\n',\n'Momentum 0.0, Epoch 15: train_loss = 0.0272, validation_loss = 0.0279,\nquality_speed_tradeoff = 1.0203', '\\n', 'Momentum 0.0, Epoch 16: train_loss =\n0.0263, validation_loss = 0.0267, quality_speed_tradeoff = 1.0229', '\\n',\n'Momentum 0.0, Epoch 17: train_loss = 0.0254, validation_loss = 0.0257,\nquality_speed_tradeoff = 1.0214', '\\n', 'Momentum 0.0, Epoch 18: train_loss =\n0.0245, validation_loss = 0.0247, quality_speed_tradeoff = 1.0221', '\\n',\n'Momentum 0.0, Epoch 19: train_loss = 0.0237, validation_loss = 0.0238,\nquality_speed_tradeoff = 1.0205', '\\n', 'Momentum 0.0, Epoch 20: train_loss =\n0.0230, validation_loss = 0.0230, quality_speed_tradeoff = 1.0199', '\\n',\n'Momentum 0.0, Epoch 21: train_loss = 0.0223, validation_loss = 0.0222,\nquality_speed_tradeoff = 1.0203', '\\n', 'Momentum 0.0, Epoch 22: train_loss =\n0.0217, validation_loss = 0.0214, quality_speed_tradeoff = 1.0182', '\\n',\n'Momentum 0.0, Epoch 23: train_loss = 0.0211, validation_loss = 0.0207,\nquality_speed_tradeoff = 1.0191', '\\n', 'Momentum 0.0, Epoch 24: train_loss =\n0.0205, validation_loss = 0.0200, quality_speed_tradeoff = 1.0210', '\\n',\n'Momentum 0.0, Epoch 25: train_loss = 0.0200, validation_loss = 0.0194,\nquality_speed_tradeoff = 1.0213', '\\n', 'Momentum 0.0, Epoch 26: train_loss =\n0.0195, validation_loss = 0.0187, quality_speed_tradeoff = 1.0232', '\\n',\n'Momentum 0.0, Epoch 27: train_loss = 0.0190, validation_loss = 0.0182,\nquality_speed_tradeoff = 1.0234', '\\n', 'Momentum 0.0, Epoch 28: train_loss =\n0.0185, validation_loss = 0.0177, quality_speed_tradeoff = 1.0224', '\\n',\n'Momentum 0.0, Epoch 29: train_loss = 0.0181, validation_loss = 0.0172,\nquality_speed_tradeoff = 1.0206', '\\n', 'Momentum 0.0, Epoch 30: train_loss =\n0.0177, validation_loss = 0.0167, quality_speed_tradeoff = 1.0210', '\\n',\n'Momentum 0.0, Epoch 31: train_loss = 0.0174, validation_loss = 0.0163,\nquality_speed_tradeoff = 1.0215', '\\n', 'Momentum 0.0, Epoch 32: train_loss =\n0.0170, validation_loss = 0.0159, quality_speed_tradeoff = 1.0195', '\\n',\n'Momentum 0.0, Epoch 33: train_loss = 0.0167, validation_loss = 0.0154,\nquality_speed_tradeoff = 1.0224', '\\n', 'Momentum 0.0, Epoch 34: train_loss =\n0.0164, validation_loss = 0.0151, quality_speed_tradeoff = 1.0206', '\\n',\n'Momentum 0.0, Epoch 35: train_loss = 0.0161, validation_loss = 0.0147,\nquality_speed_tradeoff = 1.0195', '\\n', 'Momentum 0.0, Epoch 36: train_loss =\n0.0158, validation_loss = 0.0144, quality_speed_tradeoff = 1.0213', '\\n',\n'Momentum 0.0, Epoch 37: train_loss = 0.0156, validation_loss = 0.0141,\nquality_speed_tradeoff = 1.0187', '\\n', 'Momentum 0.0, Epoch 38: train_loss =\n0.0153, validation_loss = 0.0138, quality_speed_tradeoff = 1.0213', '\\n',\n'Momentum 0.0, Epoch 39: train_loss = 0.0151, validation_loss = 0.0135,\nquality_speed_tradeoff = 1.0220', '\\n', 'Momentum 0.0, Epoch 40: train_loss =\n0.0149, validation_loss = 0.0133, quality_speed_tradeoff = 1.0191', '\\n',\n'Momentum 0.0, Epoch 41: train_loss = 0.0147, validation_loss = 0.0130,\nquality_speed_tradeoff = 1.0188', '\\n', 'Momentum 0.0, Epoch 42: train_loss =\n0.0145, validation_loss = 0.0127, quality_speed_tradeoff = 1.0218', '\\n',\n'Momentum 0.0, Epoch 43: train_loss = 0.0143, validation_loss = 0.0125,\nquality_speed_tradeoff = 1.0199', '\\n', 'Momentum 0.0, Epoch 44: train_loss =\n0.0141, validation_loss = 0.0123, quality_speed_tradeoff = 1.0219', '\\n',\n'Momentum 0.0, Epoch 45: train_loss = 0.0139, validation_loss = 0.0121,\nquality_speed_tradeoff = 1.0205', '\\n', 'Momentum 0.0, Epoch 46: train_loss =\n0.0138, validation_loss = 0.0119, quality_speed_tradeoff = 1.0215', '\\n',\n'Momentum 0.0, Epoch 47: train_loss = 0.0136, validation_loss = 0.0117,\nquality_speed_tradeoff = 1.0206', '\\n', 'Momentum 0.0, Epoch 48: train_loss =\n0.0135, validation_loss = 0.0115, quality_speed_tradeoff = 1.0209', '\\n',\n'Momentum 0.0, Epoch 49: train_loss = 0.0134, validation_loss = 0.0114,\nquality_speed_tradeoff = 1.0191', '\\n', 'Momentum 0.0, Epoch 50: train_loss =\n0.0132, validation_loss = 0.0112, quality_speed_tradeoff = 1.0215', '\\n',\n'Momentum 0.5, Epoch 1: train_loss = 0.1563, validation_loss = 0.0165,\nquality_speed_tradeoff = 0.9547', '\\n', 'Momentum 0.5, Epoch 2: train_loss =\n0.0165, validation_loss = 0.0132, quality_speed_tradeoff = 1.0225', '\\n',\n'Momentum 0.5, Epoch 3: train_loss = 0.0151, validation_loss = 0.0126,\nquality_speed_tradeoff = 1.0248', '\\n', 'Momentum 0.5, Epoch 4: train_loss =\n0.0144, validation_loss = 0.0120, quality_speed_tradeoff = 1.0251', '\\n',\n'Momentum 0.5, Epoch 5: train_loss = 0.0139, validation_loss = 0.0115,\nquality_speed_tradeoff = 1.0281', '\\n', 'Momentum 0.5, Epoch 6: train_loss =\n0.0135, validation_loss = 0.0111, quality_speed_tradeoff = 1.0282', '\\n',\n'Momentum 0.5, Epoch 7: train_loss = 0.0131, validation_loss = 0.0107,\nquality_speed_tradeoff = 1.0208', '\\n', 'Momentum 0.5, Epoch 8: train_loss =\n0.0128, validation_loss = 0.0104, quality_speed_tradeoff = 1.0219', '\\n',\n'Momentum 0.5, Epoch 9: train_loss = 0.0125, validation_loss = 0.0101,\nquality_speed_tradeoff = 1.0201', '\\n', 'Momentum 0.5, Epoch 10: train_loss =\n0.0123, validation_loss = 0.0099, quality_speed_tradeoff = 1.0198', '\\n',\n'Momentum 0.5, Epoch 11: train_loss = 0.0121, validation_loss = 0.0097,\nquality_speed_tradeoff = 1.0241', '\\n', 'Momentum 0.5, Epoch 12: train_loss =\n0.0119, validation_loss = 0.0095, quality_speed_tradeoff = 1.0212', '\\n',\n'Momentum 0.5, Epoch 13: train_loss = 0.0117, validation_loss = 0.0093,\nquality_speed_tradeoff = 1.0228', '\\n', 'Momentum 0.5, Epoch 14: train_loss =\n0.0116, validation_loss = 0.0091, quality_speed_tradeoff = 1.0176', '\\n',\n'Momentum 0.5, Epoch 15: train_loss = 0.0115, validation_loss = 0.0090,\nquality_speed_tradeoff = 1.0144', '\\n', 'Momentum 0.5, Epoch 16: train_loss =\n0.0114, validation_loss = 0.0089, quality_speed_tradeoff = 1.0140', '\\n',\n'Momentum 0.5, Epoch 17: train_loss = 0.0113, validation_loss = 0.0088,\nquality_speed_tradeoff = 1.0118', '\\n', 'Momentum 0.5, Epoch 18: train_loss =\n0.0112, validation_loss = 0.0087, quality_speed_tradeoff = 1.0199', '\\n',\n'Momentum 0.5, Epoch 19: train_loss = 0.0111, validation_loss = 0.0086,\nquality_speed_tradeoff = 1.0217', '\\n', 'Momentum 0.5, Epoch 20: train_loss =\n0.0111, validation_loss = 0.0086, quality_speed_tradeoff = 1.0161', '\\n',\n'Momentum 0.5, Epoch 21: train_loss = 0.0110, validation_loss = 0.0085,\nquality_speed_tradeoff = 1.0187', '\\n', 'Momentum 0.5, Epoch 22: train_loss =\n0.0110, validation_loss = 0.0084, quality_speed_tradeoff = 1.0163', '\\n',\n'Momentum 0.5, Epoch 23: train_loss = 0.0110, validation_loss = 0.0084,\nquality_speed_tradeoff = 1.0147', '\\n', 'Momentum 0.5, Epoch 24: train_loss =\n0.0109, validation_loss = 0.0084, quality_speed_tradeoff = 1.0182', '\\n',\n'Momentum 0.5, Epoch 25: train_loss = 0.0109, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0104', '\\n', 'Momentum 0.5, Epoch 26: train_loss =\n0.0108, validation_loss = 0.0083, quality_speed_tradeoff = 1.0090', '\\n',\n'Momentum 0.5, Epoch 27: train_loss = 0.0108, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0102', '\\n', 'Momentum 0.5, Epoch 28: train_loss =\n0.0108, validation_loss = 0.0082, quality_speed_tradeoff = 1.0109', '\\n',\n'Momentum 0.5, Epoch 29: train_loss = 0.0108, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0098', '\\n', 'Momentum 0.5, Epoch 30: train_loss =\n0.0107, validation_loss = 0.0082, quality_speed_tradeoff = 1.0139', '\\n',\n'Momentum 0.5, Epoch 31: train_loss = 0.0107, validation_loss = 0.0081,\nquality_speed_tradeoff = 1.0124', '\\n', 'Momentum 0.5, Epoch 32: train_loss =\n0.0107, validation_loss = 0.0081, quality_speed_tradeoff = 1.0131', '\\n',\n'Momentum 0.5, Epoch 33: train_loss = 0.0107, validation_loss = 0.0081,\nquality_speed_tradeoff = 1.0131', '\\n', 'Momentum 0.5, Epoch 34: train_loss =\n0.0106, validation_loss = 0.0081, quality_speed_tradeoff = 1.0148', '\\n',\n'Momentum 0.5, Epoch 35: train_loss = 0.0106, validation_loss = 0.0081,\nquality_speed_tradeoff = 1.0141', '\\n', 'Momentum 0.5, Epoch 36: train_loss =\n0.0106, validation_loss = 0.0080, quality_speed_tradeoff = 1.0166', '\\n',\n'Momentum 0.5, Epoch 37: train_loss = 0.0106, validation_loss = 0.0080,\nquality_speed_tradeoff = 1.0132', '\\n', 'Momentum 0.5, Epoch 38: train_loss =\n0.0106, validation_loss = 0.0081, quality_speed_tradeoff = 1.0063', '\\n',\n'Momentum 0.5, Epoch 39: train_loss = 0.0106, validation_loss = 0.0080,\nquality_speed_tradeoff = 1.0117', '\\n', 'Momentum 0.5, Epoch 40: train_loss =\n0.0106, validation_loss = 0.0080, quality_speed_tradeoff = 1.0103', '\\n',\n'Momentum 0.5, Epoch 41: train_loss = 0.0106, validation_loss = 0.0080,\nquality_speed_tradeoff = 1.0082', '\\n', 'Momentum 0.5, Epoch 42: train_loss =\n0.0106, validation_loss = 0.0080, quality_speed_tradeoff = 1.0089', '\\n',\n'Momentum 0.5, Epoch 43: train_loss = 0.0106, validation_loss = 0.0080,\nquality_speed_tradeoff = 1.0113', '\\n', 'Momentum 0.5, Epoch 44: train_loss =\n0.0105, validation_loss = 0.0080, quality_speed_tradeoff = 1.0129', '\\n',\n'Momentum 0.5, Epoch 45: train_loss = 0.0106, validation_loss = 0.0080,\nquality_speed_tradeoff = 1.0108', '\\n', 'Momentum 0.5, Epoch 46: train_loss =\n0.0105, validation_loss = 0.0080, quality_speed_tradeoff = 1.0040', '\\n',\n'Momentum 0.5, Epoch 47: train_loss = 0.0106, validation_loss = 0.0080,\nquality_speed_tradeoff = 1.0125', '\\n', 'Momentum 0.5, Epoch 48: train_loss =\n0.0106, validation_loss = 0.0080, quality_speed_tradeoff = 1.0099', '\\n',\n'Momentum 0.5, Epoch 49: train_loss = 0.0105, validation_loss = 0.0079,\nquality_speed_tradeoff = 1.0138', '\\n', 'Momentum 0.5, Epoch 50: train_loss =\n0.0105, validation_loss = 0.0079, quality_speed_tradeoff = 1.0118', '\\n',\n'Momentum 0.9, Epoch 1: train_loss = 0.1753, validation_loss = 0.0606,\nquality_speed_tradeoff = 0.9661', '\\n', 'Momentum 0.9, Epoch 2: train_loss =\n0.0489, validation_loss = 0.0335, quality_speed_tradeoff = 1.0884', '\\n',\n'Momentum 0.9, Epoch 3: train_loss = 0.0256, validation_loss = 0.0204,\nquality_speed_tradeoff = 1.0611', '\\n', 'Momentum 0.9, Epoch 4: train_loss =\n0.0183, validation_loss = 0.0145, quality_speed_tradeoff = 1.0430', '\\n',\n'Momentum 0.9, Epoch 5: train_loss = 0.0147, validation_loss = 0.0116,\nquality_speed_tradeoff = 1.0302', '\\n', 'Momentum 0.9, Epoch 6: train_loss =\n0.0128, validation_loss = 0.0101, quality_speed_tradeoff = 1.0306', '\\n',\n'Momentum 0.9, Epoch 7: train_loss = 0.0120, validation_loss = 0.0093,\nquality_speed_tradeoff = 1.0113', '\\n', 'Momentum 0.9, Epoch 8: train_loss =\n0.0115, validation_loss = 0.0090, quality_speed_tradeoff = 1.0445', '\\n',\n'Momentum 0.9, Epoch 9: train_loss = 0.0112, validation_loss = 0.0084,\nquality_speed_tradeoff = 1.0203', '\\n', 'Momentum 0.9, Epoch 10: train_loss =\n0.0109, validation_loss = 0.0082, quality_speed_tradeoff = 1.0125', '\\n',\n'Momentum 0.9, Epoch 11: train_loss = 0.0109, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0050', '\\n', 'Momentum 0.9, Epoch 12: train_loss =\n0.0108, validation_loss = 0.0080, quality_speed_tradeoff = 1.0174', '\\n',\n'Momentum 0.9, Epoch 13: train_loss = 0.0106, validation_loss = 0.0081,\nquality_speed_tradeoff = 1.0008', '\\n', 'Momentum 0.9, Epoch 14: train_loss =\n0.0106, validation_loss = 0.0080, quality_speed_tradeoff = 1.0077', '\\n',\n'Momentum 0.9, Epoch 15: train_loss = 0.0106, validation_loss = 0.0081,\nquality_speed_tradeoff = 0.9962', '\\n', 'Momentum 0.9, Epoch 16: train_loss =\n0.0106, validation_loss = 0.0081, quality_speed_tradeoff = 0.9986', '\\n',\n'Momentum 0.9, Epoch 17: train_loss = 0.0106, validation_loss = 0.0079,\nquality_speed_tradeoff = 1.0076', '\\n', 'Momentum 0.9, Epoch 18: train_loss =\n0.0106, validation_loss = 0.0079, quality_speed_tradeoff = 1.0125', '\\n',\n'Momentum 0.9, Epoch 19: train_loss = 0.0106, validation_loss = 0.0081,\nquality_speed_tradeoff = 1.0309', '\\n', 'Momentum 0.9, Epoch 20: train_loss =\n0.0107, validation_loss = 0.0079, quality_speed_tradeoff = 1.0190', '\\n',\n'Momentum 0.9, Epoch 21: train_loss = 0.0106, validation_loss = 0.0080,\nquality_speed_tradeoff = 0.9996', '\\n', 'Momentum 0.9, Epoch 22: train_loss =\n0.0105, validation_loss = 0.0079, quality_speed_tradeoff = 1.0145', '\\n',\n'Momentum 0.9, Epoch 23: train_loss = 0.0105, validation_loss = 0.0079,\nquality_speed_tradeoff = 1.0153', '\\n', 'Momentum 0.9, Epoch 24: train_loss =\n0.0105, validation_loss = 0.0079, quality_speed_tradeoff = 1.0071', '\\n',\n'Momentum 0.9, Epoch 25: train_loss = 0.0105, validation_loss = 0.0080,\nquality_speed_tradeoff = 1.0036', '\\n', 'Momentum 0.9, Epoch 26: train_loss =\n0.0105, validation_loss = 0.0080, quality_speed_tradeoff = 1.0042', '\\n',\n'Momentum 0.9, Epoch 27: train_loss = 0.0106, validation_loss = 0.0081,\nquality_speed_tradeoff = 0.9955', '\\n', 'Momentum 0.9, Epoch 28: train_loss =\n0.0107, validation_loss = 0.0084, quality_speed_tradeoff = 0.9843', '\\n',\n'Momentum 0.9, Epoch 29: train_loss = 0.0106, validation_loss = 0.0083,\nquality_speed_tradeoff = 0.9877', '\\n', 'Momentum 0.9, Epoch 30: train_loss =\n0.0106, validation_loss = 0.0080, quality_speed_tradeoff = 1.0171', '\\n',\n'Momentum 0.9, Epoch 31: train_loss = 0.0105, validation_loss = 0.0079,\nquality_speed_tradeoff = 1.0092', '\\n', 'Momentum 0.9, Epoch 32: train_loss =\n0.0106, validation_loss = 0.0079, quality_speed_tradeoff = 1.0057', '\\n',\n'Momentum 0.9, Epoch 33: train_loss = 0.0106, validation_loss = 0.0080,\nquality_speed_tradeoff = 1.0032', '\\n', 'Momentum 0.9, Epoch 34: train_loss =\n0.0105, validation_loss = 0.0081, quality_speed_tradeoff = 0.9964', '\\n',\n'Momentum 0.9, Epoch 35: train_loss = 0.0105, validation_loss = 0.0080,\nquality_speed_tradeoff = 1.0236', '\\n', 'Momentum 0.9, Epoch 36: train_loss =\n0.0105, validation_loss = 0.0079, quality_speed_tradeoff = 1.0151', '\\n',\n'Momentum 0.9, Epoch 37: train_loss = 0.0106, validation_loss = 0.0079,\nquality_speed_tradeoff = 1.0184', '\\n', 'Momentum 0.9, Epoch 38: train_loss =\n0.0105, validation_loss = 0.0079, quality_speed_tradeoff = 1.0099', '\\n',\n'Momentum 0.9, Epoch 39: train_loss = 0.0105, validation_loss = 0.0081,\nquality_speed_tradeoff = 0.9934', '\\n', 'Momentum 0.9, Epoch 40: train_loss =\n0.0106, validation_loss = 0.0080, quality_speed_tradeoff = 1.0037', '\\n',\n'Momentum 0.9, Epoch 41: train_loss = 0.0105, validation_loss = 0.0081,\nquality_speed_tradeoff = 0.9960', '\\n', 'Momentum 0.9, Epoch 42: train_loss =\n0.0107, validation_loss = 0.0080, quality_speed_tradeoff = 1.0024', '\\n',\n'Momentum 0.9, Epoch 43: train_loss = 0.0105, validation_loss = 0.0081,\nquality_speed_tradeoff = 0.9934', '\\n', 'Momentum 0.9, Epoch 44: train_loss =\n0.0106, validation_loss = 0.0080, quality_speed_tradeoff = 1.0029', '\\n',\n'Momentum 0.9, Epoch 45: train_loss = 0.0106, validation_loss = 0.0080,\nquality_speed_tradeoff = 0.9999', '\\n', 'Momentum 0.9, Epoch 46: train_loss =\n0.0106, validation_loss = 0.0079, quality_speed_tradeoff = 1.0150', '\\n',\n'Momentum 0.9, Epoch 47: train_loss = 0.0106, validation_loss = 0.0079,\nquality_speed_tradeoff = 1.0182', '\\n', 'Momentum 0.9, Epoch 48: train_loss =\n0.0105, validation_loss = 0.0080, quality_speed_tradeoff = 1.0178', '\\n',\n'Momentum 0.9, Epoch 49: train_loss = 0.0106, validation_loss = 0.0079,\nquality_speed_tradeoff = 1.0192', '\\n', 'Momentum 0.9, Epoch 50: train_loss =\n0.0105, validation_loss = 0.0079, quality_speed_tradeoff = 1.0172', '\\n',\n'Execution time: 3 seconds seconds (time limit is an hour).']", "['Using device: cpu', '\\n', 'Momentum 0.0, Epoch 1: train_loss = 0.6131,\nvalidation_loss = 0.2086, quality_speed_tradeoff = 0.5343', '\\n', 'Momentum 0.0,\nEpoch 2: train_loss = 0.1020, validation_loss = 0.0710, quality_speed_tradeoff =\n0.8684', '\\n', 'Momentum 0.0, Epoch 3: train_loss = 0.0509, validation_loss =\n0.0524, quality_speed_tradeoff = 0.9699', '\\n', 'Momentum 0.0, Epoch 4:\ntrain_loss = 0.0441, validation_loss = 0.0473, quality_speed_tradeoff = 1.0022',\n'\\n', 'Momentum 0.0, Epoch 5: train_loss = 0.0416, validation_loss = 0.0444,\nquality_speed_tradeoff = 1.0148', '\\n', 'Momentum 0.0, Epoch 6: train_loss =\n0.0396, validation_loss = 0.0421, quality_speed_tradeoff = 1.0166', '\\n',\n'Momentum 0.0, Epoch 7: train_loss = 0.0378, validation_loss = 0.0399,\nquality_speed_tradeoff = 1.0225', '\\n', 'Momentum 0.0, Epoch 8: train_loss =\n0.0362, validation_loss = 0.0381, quality_speed_tradeoff = 1.0200', '\\n',\n'Momentum 0.0, Epoch 9: train_loss = 0.0346, validation_loss = 0.0364,\nquality_speed_tradeoff = 1.0173', '\\n', 'Momentum 0.0, Epoch 10: train_loss =\n0.0332, validation_loss = 0.0348, quality_speed_tradeoff = 1.0171', '\\n',\n'Momentum 0.0, Epoch 11: train_loss = 0.0318, validation_loss = 0.0331,\nquality_speed_tradeoff = 1.0202', '\\n', 'Momentum 0.0, Epoch 12: train_loss =\n0.0305, validation_loss = 0.0316, quality_speed_tradeoff = 1.0224', '\\n',\n'Momentum 0.0, Epoch 13: train_loss = 0.0294, validation_loss = 0.0303,\nquality_speed_tradeoff = 1.0205', '\\n', 'Momentum 0.0, Epoch 14: train_loss =\n0.0283, validation_loss = 0.0291, quality_speed_tradeoff = 1.0206', '\\n',\n'Momentum 0.0, Epoch 15: train_loss = 0.0272, validation_loss = 0.0279,\nquality_speed_tradeoff = 1.0203', '\\n', 'Momentum 0.0, Epoch 16: train_loss =\n0.0263, validation_loss = 0.0267, quality_speed_tradeoff = 1.0229', '\\n',\n'Momentum 0.0, Epoch 17: train_loss = 0.0254, validation_loss = 0.0257,\nquality_speed_tradeoff = 1.0214', '\\n', 'Momentum 0.0, Epoch 18: train_loss =\n0.0245, validation_loss = 0.0247, quality_speed_tradeoff = 1.0221', '\\n',\n'Momentum 0.0, Epoch 19: train_loss = 0.0237, validation_loss = 0.0238,\nquality_speed_tradeoff = 1.0205', '\\n', 'Momentum 0.0, Epoch 20: train_loss =\n0.0230, validation_loss = 0.0230, quality_speed_tradeoff = 1.0199', '\\n',\n'Momentum 0.0, Epoch 21: train_loss = 0.0223, validation_loss = 0.0222,\nquality_speed_tradeoff = 1.0203', '\\n', 'Momentum 0.0, Epoch 22: train_loss =\n0.0217, validation_loss = 0.0214, quality_speed_tradeoff = 1.0182', '\\n',\n'Momentum 0.0, Epoch 23: train_loss = 0.0211, validation_loss = 0.0207,\nquality_speed_tradeoff = 1.0191', '\\n', 'Momentum 0.0, Epoch 24: train_loss =\n0.0205, validation_loss = 0.0200, quality_speed_tradeoff = 1.0210', '\\n',\n'Momentum 0.0, Epoch 25: train_loss = 0.0200, validation_loss = 0.0194,\nquality_speed_tradeoff = 1.0213', '\\n', 'Momentum 0.0, Epoch 26: train_loss =\n0.0195, validation_loss = 0.0187, quality_speed_tradeoff = 1.0232', '\\n',\n'Momentum 0.0, Epoch 27: train_loss = 0.0190, validation_loss = 0.0182,\nquality_speed_tradeoff = 1.0234', '\\n', 'Momentum 0.0, Epoch 28: train_loss =\n0.0185, validation_loss = 0.0177, quality_speed_tradeoff = 1.0224', '\\n',\n'Momentum 0.0, Epoch 29: train_loss = 0.0181, validation_loss = 0.0172,\nquality_speed_tradeoff = 1.0206', '\\n', 'Momentum 0.0, Epoch 30: train_loss =\n0.0177, validation_loss = 0.0167, quality_speed_tradeoff = 1.0210', '\\n',\n'Momentum 0.0, Epoch 31: train_loss = 0.0174, validation_loss = 0.0163,\nquality_speed_tradeoff = 1.0215', '\\n', 'Momentum 0.0, Epoch 32: train_loss =\n0.0170, validation_loss = 0.0159, quality_speed_tradeoff = 1.0195', '\\n',\n'Momentum 0.0, Epoch 33: train_loss = 0.0167, validation_loss = 0.0154,\nquality_speed_tradeoff = 1.0224', '\\n', 'Momentum 0.0, Epoch 34: train_loss =\n0.0164, validation_loss = 0.0151, quality_speed_tradeoff = 1.0206', '\\n',\n'Momentum 0.0, Epoch 35: train_loss = 0.0161, validation_loss = 0.0147,\nquality_speed_tradeoff = 1.0195', '\\n', 'Momentum 0.0, Epoch 36: train_loss =\n0.0158, validation_loss = 0.0144, quality_speed_tradeoff = 1.0213', '\\n',\n'Momentum 0.0, Epoch 37: train_loss = 0.0156, validation_loss = 0.0141,\nquality_speed_tradeoff = 1.0187', '\\n', 'Momentum 0.0, Epoch 38: train_loss =\n0.0153, validation_loss = 0.0138, quality_speed_tradeoff = 1.0213', '\\n',\n'Momentum 0.0, Epoch 39: train_loss = 0.0151, validation_loss = 0.0135,\nquality_speed_tradeoff = 1.0220', '\\n', 'Momentum 0.0, Epoch 40: train_loss =\n0.0149, validation_loss = 0.0133, quality_speed_tradeoff = 1.0191', '\\n',\n'Momentum 0.0, Epoch 41: train_loss = 0.0147, validation_loss = 0.0130,\nquality_speed_tradeoff = 1.0188', '\\n', 'Momentum 0.0, Epoch 42: train_loss =\n0.0145, validation_loss = 0.0127, quality_speed_tradeoff = 1.0218', '\\n',\n'Momentum 0.0, Epoch 43: train_loss = 0.0143, validation_loss = 0.0125,\nquality_speed_tradeoff = 1.0199', '\\n', 'Momentum 0.0, Epoch 44: train_loss =\n0.0141, validation_loss = 0.0123, quality_speed_tradeoff = 1.0219', '\\n',\n'Momentum 0.0, Epoch 45: train_loss = 0.0139, validation_loss = 0.0121,\nquality_speed_tradeoff = 1.0205', '\\n', 'Momentum 0.0, Epoch 46: train_loss =\n0.0138, validation_loss = 0.0119, quality_speed_tradeoff = 1.0215', '\\n',\n'Momentum 0.0, Epoch 47: train_loss = 0.0136, validation_loss = 0.0117,\nquality_speed_tradeoff = 1.0206', '\\n', 'Momentum 0.0, Epoch 48: train_loss =\n0.0135, validation_loss = 0.0115, quality_speed_tradeoff = 1.0209', '\\n',\n'Momentum 0.0, Epoch 49: train_loss = 0.0134, validation_loss = 0.0114,\nquality_speed_tradeoff = 1.0191', '\\n', 'Momentum 0.0, Epoch 50: train_loss =\n0.0132, validation_loss = 0.0112, quality_speed_tradeoff = 1.0215', '\\n',\n'Momentum 0.5, Epoch 1: train_loss = 0.1563, validation_loss = 0.0165,\nquality_speed_tradeoff = 0.9547', '\\n', 'Momentum 0.5, Epoch 2: train_loss =\n0.0165, validation_loss = 0.0132, quality_speed_tradeoff = 1.0225', '\\n',\n'Momentum 0.5, Epoch 3: train_loss = 0.0151, validation_loss = 0.0126,\nquality_speed_tradeoff = 1.0248', '\\n', 'Momentum 0.5, Epoch 4: train_loss =\n0.0144, validation_loss = 0.0120, quality_speed_tradeoff = 1.0251', '\\n',\n'Momentum 0.5, Epoch 5: train_loss = 0.0139, validation_loss = 0.0115,\nquality_speed_tradeoff = 1.0281', '\\n', 'Momentum 0.5, Epoch 6: train_loss =\n0.0135, validation_loss = 0.0111, quality_speed_tradeoff = 1.0282', '\\n',\n'Momentum 0.5, Epoch 7: train_loss = 0.0131, validation_loss = 0.0107,\nquality_speed_tradeoff = 1.0208', '\\n', 'Momentum 0.5, Epoch 8: train_loss =\n0.0128, validation_loss = 0.0104, quality_speed_tradeoff = 1.0219', '\\n',\n'Momentum 0.5, Epoch 9: train_loss = 0.0125, validation_loss = 0.0101,\nquality_speed_tradeoff = 1.0201', '\\n', 'Momentum 0.5, Epoch 10: train_loss =\n0.0123, validation_loss = 0.0099, quality_speed_tradeoff = 1.0198', '\\n',\n'Momentum 0.5, Epoch 11: train_loss = 0.0121, validation_loss = 0.0097,\nquality_speed_tradeoff = 1.0241', '\\n', 'Momentum 0.5, Epoch 12: train_loss =\n0.0119, validation_loss = 0.0095, quality_speed_tradeoff = 1.0212', '\\n',\n'Momentum 0.5, Epoch 13: train_loss = 0.0117, validation_loss = 0.0093,\nquality_speed_tradeoff = 1.0228', '\\n', 'Momentum 0.5, Epoch 14: train_loss =\n0.0116, validation_loss = 0.0091, quality_speed_tradeoff = 1.0176', '\\n',\n'Momentum 0.5, Epoch 15: train_loss = 0.0115, validation_loss = 0.0090,\nquality_speed_tradeoff = 1.0144', '\\n', 'Momentum 0.5, Epoch 16: train_loss =\n0.0114, validation_loss = 0.0089, quality_speed_tradeoff = 1.0140', '\\n',\n'Momentum 0.5, Epoch 17: train_loss = 0.0113, validation_loss = 0.0088,\nquality_speed_tradeoff = 1.0118', '\\n', 'Momentum 0.5, Epoch 18: train_loss =\n0.0112, validation_loss = 0.0087, quality_speed_tradeoff = 1.0199', '\\n',\n'Momentum 0.5, Epoch 19: train_loss = 0.0111, validation_loss = 0.0086,\nquality_speed_tradeoff = 1.0217', '\\n', 'Momentum 0.5, Epoch 20: train_loss =\n0.0111, validation_loss = 0.0086, quality_speed_tradeoff = 1.0161', '\\n',\n'Momentum 0.5, Epoch 21: train_loss = 0.0110, validation_loss = 0.0085,\nquality_speed_tradeoff = 1.0187', '\\n', 'Momentum 0.5, Epoch 22: train_loss =\n0.0110, validation_loss = 0.0084, quality_speed_tradeoff = 1.0163', '\\n',\n'Momentum 0.5, Epoch 23: train_loss = 0.0110, validation_loss = 0.0084,\nquality_speed_tradeoff = 1.0147', '\\n', 'Momentum 0.5, Epoch 24: train_loss =\n0.0109, validation_loss = 0.0084, quality_speed_tradeoff = 1.0182', '\\n',\n'Momentum 0.5, Epoch 25: train_loss = 0.0109, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0104', '\\n', 'Momentum 0.5, Epoch 26: train_loss =\n0.0108, validation_loss = 0.0083, quality_speed_tradeoff = 1.0090', '\\n',\n'Momentum 0.5, Epoch 27: train_loss = 0.0108, validation_loss = 0.0083,\nquality_speed_tradeoff = 1.0102', '\\n', 'Momentum 0.5, Epoch 28: train_loss =\n0.0108, validation_loss = 0.0082, quality_speed_tradeoff = 1.0109', '\\n',\n'Momentum 0.5, Epoch 29: train_loss = 0.0108, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0098', '\\n', 'Momentum 0.5, Epoch 30: train_loss =\n0.0107, validation_loss = 0.0082, quality_speed_tradeoff = 1.0139', '\\n',\n'Momentum 0.5, Epoch 31: train_loss = 0.0107, validation_loss = 0.0081,\nquality_speed_tradeoff = 1.0124', '\\n', 'Momentum 0.5, Epoch 32: train_loss =\n0.0107, validation_loss = 0.0081, quality_speed_tradeoff = 1.0131', '\\n',\n'Momentum 0.5, Epoch 33: train_loss = 0.0107, validation_loss = 0.0081,\nquality_speed_tradeoff = 1.0131', '\\n', 'Momentum 0.5, Epoch 34: train_loss =\n0.0106, validation_loss = 0.0081, quality_speed_tradeoff = 1.0148', '\\n',\n'Momentum 0.5, Epoch 35: train_loss = 0.0106, validation_loss = 0.0081,\nquality_speed_tradeoff = 1.0141', '\\n', 'Momentum 0.5, Epoch 36: train_loss =\n0.0106, validation_loss = 0.0080, quality_speed_tradeoff = 1.0166', '\\n',\n'Momentum 0.5, Epoch 37: train_loss = 0.0106, validation_loss = 0.0080,\nquality_speed_tradeoff = 1.0132', '\\n', 'Momentum 0.5, Epoch 38: train_loss =\n0.0106, validation_loss = 0.0081, quality_speed_tradeoff = 1.0063', '\\n',\n'Momentum 0.5, Epoch 39: train_loss = 0.0106, validation_loss = 0.0080,\nquality_speed_tradeoff = 1.0117', '\\n', 'Momentum 0.5, Epoch 40: train_loss =\n0.0106, validation_loss = 0.0080, quality_speed_tradeoff = 1.0103', '\\n',\n'Momentum 0.5, Epoch 41: train_loss = 0.0106, validation_loss = 0.0080,\nquality_speed_tradeoff = 1.0082', '\\n', 'Momentum 0.5, Epoch 42: train_loss =\n0.0106, validation_loss = 0.0080, quality_speed_tradeoff = 1.0089', '\\n',\n'Momentum 0.5, Epoch 43: train_loss = 0.0106, validation_loss = 0.0080,\nquality_speed_tradeoff = 1.0113', '\\n', 'Momentum 0.5, Epoch 44: train_loss =\n0.0105, validation_loss = 0.0080, quality_speed_tradeoff = 1.0129', '\\n',\n'Momentum 0.5, Epoch 45: train_loss = 0.0106, validation_loss = 0.0080,\nquality_speed_tradeoff = 1.0108', '\\n', 'Momentum 0.5, Epoch 46: train_loss =\n0.0105, validation_loss = 0.0080, quality_speed_tradeoff = 1.0040', '\\n',\n'Momentum 0.5, Epoch 47: train_loss = 0.0106, validation_loss = 0.0080,\nquality_speed_tradeoff = 1.0125', '\\n', 'Momentum 0.5, Epoch 48: train_loss =\n0.0106, validation_loss = 0.0080, quality_speed_tradeoff = 1.0099', '\\n',\n'Momentum 0.5, Epoch 49: train_loss = 0.0105, validation_loss = 0.0079,\nquality_speed_tradeoff = 1.0138', '\\n', 'Momentum 0.5, Epoch 50: train_loss =\n0.0105, validation_loss = 0.0079, quality_speed_tradeoff = 1.0118', '\\n',\n'Momentum 0.9, Epoch 1: train_loss = 0.1753, validation_loss = 0.0606,\nquality_speed_tradeoff = 0.9661', '\\n', 'Momentum 0.9, Epoch 2: train_loss =\n0.0489, validation_loss = 0.0335, quality_speed_tradeoff = 1.0884', '\\n',\n'Momentum 0.9, Epoch 3: train_loss = 0.0256, validation_loss = 0.0204,\nquality_speed_tradeoff = 1.0611', '\\n', 'Momentum 0.9, Epoch 4: train_loss =\n0.0183, validation_loss = 0.0145, quality_speed_tradeoff = 1.0430', '\\n',\n'Momentum 0.9, Epoch 5: train_loss = 0.0147, validation_loss = 0.0116,\nquality_speed_tradeoff = 1.0302', '\\n', 'Momentum 0.9, Epoch 6: train_loss =\n0.0128, validation_loss = 0.0101, quality_speed_tradeoff = 1.0306', '\\n',\n'Momentum 0.9, Epoch 7: train_loss = 0.0120, validation_loss = 0.0093,\nquality_speed_tradeoff = 1.0113', '\\n', 'Momentum 0.9, Epoch 8: train_loss =\n0.0115, validation_loss = 0.0090, quality_speed_tradeoff = 1.0445', '\\n',\n'Momentum 0.9, Epoch 9: train_loss = 0.0112, validation_loss = 0.0084,\nquality_speed_tradeoff = 1.0203', '\\n', 'Momentum 0.9, Epoch 10: train_loss =\n0.0109, validation_loss = 0.0082, quality_speed_tradeoff = 1.0125', '\\n',\n'Momentum 0.9, Epoch 11: train_loss = 0.0109, validation_loss = 0.0082,\nquality_speed_tradeoff = 1.0050', '\\n', 'Momentum 0.9, Epoch 12: train_loss =\n0.0108, validation_loss = 0.0080, quality_speed_tradeoff = 1.0174', '\\n',\n'Momentum 0.9, Epoch 13: train_loss = 0.0106, validation_loss = 0.0081,\nquality_speed_tradeoff = 1.0008', '\\n', 'Momentum 0.9, Epoch 14: train_loss =\n0.0106, validation_loss = 0.0080, quality_speed_tradeoff = 1.0077', '\\n',\n'Momentum 0.9, Epoch 15: train_loss = 0.0106, validation_loss = 0.0081,\nquality_speed_tradeoff = 0.9962', '\\n', 'Momentum 0.9, Epoch 16: train_loss =\n0.0106, validation_loss = 0.0081, quality_speed_tradeoff = 0.9986', '\\n',\n'Momentum 0.9, Epoch 17: train_loss = 0.0106, validation_loss = 0.0079,\nquality_speed_tradeoff = 1.0076', '\\n', 'Momentum 0.9, Epoch 18: train_loss =\n0.0106, validation_loss = 0.0079, quality_speed_tradeoff = 1.0125', '\\n',\n'Momentum 0.9, Epoch 19: train_loss = 0.0106, validation_loss = 0.0081,\nquality_speed_tradeoff = 1.0309', '\\n', 'Momentum 0.9, Epoch 20: train_loss =\n0.0107, validation_loss = 0.0079, quality_speed_tradeoff = 1.0190', '\\n',\n'Momentum 0.9, Epoch 21: train_loss = 0.0106, validation_loss = 0.0080,\nquality_speed_tradeoff = 0.9996', '\\n', 'Momentum 0.9, Epoch 22: train_loss =\n0.0105, validation_loss = 0.0079, quality_speed_tradeoff = 1.0145', '\\n',\n'Momentum 0.9, Epoch 23: train_loss = 0.0105, validation_loss = 0.0079,\nquality_speed_tradeoff = 1.0153', '\\n', 'Momentum 0.9, Epoch 24: train_loss =\n0.0105, validation_loss = 0.0079, quality_speed_tradeoff = 1.0071', '\\n',\n'Momentum 0.9, Epoch 25: train_loss = 0.0105, validation_loss = 0.0080,\nquality_speed_tradeoff = 1.0036', '\\n', 'Momentum 0.9, Epoch 26: train_loss =\n0.0105, validation_loss = 0.0080, quality_speed_tradeoff = 1.0042', '\\n',\n'Momentum 0.9, Epoch 27: train_loss = 0.0106, validation_loss = 0.0081,\nquality_speed_tradeoff = 0.9955', '\\n', 'Momentum 0.9, Epoch 28: train_loss =\n0.0107, validation_loss = 0.0084, quality_speed_tradeoff = 0.9843', '\\n',\n'Momentum 0.9, Epoch 29: train_loss = 0.0106, validation_loss = 0.0083,\nquality_speed_tradeoff = 0.9877', '\\n', 'Momentum 0.9, Epoch 30: train_loss =\n0.0106, validation_loss = 0.0080, quality_speed_tradeoff = 1.0171', '\\n',\n'Momentum 0.9, Epoch 31: train_loss = 0.0105, validation_loss = 0.0079,\nquality_speed_tradeoff = 1.0092', '\\n', 'Momentum 0.9, Epoch 32: train_loss =\n0.0106, validation_loss = 0.0079, quality_speed_tradeoff = 1.0057', '\\n',\n'Momentum 0.9, Epoch 33: train_loss = 0.0106, validation_loss = 0.0080,\nquality_speed_tradeoff = 1.0032', '\\n', 'Momentum 0.9, Epoch 34: train_loss =\n0.0105, validation_loss = 0.0081, quality_speed_tradeoff = 0.9964', '\\n',\n'Momentum 0.9, Epoch 35: train_loss = 0.0105, validation_loss = 0.0080,\nquality_speed_tradeoff = 1.0236', '\\n', 'Momentum 0.9, Epoch 36: train_loss =\n0.0105, validation_loss = 0.0079, quality_speed_tradeoff = 1.0151', '\\n',\n'Momentum 0.9, Epoch 37: train_loss = 0.0106, validation_loss = 0.0079,\nquality_speed_tradeoff = 1.0184', '\\n', 'Momentum 0.9, Epoch 38: train_loss =\n0.0105, validation_loss = 0.0079, quality_speed_tradeoff = 1.0099', '\\n',\n'Momentum 0.9, Epoch 39: train_loss = 0.0105, validation_loss = 0.0081,\nquality_speed_tradeoff = 0.9934', '\\n', 'Momentum 0.9, Epoch 40: train_loss =\n0.0106, validation_loss = 0.0080, quality_speed_tradeoff = 1.0037', '\\n',\n'Momentum 0.9, Epoch 41: train_loss = 0.0105, validation_loss = 0.0081,\nquality_speed_tradeoff = 0.9960', '\\n', 'Momentum 0.9, Epoch 42: train_loss =\n0.0107, validation_loss = 0.0080, quality_speed_tradeoff = 1.0024', '\\n',\n'Momentum 0.9, Epoch 43: train_loss = 0.0105, validation_loss = 0.0081,\nquality_speed_tradeoff = 0.9934', '\\n', 'Momentum 0.9, Epoch 44: train_loss =\n0.0106, validation_loss = 0.0080, quality_speed_tradeoff = 1.0029', '\\n',\n'Momentum 0.9, Epoch 45: train_loss = 0.0106, validation_loss = 0.0080,\nquality_speed_tradeoff = 0.9999', '\\n', 'Momentum 0.9, Epoch 46: train_loss =\n0.0106, validation_loss = 0.0079, quality_speed_tradeoff = 1.0150', '\\n',\n'Momentum 0.9, Epoch 47: train_loss = 0.0106, validation_loss = 0.0079,\nquality_speed_tradeoff = 1.0182', '\\n', 'Momentum 0.9, Epoch 48: train_loss =\n0.0105, validation_loss = 0.0080, quality_speed_tradeoff = 1.0178', '\\n',\n'Momentum 0.9, Epoch 49: train_loss = 0.0106, validation_loss = 0.0079,\nquality_speed_tradeoff = 1.0192', '\\n', 'Momentum 0.9, Epoch 50: train_loss =\n0.0105, validation_loss = 0.0079, quality_speed_tradeoff = 1.0172', '\\n',\n'Execution time: 3 seconds seconds (time limit is an hour).']"], "analysis": ["", "", "", "", "", "", "", "", ""], "exc_type": [null, null, null, null, null, null, null, null, null], "exc_info": [null, null, null, null, null, null, null, null, null], "exc_stack": [null, null, null, null, null, null, null, null, null], "exp_name": "0-run", "metrics": [{"metric_names": [{"metric_name": "train loss", "lower_is_better": true, "description": "Final training loss of the model", "data": [{"dataset_name": "Quality Route", "final_value": 0.0099, "best_value": 0.0099}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "Final validation loss of the model", "data": [{"dataset_name": "Quality Route", "final_value": 0.0083, "best_value": 0.0083}]}, {"metric_name": "quality speed tradeoff", "lower_is_better": false, "description": "Final quality-speed tradeoff metric", "data": [{"dataset_name": "Quality Route", "final_value": 1.0348, "best_value": 1.0348}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training, indicating how well the model is learning.", "data": [{"dataset_name": "Quality Route", "final_value": 0.0138, "best_value": 0.0138}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value on the validation set, indicating how well the model generalizes to unseen data.", "data": [{"dataset_name": "Quality Route", "final_value": 0.0115, "best_value": 0.0115}]}, {"metric_name": "validation quality-speed tradeoff", "lower_is_better": false, "description": "A measure of the tradeoff between quality and speed on the validation set, where higher values indicate better performance.", "data": [{"dataset_name": "Quality Route", "final_value": 1.1238, "best_value": 1.1238}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The final training loss value after training is complete.", "data": [{"dataset_name": "batch_size_16", "final_value": 0.0102, "best_value": 0.0102}, {"dataset_name": "batch_size_32", "final_value": 0.0097, "best_value": 0.0097}, {"dataset_name": "batch_size_64", "final_value": 0.0097, "best_value": 0.0097}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The final validation loss value after training is complete.", "data": [{"dataset_name": "batch_size_16", "final_value": 0.0094, "best_value": 0.0094}, {"dataset_name": "batch_size_32", "final_value": 0.0083, "best_value": 0.0083}, {"dataset_name": "batch_size_64", "final_value": 0.0089, "best_value": 0.0089}]}, {"metric_name": "quality-speed tradeoff", "lower_is_better": false, "description": "The final quality-speed tradeoff value after training is complete.", "data": [{"dataset_name": "batch_size_16", "final_value": 1.0976, "best_value": 1.0976}, {"dataset_name": "batch_size_32", "final_value": 1.0357, "best_value": 1.0357}, {"dataset_name": "batch_size_64", "final_value": 1.0586, "best_value": 1.0586}]}]}, {"metric_names": [{"metric_name": "final training loss", "lower_is_better": true, "description": "The final loss value from the training phase, indicating how well the model learned from the training data.", "data": [{"dataset_name": "Quality Route", "final_value": 0.0098, "best_value": 0.0098}]}, {"metric_name": "final validation loss", "lower_is_better": true, "description": "The final loss value from the validation phase, indicating how well the model performed on unseen data.", "data": [{"dataset_name": "Quality Route", "final_value": 0.0082, "best_value": 0.0082}]}, {"metric_name": "final validation metric (Quality-Speed Tradeoff)", "lower_is_better": false, "description": "The final value of the Quality-Speed Tradeoff metric, indicating the balance between quality and speed of the model.", "data": [{"dataset_name": "Quality Route", "final_value": 1.043, "best_value": 1.043}]}]}, {"metric_names": [{"metric_name": "final training loss", "lower_is_better": true, "description": "The final training loss achieved during the training process.", "data": [{"dataset_name": "query_response_dataset", "final_value": 0.0097, "best_value": 0.0097}]}, {"metric_name": "final validation loss", "lower_is_better": true, "description": "The final validation loss achieved on the validation dataset.", "data": [{"dataset_name": "query_response_dataset", "final_value": 0.0082, "best_value": 0.0082}]}, {"metric_name": "final validation quality-speed tradeoff", "lower_is_better": false, "description": "The final quality-speed tradeoff metric achieved on the validation dataset.", "data": [{"dataset_name": "query_response_dataset", "final_value": 1.0434, "best_value": 1.0434}]}]}, {"metric_names": [{"metric_name": "training loss", "lower_is_better": true, "description": "The loss value during training.", "data": [{"dataset_name": "dropout_rate_0.0", "final_value": 0.0099, "best_value": 0.0099}, {"dataset_name": "dropout_rate_0.2", "final_value": 0.0318, "best_value": 0.0318}, {"dataset_name": "dropout_rate_0.5", "final_value": 0.0464, "best_value": 0.0464}]}, {"metric_name": "validation loss", "lower_is_better": true, "description": "The loss value during validation.", "data": [{"dataset_name": "dropout_rate_0.0", "final_value": 0.0083, "best_value": 0.0083}, {"dataset_name": "dropout_rate_0.2", "final_value": 0.0228, "best_value": 0.0228}, {"dataset_name": "dropout_rate_0.5", "final_value": 0.0431, "best_value": 0.0431}]}, {"metric_name": "validation quality-speed tradeoff", "lower_is_better": false, "description": "The quality-speed tradeoff during validation.", "data": [{"dataset_name": "dropout_rate_0.0", "final_value": 1.0348, "best_value": 1.0348}, {"dataset_name": "dropout_rate_0.2", "final_value": 1.0243, "best_value": 1.0243}, {"dataset_name": "dropout_rate_0.5", "final_value": 1.0068, "best_value": 1.0068}]}]}, {"metric_names": [{"metric_name": "final training loss", "lower_is_better": true, "description": "The final training loss after training is complete.", "data": [{"dataset_name": "Momentum 0.0", "final_value": 0.0137, "best_value": 0.0137}, {"dataset_name": "Momentum 0.5", "final_value": 0.0098, "best_value": 0.0098}, {"dataset_name": "Momentum 0.9", "final_value": 0.0097, "best_value": 0.0097}]}, {"metric_name": "final validation loss", "lower_is_better": true, "description": "The final validation loss after training is complete.", "data": [{"dataset_name": "Momentum 0.0", "final_value": 0.014, "best_value": 0.014}, {"dataset_name": "Momentum 0.5", "final_value": 0.0086, "best_value": 0.0086}, {"dataset_name": "Momentum 0.9", "final_value": 0.0082, "best_value": 0.0082}]}, {"metric_name": "final quality-speed tradeoff", "lower_is_better": false, "description": "The final quality-speed tradeoff after training is complete.", "data": [{"dataset_name": "Momentum 0.0", "final_value": 1.0524, "best_value": 1.0524}, {"dataset_name": "Momentum 0.5", "final_value": 1.0495, "best_value": 1.0495}, {"dataset_name": "Momentum 0.9", "final_value": 1.0599, "best_value": 1.0599}]}]}, {"metric_names": [{"metric_name": "final training loss", "lower_is_better": true, "description": "The final loss value from the training phase.", "data": [{"dataset_name": "Momentum 0.0", "final_value": 0.0132, "best_value": 0.0132}, {"dataset_name": "Momentum 0.5", "final_value": 0.0105, "best_value": 0.0105}, {"dataset_name": "Momentum 0.9", "final_value": 0.0105, "best_value": 0.0105}]}, {"metric_name": "final validation loss", "lower_is_better": true, "description": "The final loss value from the validation phase.", "data": [{"dataset_name": "Momentum 0.0", "final_value": 0.0112, "best_value": 0.0112}, {"dataset_name": "Momentum 0.5", "final_value": 0.0079, "best_value": 0.0079}, {"dataset_name": "Momentum 0.9", "final_value": 0.0079, "best_value": 0.0079}]}, {"metric_name": "final quality-speed tradeoff", "lower_is_better": false, "description": "The final quality-speed tradeoff value, where higher values are better.", "data": [{"dataset_name": "Momentum 0.0", "final_value": 1.0215, "best_value": 1.0215}, {"dataset_name": "Momentum 0.5", "final_value": 1.0118, "best_value": 1.0118}, {"dataset_name": "Momentum 0.9", "final_value": 1.0172, "best_value": 1.0172}]}]}, {"metric_names": [{"metric_name": "Final Training Loss", "lower_is_better": true, "description": "The final training loss value after training is complete.", "data": [{"dataset_name": "Momentum 0.0", "final_value": 0.0132, "best_value": 0.0132}, {"dataset_name": "Momentum 0.5", "final_value": 0.0105, "best_value": 0.0105}, {"dataset_name": "Momentum 0.9", "final_value": 0.0105, "best_value": 0.0105}]}, {"metric_name": "Final Validation Loss", "lower_is_better": true, "description": "The final validation loss value after training is complete.", "data": [{"dataset_name": "Momentum 0.0", "final_value": 0.0112, "best_value": 0.0112}, {"dataset_name": "Momentum 0.5", "final_value": 0.0079, "best_value": 0.0079}, {"dataset_name": "Momentum 0.9", "final_value": 0.0079, "best_value": 0.0079}]}, {"metric_name": "Final Quality-Speed Tradeoff", "lower_is_better": false, "description": "The final quality-speed tradeoff value after training is complete.", "data": [{"dataset_name": "Momentum 0.0", "final_value": 1.0215, "best_value": 1.0215}, {"dataset_name": "Momentum 0.5", "final_value": 1.0118, "best_value": 1.0118}, {"dataset_name": "Momentum 0.9", "final_value": 1.0172, "best_value": 1.0172}]}]}], "is_best_node": [false, false, false, false, false, false, true, false, false], "plots": [["../../logs/0-run/experiment_results/experiment_020b8150f02a493e879a6de20343ae72_proc_3630414/training_validation_losses.png", "../../logs/0-run/experiment_results/experiment_020b8150f02a493e879a6de20343ae72_proc_3630414/quality_speed_tradeoff.png"], ["../../logs/0-run/experiment_results/experiment_10c772d4b4694dde8a6768e3c72e0893_proc_3634789/loss_curves_quality_prediction.png", "../../logs/0-run/experiment_results/experiment_10c772d4b4694dde8a6768e3c72e0893_proc_3634789/quality_speed_tradeoff.png"], ["../../logs/0-run/experiment_results/experiment_4d0bc32255de4e16a1395b1edfe8553a_proc_3634790/loss_curves_batch_size_16.png", "../../logs/0-run/experiment_results/experiment_4d0bc32255de4e16a1395b1edfe8553a_proc_3634790/loss_curves_batch_size_32.png", "../../logs/0-run/experiment_results/experiment_4d0bc32255de4e16a1395b1edfe8553a_proc_3634790/loss_curves_batch_size_64.png", "../../logs/0-run/experiment_results/experiment_4d0bc32255de4e16a1395b1edfe8553a_proc_3634790/quality_speed_tradeoff.png"], ["../../logs/0-run/experiment_results/experiment_676a761fe5fd45beac7f2f2e10faf6c6_proc_3634789/quality_route_training_validation_losses.png", "../../logs/0-run/experiment_results/experiment_676a761fe5fd45beac7f2f2e10faf6c6_proc_3634789/quality_route_quality_speed_tradeoff.png"], ["../../logs/0-run/experiment_results/experiment_ff2fb2732d5b42d3ba84e690748204a8_proc_3634790/query_response_dataset_loss_curves.png", "../../logs/0-run/experiment_results/experiment_ff2fb2732d5b42d3ba84e690748204a8_proc_3634790/query_response_dataset_quality_speed_tradeoff.png"], ["../../logs/0-run/experiment_results/experiment_8a38b856e99c49fbb5f9fd2c5cd0198e_proc_3634789/loss_curves.png", "../../logs/0-run/experiment_results/experiment_8a38b856e99c49fbb5f9fd2c5cd0198e_proc_3634789/quality_speed_tradeoff.png"], ["../../logs/0-run/experiment_results/experiment_a242946b6f3d4fec8489d145d0d64b35_proc_3634790/training_validation_loss_momentum_0.0.png", "../../logs/0-run/experiment_results/experiment_a242946b6f3d4fec8489d145d0d64b35_proc_3634790/training_validation_loss_momentum_0.5.png", "../../logs/0-run/experiment_results/experiment_a242946b6f3d4fec8489d145d0d64b35_proc_3634790/training_validation_loss_momentum_0.9.png", "../../logs/0-run/experiment_results/experiment_a242946b6f3d4fec8489d145d0d64b35_proc_3634790/quality_speed_tradeoff.png"], ["../../logs/0-run/experiment_results/experiment_c85ed562c43849c59e1e2cc15f9b6d03_proc_3634789/training_validation_loss_momentum_0.0.png", "../../logs/0-run/experiment_results/experiment_c85ed562c43849c59e1e2cc15f9b6d03_proc_3634789/training_validation_loss_momentum_0.5.png", "../../logs/0-run/experiment_results/experiment_c85ed562c43849c59e1e2cc15f9b6d03_proc_3634789/training_validation_loss_momentum_0.9.png", "../../logs/0-run/experiment_results/experiment_c85ed562c43849c59e1e2cc15f9b6d03_proc_3634789/quality_speed_tradeoff.png"], ["../../logs/0-run/experiment_results/experiment_cb8e561ff0b243159ab66f3a1be76584_proc_3634790/training_validation_loss_momentum_0.0.png", "../../logs/0-run/experiment_results/experiment_cb8e561ff0b243159ab66f3a1be76584_proc_3634790/training_validation_loss_momentum_0.5.png", "../../logs/0-run/experiment_results/experiment_cb8e561ff0b243159ab66f3a1be76584_proc_3634790/training_validation_loss_momentum_0.9.png", "../../logs/0-run/experiment_results/experiment_cb8e561ff0b243159ab66f3a1be76584_proc_3634790/quality_speed_tradeoff.png"]], "plot_paths": [["experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_020b8150f02a493e879a6de20343ae72_proc_3630414/training_validation_losses.png", "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_020b8150f02a493e879a6de20343ae72_proc_3630414/quality_speed_tradeoff.png"], ["experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_10c772d4b4694dde8a6768e3c72e0893_proc_3634789/loss_curves_quality_prediction.png", "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_10c772d4b4694dde8a6768e3c72e0893_proc_3634789/quality_speed_tradeoff.png"], ["experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_4d0bc32255de4e16a1395b1edfe8553a_proc_3634790/loss_curves_batch_size_16.png", "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_4d0bc32255de4e16a1395b1edfe8553a_proc_3634790/loss_curves_batch_size_32.png", "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_4d0bc32255de4e16a1395b1edfe8553a_proc_3634790/loss_curves_batch_size_64.png", "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_4d0bc32255de4e16a1395b1edfe8553a_proc_3634790/quality_speed_tradeoff.png"], ["experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_676a761fe5fd45beac7f2f2e10faf6c6_proc_3634789/quality_route_training_validation_losses.png", "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_676a761fe5fd45beac7f2f2e10faf6c6_proc_3634789/quality_route_quality_speed_tradeoff.png"], ["experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_ff2fb2732d5b42d3ba84e690748204a8_proc_3634790/query_response_dataset_loss_curves.png", "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_ff2fb2732d5b42d3ba84e690748204a8_proc_3634790/query_response_dataset_quality_speed_tradeoff.png"], ["experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_8a38b856e99c49fbb5f9fd2c5cd0198e_proc_3634789/loss_curves.png", "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_8a38b856e99c49fbb5f9fd2c5cd0198e_proc_3634789/quality_speed_tradeoff.png"], ["experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_a242946b6f3d4fec8489d145d0d64b35_proc_3634790/training_validation_loss_momentum_0.0.png", "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_a242946b6f3d4fec8489d145d0d64b35_proc_3634790/training_validation_loss_momentum_0.5.png", "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_a242946b6f3d4fec8489d145d0d64b35_proc_3634790/training_validation_loss_momentum_0.9.png", "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_a242946b6f3d4fec8489d145d0d64b35_proc_3634790/quality_speed_tradeoff.png"], ["experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_c85ed562c43849c59e1e2cc15f9b6d03_proc_3634789/training_validation_loss_momentum_0.0.png", "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_c85ed562c43849c59e1e2cc15f9b6d03_proc_3634789/training_validation_loss_momentum_0.5.png", "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_c85ed562c43849c59e1e2cc15f9b6d03_proc_3634789/training_validation_loss_momentum_0.9.png", "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_c85ed562c43849c59e1e2cc15f9b6d03_proc_3634789/quality_speed_tradeoff.png"], ["experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_cb8e561ff0b243159ab66f3a1be76584_proc_3634790/training_validation_loss_momentum_0.0.png", "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_cb8e561ff0b243159ab66f3a1be76584_proc_3634790/training_validation_loss_momentum_0.5.png", "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_cb8e561ff0b243159ab66f3a1be76584_proc_3634790/training_validation_loss_momentum_0.9.png", "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_cb8e561ff0b243159ab66f3a1be76584_proc_3634790/quality_speed_tradeoff.png"]], "plot_analyses": [[{"analysis": "The quality-speed tradeoff plot demonstrates fluctuations in the quality-speed ratio over the epochs. Initially, there is a notable spike, which may indicate adjustments in model parameters or learning rates. However, the overall trend appears to stabilize around 1.05 to 1.18, suggesting that while the model is capable of achieving a reasonable quality-speed tradeoff, it may require further tuning for consistent performance. The variability in the tradeoff could imply that the model is still adapting to the dataset and may improve with additional training or adjustments to the learning algorithm.", "plot_path": "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_020b8150f02a493e879a6de20343ae72_proc_3630414/training_validation_losses.png"}], [{"analysis": "The quality-speed tradeoff metric shows a fluctuating trend throughout the epochs. There is a notable spike at epoch 60, which aligns with the loss curve, suggesting that the model's performance in balancing quality and speed is sensitive to changes in training dynamics. The initial stability followed by fluctuations may indicate that while the model learns to predict quality, it struggles to maintain a consistent tradeoff. This could be a signal for further investigation into the model's capacity to generalize its learning to unseen data, as well as the need for refining the selection of draft-verify pairs.", "plot_path": "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_10c772d4b4694dde8a6768e3c72e0893_proc_3634789/loss_curves_quality_prediction.png"}], [{"analysis": "The Quality-Speed Tradeoff plot demonstrates that all batch sizes (16, 32, and 64) achieve similar metrics over the epochs. The values stabilize around 1.1, indicating that the model maintains a consistent balance between quality and speed regardless of the batch size used.", "plot_path": "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_4d0bc32255de4e16a1395b1edfe8553a_proc_3634790/loss_curves_batch_size_16.png"}], [{"analysis": "The training and validation losses show a significant drop in the initial epochs, indicating effective learning. The training loss stabilizes around 0.01, suggesting that the model is converging well. However, the validation loss also levels off at a similar value, indicating that the model may be experiencing some level of overfitting as the two curves are close together after the initial drop. Continued monitoring of these losses is essential to ensure the model generalizes well on unseen data.", "plot_path": "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_676a761fe5fd45beac7f2f2e10faf6c6_proc_3634789/quality_route_training_validation_losses.png"}, {"analysis": "The quality-speed tradeoff metric fluctuates throughout the epochs but does not show a clear upward or downward trend. The initial spike indicates some instability in the model's predictions, which may be due to the learning rate or hyperparameter settings. The overall stability of the metric in later epochs suggests that the model is maintaining a balance between quality and speed, but further tuning may be necessary to improve this tradeoff consistently.", "plot_path": "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_676a761fe5fd45beac7f2f2e10faf6c6_proc_3634789/quality_route_quality_speed_tradeoff.png"}], [{"analysis": "The quality-speed tradeoff plot shows a relatively uniform distribution of quality-speed tradeoff values across various weight decay settings. However, the presence of spikes indicates that certain configurations may yield better performance, though no clear optimal weight decay value emerges from the data. This suggests that while the model can achieve reasonable quality-speed tradeoffs, further exploration of hyperparameter tuning, especially around weight decay, is necessary to enhance performance.", "plot_path": "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_ff2fb2732d5b42d3ba84e690748204a8_proc_3634790/query_response_dataset_loss_curves.png"}], [{"analysis": "The training and validation loss curves indicate that the model with a dropout rate of 0.0 shows a significant drop in loss initially, suggesting effective learning. However, the validation loss remains higher compared to the training loss, indicating potential overfitting. The models with dropout rates of 0.2 and 0.5 show similar trends, with slightly higher validation losses, but they also exhibit more stable training curves, suggesting better generalization. The dropout mechanism seems to be effective in preventing overfitting at higher rates, but further tuning may be needed to optimize performance across all datasets.", "plot_path": "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_8a38b856e99c49fbb5f9fd2c5cd0198e_proc_3634789/loss_curves.png"}, {"analysis": "The quality-speed tradeoff for validation data indicates that all dropout rates initially show a spike, likely due to the model's adaptation phase. The curves stabilize over time, with dropout rates of 0.2 and 0.5 maintaining a slight edge in quality-speed tradeoff compared to 0.0. However, the differences are minimal, suggesting that while dropout has some impact, the overall architecture and dataset may play a larger role in determining the quality-speed balance. Further experiments with different datasets and hyperparameters could yield more pronounced effects.", "plot_path": "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_8a38b856e99c49fbb5f9fd2c5cd0198e_proc_3634789/quality_speed_tradeoff.png"}], [{"analysis": "The training and validation loss plots show a clear trend of decreasing loss over epochs for all momentum values. For momentum 0.0, the validation loss decreases steadily but does not converge to a low value, suggesting potential issues with overfitting or insufficient model capacity. Momentum 0.5 shows a more rapid decrease in both training and validation loss, indicating a better fit to the data. Finally, momentum 0.9 achieves the lowest validation loss, indicating that this momentum value helps stabilize the optimization process and leads to a more effective training outcome.", "plot_path": "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_a242946b6f3d4fec8489d145d0d64b35_proc_3634790/training_validation_loss_momentum_0.0.png"}, {"analysis": "In the second plot, the training loss decreases sharply initially, indicating that the model is learning effectively. The validation loss also decreases but levels off, suggesting that the model may be approaching a good fit. The gap between training and validation loss is relatively small, indicating that the model is not overfitting significantly, which is a positive outcome.", "plot_path": "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_a242946b6f3d4fec8489d145d0d64b35_proc_3634790/training_validation_loss_momentum_0.5.png"}, {"analysis": "The third plot shows that with momentum 0.9, both training and validation losses reach very low values, indicating a strong fit to the training data. The close convergence of the training and validation loss suggests that the model generalizes well without overfitting, making this momentum setting potentially the best choice for this experiment.", "plot_path": "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_a242946b6f3d4fec8489d145d0d64b35_proc_3634790/training_validation_loss_momentum_0.9.png"}, {"analysis": "The quality-speed tradeoff plot illustrates the performance of different momentum values across epochs. The curves for all momentum settings are relatively stable, with slight fluctuations, suggesting that the model maintains a consistent tradeoff between quality and speed. The momentum 0.9 setting shows the best performance, consistently achieving a quality-speed tradeoff that is slightly superior to the others, indicating that it balances quality and computational cost effectively.", "plot_path": "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_a242946b6f3d4fec8489d145d0d64b35_proc_3634790/quality_speed_tradeoff.png"}], [{"analysis": "The quality-speed tradeoff plot indicates that the model maintains a consistent quality-speed ratio across different momentum settings. Initially, there is a spike in the quality-speed tradeoff for momentum 0.0, but it stabilizes for all momentum values around 1.0, showing that adjustments in momentum do not significantly impact the tradeoff, suggesting robustness in performance.", "plot_path": "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_c85ed562c43849c59e1e2cc15f9b6d03_proc_3634789/training_validation_loss_momentum_0.0.png"}], [{"analysis": "The quality-speed tradeoff across epochs shows that all momentum settings converge towards a stable point, with Momentum: 0.0 initially achieving a higher quality-speed ratio. However, as training progresses, the tradeoffs for all momentum settings stabilize, indicating that while momentum affects initial performance, the long-term tradeoff remains consistent across different settings.", "plot_path": "experiments/2025-06-05_13-02-24_quality_predictive_routing_attempt_0/logs/0-run/experiment_results/experiment_cb8e561ff0b243159ab66f3a1be76584_proc_3634790/training_validation_loss_momentum_0.0.png"}]], "vlm_feedback_summary": ["The analysis indicates effective learning in the model with room for improvement\nin quality-speed tradeoffs.", "The training and validation loss curves indicate potential overfitting, while\nthe quality-speed tradeoff metric reflects instability during training.", "The plots indicate that the model is effectively learning across different batch\nsizes, with stable loss values and a consistent quality-speed tradeoff.", "The plots indicate that while the model is learning effectively, there may be\nconcerns regarding overfitting and the stability of the quality-speed tradeoff.", "Two plots were analyzed: 1) Loss curves indicating potential overfitting and\ninstability, and 2) Quality-speed tradeoff showing uniform performance with\nspikes suggesting areas for improvement.", "The plots provide insights into the model's performance with varying dropout\nrates, highlighting issues of overfitting and the effects of dropout on quality-\nspeed tradeoff.", "The analysis of the plots indicates that varying momentum values significantly\nimpact the model's training dynamics and performance metrics, with momentum 0.9\nyielding the best results.", "The analysis highlights effective learning dynamics across different momentum\nsettings, with improvements in loss metrics and stable quality-speed tradeoffs.", "The analysis indicates that varying momentum impacts convergence and\ngeneralization, with higher momentum potentially leading to better model\nperformance."], "exec_time": [2.088200330734253, 3.9026401042938232, 3.5035741329193115, 3.8502137660980225, 4.74289608001709, 4.044113874435425, 3.1292202472686768, 3.814242124557495, 3.8081822395324707], "exec_time_feedback": ["", "", "", "", "", "", "", "", ""], "datasets_successfully_tested": [["[\"quality_route\"]"], ["[hyperparam_tuning_learning_rate]"], ["batch_size_16", "batch_size_32", "batch_size_64"], ["quality_route"], ["query_response_dataset"], ["[\"dataset_with_dropout_0.0\"", "\"dataset_with_dropout_0.2\"", "\"dataset_with_dropout_0.5\"]"], ["[momentum_0.9]"], ["experiment_data"], ["[\"hyperparam_tuning_momentum\"]"]], "plot_code": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n\ntry:\n    plt.figure()\n    plt.plot(experiment_data[\"quality_route\"][\"losses\"][\"train\"], label=\"Training Loss\")\n    plt.plot(experiment_data[\"quality_route\"][\"losses\"][\"val\"], label=\"Validation Loss\")\n    plt.title(\"Training and Validation Losses Over Epochs\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"training_validation_losses.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating training/validation losses plot: {e}\")\n    plt.close()\n\ntry:\n    plt.figure()\n    plt.plot(\n        experiment_data[\"quality_route\"][\"metrics\"][\"val\"],\n        label=\"Quality-Speed Tradeoff\",\n    )\n    plt.title(\"Quality-Speed Tradeoff Over Epochs\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Quality-Speed Tradeoff\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"quality_speed_tradeoff.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating quality-speed tradeoff plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n\ntry:\n    train_losses = experiment_data[\"hyperparam_tuning_learning_rate\"][\"quality_route\"][\n        \"losses\"\n    ][\"train\"]\n    val_losses = experiment_data[\"hyperparam_tuning_learning_rate\"][\"quality_route\"][\n        \"losses\"\n    ][\"val\"]\n    epochs = range(1, len(train_losses) + 1)\n\n    plt.figure()\n    plt.plot(epochs, train_losses, label=\"Train Loss\")\n    plt.plot(epochs, val_losses, label=\"Validation Loss\")\n    plt.title(\"Loss Curves for Quality Prediction\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"loss_curves_quality_prediction.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curve plot: {e}\")\n\ntry:\n    metrics = experiment_data[\"hyperparam_tuning_learning_rate\"][\"quality_route\"][\n        \"metrics\"\n    ][\"val\"]\n    plt.figure()\n    plt.plot(epochs, metrics, label=\"Quality-Speed Tradeoff\", color=\"orange\")\n    plt.title(\"Quality-Speed Tradeoff\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Tradeoff Metric\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"quality_speed_tradeoff.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating quality-speed tradeoff plot: {e}\")\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexperiment_data = np.load(\n    os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n).item()\n\n# Plotting training and validation losses\nbatch_sizes = [16, 32, 64]\nfor batch_size in batch_sizes:\n    try:\n        losses = experiment_data[\"batch_size_tuning\"][f\"batch_size_{batch_size}\"][\n            \"losses\"\n        ]\n        plt.figure()\n        plt.plot(losses[\"train\"], label=\"Training Loss\")\n        plt.plot(losses[\"val\"], label=\"Validation Loss\")\n        plt.title(f\"Loss Curves for Batch Size {batch_size}\")\n        plt.xlabel(\"Epochs\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n        plt.savefig(\n            os.path.join(working_dir, f\"loss_curves_batch_size_{batch_size}.png\")\n        )\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for batch size {batch_size}: {e}\")\n        plt.close()\n\n# Plotting quality-speed tradeoff\ntry:\n    plt.figure()\n    for batch_size in batch_sizes:\n        quality_speed = experiment_data[\"batch_size_tuning\"][\n            f\"batch_size_{batch_size}\"\n        ][\"metrics\"][\"val\"]\n        plt.plot(quality_speed, label=f\"Batch Size {batch_size}\")\n    plt.title(\"Quality-Speed Tradeoff\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Quality-Speed Tradeoff Metric\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"quality_speed_tradeoff.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating quality-speed tradeoff plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexperiment_data = np.load(\n    os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n).item()\n\ntry:\n    plt.figure()\n    plt.plot(\n        experiment_data[\"hyperparam_tuning_epochs\"][\"quality_route\"][\"losses\"][\"train\"],\n        label=\"Training Loss\",\n    )\n    plt.plot(\n        experiment_data[\"hyperparam_tuning_epochs\"][\"quality_route\"][\"losses\"][\"val\"],\n        label=\"Validation Loss\",\n    )\n    plt.title(\"Training and Validation Losses\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.savefig(\n        os.path.join(working_dir, \"quality_route_training_validation_losses.png\")\n    )\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating training/validation loss plot: {e}\")\n    plt.close()\n\ntry:\n    plt.figure()\n    plt.plot(\n        experiment_data[\"hyperparam_tuning_epochs\"][\"quality_route\"][\"metrics\"][\"val\"],\n        label=\"Quality-Speed Tradeoff\",\n    )\n    plt.title(\"Quality-Speed Tradeoff Over Epochs\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Tradeoff Metric\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"quality_route_quality_speed_tradeoff.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating quality-speed tradeoff plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nos.makedirs(working_dir, exist_ok=True)\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n\nweight_decays = list(\n    experiment_data[\"weight_decay_tuning\"][\"query_response_dataset\"][\"losses\"][\"train\"]\n)\ntrain_losses = experiment_data[\"weight_decay_tuning\"][\"query_response_dataset\"][\n    \"losses\"\n][\"train\"]\nval_losses = experiment_data[\"weight_decay_tuning\"][\"query_response_dataset\"][\"losses\"][\n    \"val\"\n]\nmetrics = experiment_data[\"weight_decay_tuning\"][\"query_response_dataset\"][\"metrics\"][\n    \"val\"\n]\n\ntry:\n    plt.figure()\n    plt.plot(range(1, len(train_losses) + 1), train_losses, label=\"Training Loss\")\n    plt.plot(range(1, len(val_losses) + 1), val_losses, label=\"Validation Loss\")\n    plt.title(\"Loss Curves: Query Response Dataset\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"query_response_dataset_loss_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curves plot: {e}\")\n    plt.close()\n\ntry:\n    plt.figure()\n    plt.bar(range(len(weight_decays)), metrics)\n    plt.xticks(range(len(weight_decays)), weight_decays)\n    plt.title(\"Quality-Speed Tradeoff: Query Response Dataset\")\n    plt.xlabel(\"Weight Decay\")\n    plt.ylabel(\"Quality-Speed Tradeoff\")\n    plt.savefig(\n        os.path.join(working_dir, \"query_response_dataset_quality_speed_tradeoff.png\")\n    )\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating quality-speed tradeoff plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexperiment_data = np.load(\n    os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n).item()\n\n# Plot training and validation loss curves\ntry:\n    plt.figure()\n    for rate in experiment_data[\"dropout_tuning\"]:\n        plt.plot(\n            experiment_data[\"dropout_tuning\"][rate][\"losses\"][\"train\"],\n            label=f\"Train Loss {rate}\",\n        )\n        plt.plot(\n            experiment_data[\"dropout_tuning\"][rate][\"losses\"][\"val\"],\n            label=f\"Val Loss {rate}\",\n            linestyle=\"--\",\n        )\n    plt.title(\"Training and Validation Loss Curves\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"loss_curves.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating loss curves plot: {e}\")\n    plt.close()\n\n# Plot quality-speed tradeoff\ntry:\n    plt.figure()\n    for rate in experiment_data[\"dropout_tuning\"]:\n        plt.plot(\n            experiment_data[\"dropout_tuning\"][rate][\"metrics\"][\"val\"],\n            label=f\"Quality-Speed Tradeoff {rate}\",\n        )\n    plt.title(\"Quality-Speed Tradeoff for Validation Data\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Quality-Speed Tradeoff\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"quality_speed_tradeoff.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating quality-speed tradeoff plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n\nmomentum_values = list(experiment_data[\"hyperparam_tuning_momentum\"].keys())\n\nfor momentum in momentum_values:\n    try:\n        plt.figure()\n        plt.plot(\n            experiment_data[\"hyperparam_tuning_momentum\"][momentum][\"losses\"][\"train\"],\n            label=\"Train Loss\",\n        )\n        plt.plot(\n            experiment_data[\"hyperparam_tuning_momentum\"][momentum][\"losses\"][\"val\"],\n            label=\"Validation Loss\",\n        )\n        plt.title(f\"Training and Validation Loss (Momentum: {momentum})\")\n        plt.xlabel(\"Epochs\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n        plt.savefig(\n            os.path.join(\n                working_dir, f\"training_validation_loss_momentum_{momentum}.png\"\n            )\n        )\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for momentum {momentum}: {e}\")\n        plt.close()\n\ntry:\n    plt.figure()\n    for momentum in momentum_values:\n        plt.plot(\n            experiment_data[\"hyperparam_tuning_momentum\"][momentum][\"metrics\"][\"val\"],\n            label=f\"Momentum: {momentum}\",\n        )\n    plt.title(\"Quality-Speed Tradeoff across Epochs\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Quality-Speed Tradeoff\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"quality_speed_tradeoff.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating quality-speed tradeoff plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n\nmomentum_values = list(experiment_data[\"hyperparam_tuning_momentum\"].keys())\n\nfor momentum in momentum_values:\n    try:\n        plt.figure()\n        plt.plot(\n            experiment_data[\"hyperparam_tuning_momentum\"][momentum][\"losses\"][\"train\"],\n            label=\"Train Loss\",\n        )\n        plt.plot(\n            experiment_data[\"hyperparam_tuning_momentum\"][momentum][\"losses\"][\"val\"],\n            label=\"Validation Loss\",\n        )\n        plt.title(f\"Training and Validation Loss (Momentum: {momentum})\")\n        plt.xlabel(\"Epochs\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n        plt.savefig(\n            os.path.join(\n                working_dir, f\"training_validation_loss_momentum_{momentum}.png\"\n            )\n        )\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for momentum {momentum}: {e}\")\n        plt.close()\n\ntry:\n    plt.figure()\n    for momentum in momentum_values:\n        plt.plot(\n            experiment_data[\"hyperparam_tuning_momentum\"][momentum][\"metrics\"][\"val\"],\n            label=f\"Momentum: {momentum}\",\n        )\n    plt.title(\"Quality-Speed Tradeoff across Epochs\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Quality-Speed Tradeoff\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"quality_speed_tradeoff.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating quality-speed tradeoff plot: {e}\")\n    plt.close()\n", "import matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nworking_dir = os.path.join(os.getcwd(), \"working\")\n\ntry:\n    experiment_data = np.load(\n        os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n    ).item()\nexcept Exception as e:\n    print(f\"Error loading experiment data: {e}\")\n\nmomentum_values = list(experiment_data[\"hyperparam_tuning_momentum\"].keys())\n\nfor momentum in momentum_values:\n    try:\n        plt.figure()\n        plt.plot(\n            experiment_data[\"hyperparam_tuning_momentum\"][momentum][\"losses\"][\"train\"],\n            label=\"Train Loss\",\n        )\n        plt.plot(\n            experiment_data[\"hyperparam_tuning_momentum\"][momentum][\"losses\"][\"val\"],\n            label=\"Validation Loss\",\n        )\n        plt.title(f\"Training and Validation Loss (Momentum: {momentum})\")\n        plt.xlabel(\"Epochs\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n        plt.savefig(\n            os.path.join(\n                working_dir, f\"training_validation_loss_momentum_{momentum}.png\"\n            )\n        )\n        plt.close()\n    except Exception as e:\n        print(f\"Error creating loss plot for momentum {momentum}: {e}\")\n        plt.close()\n\ntry:\n    plt.figure()\n    for momentum in momentum_values:\n        plt.plot(\n            experiment_data[\"hyperparam_tuning_momentum\"][momentum][\"metrics\"][\"val\"],\n            label=f\"Momentum: {momentum}\",\n        )\n    plt.title(\"Quality-Speed Tradeoff across Epochs\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Quality-Speed Tradeoff\")\n    plt.legend()\n    plt.savefig(os.path.join(working_dir, \"quality_speed_tradeoff.png\"))\n    plt.close()\nexcept Exception as e:\n    print(f\"Error creating quality-speed tradeoff plot: {e}\")\n    plt.close()\n"], "plot_plan": ["To visualize the experiment results, we will load the `experiment_data.npy` file and extract the training and validation losses as well as the quality-speed tradeoff metrics. We will create separate plots for training and validation losses over epochs, clearly labeling each plot with appropriate titles and subtitles. Additionally, we'll plot the quality-speed tradeoff metric, ensuring that each plot is saved in the specified `working_dir`. Each plot will be enclosed in a try-except block to handle any errors during the plotting process, and the figures will be closed immediately after saving to manage memory efficiently.", "To visualize the results of the experiment, I will extract the relevant data from the `experiment_data.npy` file. I will create plots for training and validation losses over epochs, and also for the quality-speed tradeoff metric. Each plot will be saved in the specified `working_dir`. The code will include try-except blocks for error handling while loading the data and creating plots, ensuring that figures are closed properly after saving. I'll implement suitable intervals for plotting to limit the number of figures to at most five. Each figure will be given a descriptive title and filename.", "To visualize the experiment results, I'll first load the `experiment_data.npy` file to extract the training and validation losses, as well as the quality-speed tradeoff metrics for different batch sizes. I'll create plots for the training and validation loss curves, ensuring to label them clearly with titles and subtitles. Additionally, I'll plot the quality-speed tradeoff for each batch size. Each plot will be wrapped in a try-except block for error handling, and I will save them with descriptive names in the 'working' directory. Finally, I will ensure to close each figure after saving to free resources.", "To visualize the experiment results stored in `experiment_data.npy`, I will create standard plots for training and validation losses, as well as for the quality-speed tradeoff metric over the different epochs. Each plot will be created inside separate try-except blocks to handle potential errors gracefully. The training and validation losses will be plotted on the same figure to facilitate comparison, and the title will specify the dataset and type of plot. The quality-speed tradeoff will be plotted separately. I will save all figures to the `working_dir`, ensuring that the filenames are descriptive. After saving each plot, I will close the figure to free up resources.", "To visualize the results from the experiment data, I will load the data from `experiment_data.npy` and create plots for the training and validation losses over epochs. I will also plot the quality-speed tradeoff metric for each weight decay value. Each plot will be generated in its own try-except block to handle potential errors during plotting. The figures will be saved in the `working_dir` with descriptive filenames indicating the dataset used and the type of metric being visualized. I will ensure that each plot includes a title and will close the figures after saving them.", "To visualize the experiment results, I will load the saved experiment data from `experiment_data.npy` and create multiple plots. The first plot will display the training and validation loss curves for different dropout rates, showing how the loss changes over epochs. The second plot will illustrate the quality-speed tradeoff for validation data, showing the relationship between the quality predictions and processing times for each dropout rate. Each plot will be saved in the `working_dir` with descriptive filenames. I will ensure that figures are closed after saving, and appropriate try-except blocks will handle any exceptions during the plotting process.", "To visualize the experiment results, we will load the saved `experiment_data.npy` file and create multiple plots based on the training and validation losses across different momentum values. We will also plot the quality-speed tradeoff metric. Each plot will be saved in the `working_dir` with descriptive titles indicating the dataset and the type of plot. We will handle plotting in separate try-except blocks to ensure robustness, and we will close each figure after saving it. For the training and validation loss curves, we will create one plot for each momentum value, while for the quality-speed tradeoff, a single plot will summarize the results across epochs.", null, null], "ablation_name": [null, null, null, null, null, null, null, null, null], "hyperparam_name": [null, "learning rate", "batch_size", "num_epochs", "weight_decay", "dropout_rate", "momentum", null, null], "is_seed_node": [false, false, false, false, false, false, false, true, true], "is_seed_agg_node": [false, false, false, false, false, false, false, false, false], "parse_metrics_plan": ["I will load the experiment data from the `experiment_data.npy` file located in\nthe working directory. I will then extract and print the relevant metrics for\nthe quality prediction task, ensuring to clearly label each metric with its\ndescription. Finally, I will display only the best or final values for each\nmetric, adhering to the specified requirements.", "I will load the `experiment_data.npy` file from the working directory and\nextract the metrics for the training and validation datasets. The structure of\nthe data will be referred to ensure that the correct values are accessed. I will\nprint the dataset name followed by each metric name and its corresponding value,\nfocusing on the final values for each metric.", "I will load the `experiment_data.npy` file from the working directory and\nextract the metrics for each batch size. For each dataset, I will print the name\nof the dataset followed by the final values of each metric, ensuring that the\nlabels are clear and precise. This will provide a concise summary of the\nexperimental results without any visualizations.", "To analyze the metrics stored in the `experiment_data.npy` file, I will first\nload the file from the working directory. Then, I will extract the training and\nvalidation losses, along with the validation metrics for the quality route\ndataset. Finally, I will print the final values of each metric clearly labeled\nfor easy understanding.", "The solution involves loading the `experiment_data.npy` file from the working\ndirectory and extracting metrics related to the quality predictor model's\nperformance. For each dataset, we will print the metrics with clear labels for\nbetter understanding, specifically focusing on the final values for training\nloss, validation loss, and any other relevant metrics. The output will be\nstructured to ensure clarity and correctness.", "I will load the `experiment_data.npy` file from the specified working directory\nand extract the relevant metrics for each dropout rate. For each dataset, I will\nprint the final training loss, validation loss, and validation quality-speed\ntradeoff with clear labels. This will ensure that the output is informative and\nwell-structured.", "I will load the `experiment_data.npy` file from the working directory and\nextract the metrics for each momentum value. For each dataset, I will print the\nbest or final value for the training loss, validation loss, and the quality-\nspeed tradeoff metric, ensuring that the names of the metrics are descriptive.", "I will load the `experiment_data.npy` file from the working directory and\nextract the metrics for each momentum value. For each dataset, I will print the\nbest or final value for the training loss, validation loss, and the quality-\nspeed tradeoff metric, ensuring that the names of the metrics are descriptive.", "I will load the `experiment_data.npy` file from the working directory and\nextract the metrics for each momentum value. For each dataset, I will print the\nbest or final value for the training loss, validation loss, and the quality-\nspeed tradeoff metric, ensuring that the names of the metrics are descriptive."], "parse_metrics_code": ["import os\nimport numpy as np\n\n# Load experiment data\nexperiment_data = np.load(\n    os.path.join(os.getcwd(), \"working\", \"experiment_data.npy\"), allow_pickle=True\n).item()\n\n# Extract metrics for the quality_route dataset\ndataset_name = \"Quality Route\"\n\n# Extract and print train and validation losses\ntrain_loss = experiment_data[\"quality_route\"][\"losses\"][\"train\"][-1]\nval_loss = experiment_data[\"quality_route\"][\"losses\"][\"val\"][-1]\nquality_speed_tradeoff = experiment_data[\"quality_route\"][\"metrics\"][\"val\"][-1]\n\nprint(f\"{dataset_name} - Final train loss: {train_loss:.4f}\")\nprint(f\"{dataset_name} - Final validation loss: {val_loss:.4f}\")\nprint(f\"{dataset_name} - Final quality speed tradeoff: {quality_speed_tradeoff:.4f}\")\n", "import os\nimport numpy as np\n\n# Load the experiment data\nexperiment_data = np.load(\n    os.path.join(os.getcwd(), \"working\", \"experiment_data.npy\"), allow_pickle=True\n).item()\n\n# Extract metrics for the quality route\ndataset_name = \"Quality Route\"\nmetrics = experiment_data[\"hyperparam_tuning_learning_rate\"][\"quality_route\"]\n\n# Print training metrics\nprint(f\"Dataset: {dataset_name}\")\nprint(f\"Final training loss: {metrics['losses']['train'][-1]:.4f}\")\n\n# Print validation metrics\nprint(f\"Final validation loss: {metrics['losses']['val'][-1]:.4f}\")\nprint(f\"Final validation quality-speed tradeoff: {metrics['metrics']['val'][-1]:.4f}\")\n", "import os\nimport numpy as np\n\n# Load the experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexperiment_data = np.load(\n    os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n).item()\n\n# Extract and print metrics\nfor batch_size, data in experiment_data[\"batch_size_tuning\"].items():\n    print(f\"Dataset: {batch_size}\")\n    train_loss_final = data[\"losses\"][\"train\"][-1]\n    val_loss_final = data[\"losses\"][\"val\"][-1]\n    quality_speed_tradeoff_final = data[\"metrics\"][\"val\"][-1]\n\n    print(f\"Final training loss: {train_loss_final:.4f}\")\n    print(f\"Final validation loss: {val_loss_final:.4f}\")\n    print(f\"Final quality-speed tradeoff: {quality_speed_tradeoff_final:.4f}\")\n", "import os\nimport numpy as np\n\n# Load experiment data\nexperiment_data = np.load(\n    os.path.join(os.getcwd(), \"working\", \"experiment_data.npy\"), allow_pickle=True\n).item()\n\n# Extract metrics for the quality route dataset\ndataset_name = \"Quality Route\"\ntrain_losses = experiment_data[\"hyperparam_tuning_epochs\"][\"quality_route\"][\"losses\"][\n    \"train\"\n]\nval_losses = experiment_data[\"hyperparam_tuning_epochs\"][\"quality_route\"][\"losses\"][\n    \"val\"\n]\nval_metrics = experiment_data[\"hyperparam_tuning_epochs\"][\"quality_route\"][\"metrics\"][\n    \"val\"\n]\n\n# Print the metrics\nprint(f\"Dataset: {dataset_name}\")\nprint(f\"Final Training Loss: {train_losses[-1]:.4f}\")\nprint(f\"Final Validation Loss: {val_losses[-1]:.4f}\")\nprint(f\"Final Validation Metric (Quality-Speed Tradeoff): {val_metrics[-1]:.4f}\")\n", "import os\nimport numpy as np\n\n# Load experiment data\nexperiment_data = np.load(\n    os.path.join(os.getcwd(), \"working\", \"experiment_data.npy\"), allow_pickle=True\n).item()\n\n# Extract metrics\ndataset_name = \"query_response_dataset\"\nmetrics = experiment_data[\"weight_decay_tuning\"][dataset_name][\"metrics\"]\nlosses = experiment_data[\"weight_decay_tuning\"][dataset_name][\"losses\"]\n\n# Print the metrics\nprint(f\"Metrics for {dataset_name}:\")\nprint(f\"Final training loss: {losses['train'][-1]:.4f}\")\nprint(f\"Final validation loss: {losses['val'][-1]:.4f}\")\nprint(f\"Final validation quality-speed tradeoff: {metrics['val'][-1]:.4f}\")\n", "import os\nimport numpy as np\n\n# Load experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexperiment_data = np.load(\n    os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n).item()\n\n# Extract metrics and print them\nfor dropout_rate, data in experiment_data[\"dropout_tuning\"].items():\n    print(f\"Metrics for {dropout_rate}:\")\n    final_train_loss = data[\"losses\"][\"train\"][-1] if data[\"losses\"][\"train\"] else None\n    final_val_loss = data[\"losses\"][\"val\"][-1] if data[\"losses\"][\"val\"] else None\n    final_quality_speed_tradeoff = (\n        data[\"metrics\"][\"val\"][-1] if data[\"metrics\"][\"val\"] else None\n    )\n\n    if final_train_loss is not None:\n        print(f\"Final training loss: {final_train_loss:.4f}\")\n    if final_val_loss is not None:\n        print(f\"Final validation loss: {final_val_loss:.4f}\")\n    if final_quality_speed_tradeoff is not None:\n        print(\n            f\"Final validation quality-speed tradeoff: {final_quality_speed_tradeoff:.4f}\"\n        )\n", "import os\nimport numpy as np\n\n# Load the experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexperiment_data = np.load(\n    os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n).item()\n\n# Extract and print metrics\nfor momentum, data in experiment_data[\"hyperparam_tuning_momentum\"].items():\n    print(f\"Dataset for Momentum: {momentum}\")\n\n    # Training loss\n    final_train_loss = data[\"losses\"][\"train\"][-1] if data[\"losses\"][\"train\"] else None\n    print(\n        f\"Final Training Loss: {final_train_loss:.4f}\"\n        if final_train_loss is not None\n        else \"No Training Loss data available\"\n    )\n\n    # Validation loss\n    final_val_loss = data[\"losses\"][\"val\"][-1] if data[\"losses\"][\"val\"] else None\n    print(\n        f\"Final Validation Loss: {final_val_loss:.4f}\"\n        if final_val_loss is not None\n        else \"No Validation Loss data available\"\n    )\n\n    # Quality-speed tradeoff\n    final_quality_speed_tradeoff = (\n        data[\"metrics\"][\"val\"][-1] if data[\"metrics\"][\"val\"] else None\n    )\n    print(\n        f\"Final Quality-Speed Tradeoff: {final_quality_speed_tradeoff:.4f}\"\n        if final_quality_speed_tradeoff is not None\n        else \"No Quality-Speed Tradeoff data available\"\n    )\n", "import os\nimport numpy as np\n\n# Load the experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexperiment_data = np.load(\n    os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n).item()\n\n# Extract and print metrics\nfor momentum, data in experiment_data[\"hyperparam_tuning_momentum\"].items():\n    print(f\"Dataset for Momentum: {momentum}\")\n\n    # Training loss\n    final_train_loss = data[\"losses\"][\"train\"][-1] if data[\"losses\"][\"train\"] else None\n    print(\n        f\"Final Training Loss: {final_train_loss:.4f}\"\n        if final_train_loss is not None\n        else \"No Training Loss data available\"\n    )\n\n    # Validation loss\n    final_val_loss = data[\"losses\"][\"val\"][-1] if data[\"losses\"][\"val\"] else None\n    print(\n        f\"Final Validation Loss: {final_val_loss:.4f}\"\n        if final_val_loss is not None\n        else \"No Validation Loss data available\"\n    )\n\n    # Quality-speed tradeoff\n    final_quality_speed_tradeoff = (\n        data[\"metrics\"][\"val\"][-1] if data[\"metrics\"][\"val\"] else None\n    )\n    print(\n        f\"Final Quality-Speed Tradeoff: {final_quality_speed_tradeoff:.4f}\"\n        if final_quality_speed_tradeoff is not None\n        else \"No Quality-Speed Tradeoff data available\"\n    )\n", "import os\nimport numpy as np\n\n# Load the experiment data\nworking_dir = os.path.join(os.getcwd(), \"working\")\nexperiment_data = np.load(\n    os.path.join(working_dir, \"experiment_data.npy\"), allow_pickle=True\n).item()\n\n# Extract and print metrics\nfor momentum, data in experiment_data[\"hyperparam_tuning_momentum\"].items():\n    print(f\"Dataset for Momentum: {momentum}\")\n\n    # Training loss\n    final_train_loss = data[\"losses\"][\"train\"][-1] if data[\"losses\"][\"train\"] else None\n    print(\n        f\"Final Training Loss: {final_train_loss:.4f}\"\n        if final_train_loss is not None\n        else \"No Training Loss data available\"\n    )\n\n    # Validation loss\n    final_val_loss = data[\"losses\"][\"val\"][-1] if data[\"losses\"][\"val\"] else None\n    print(\n        f\"Final Validation Loss: {final_val_loss:.4f}\"\n        if final_val_loss is not None\n        else \"No Validation Loss data available\"\n    )\n\n    # Quality-speed tradeoff\n    final_quality_speed_tradeoff = (\n        data[\"metrics\"][\"val\"][-1] if data[\"metrics\"][\"val\"] else None\n    )\n    print(\n        f\"Final Quality-Speed Tradeoff: {final_quality_speed_tradeoff:.4f}\"\n        if final_quality_speed_tradeoff is not None\n        else \"No Quality-Speed Tradeoff data available\"\n    )\n"], "parse_term_out": ["['Quality Route - Final train loss: 0.0099', '\\n', 'Quality Route - Final\nvalidation loss: 0.0083', '\\n', 'Quality Route - Final quality speed tradeoff:\n1.0348', '\\n', 'Execution time: a moment seconds (time limit is an hour).']", "['Dataset: Quality Route', '\\n', 'Final training loss: 0.0138', '\\n', 'Final\nvalidation loss: 0.0115', '\\n', 'Final validation quality-speed tradeoff:\n1.1238', '\\n', 'Execution time: a moment seconds (time limit is an hour).']", "['Dataset: batch_size_16', '\\n', 'Final training loss: 0.0102', '\\n', 'Final\nvalidation loss: 0.0094', '\\n', 'Final quality-speed tradeoff: 1.0976', '\\n',\n'Dataset: batch_size_32', '\\n', 'Final training loss: 0.0097', '\\n', 'Final\nvalidation loss: 0.0083', '\\n', 'Final quality-speed tradeoff: 1.0357', '\\n',\n'Dataset: batch_size_64', '\\n', 'Final training loss: 0.0097', '\\n', 'Final\nvalidation loss: 0.0089', '\\n', 'Final quality-speed tradeoff: 1.0586', '\\n',\n'Execution time: a moment seconds (time limit is an hour).']", "['Dataset: Quality Route', '\\n', 'Final Training Loss: 0.0098', '\\n', 'Final\nValidation Loss: 0.0082', '\\n', 'Final Validation Metric (Quality-Speed\nTradeoff): 1.0430', '\\n', 'Execution time: a moment seconds (time limit is an\nhour).']", "['Metrics for query_response_dataset:', '\\n', 'Final training loss: 0.0097',\n'\\n', 'Final validation loss: 0.0082', '\\n', 'Final validation quality-speed\ntradeoff: 1.0434', '\\n', 'Execution time: a moment seconds (time limit is an\nhour).']", "['Metrics for dropout_rate_0.0:', '\\n', 'Final training loss: 0.0099', '\\n',\n'Final validation loss: 0.0083', '\\n', 'Final validation quality-speed tradeoff:\n1.0348', '\\n', 'Metrics for dropout_rate_0.2:', '\\n', 'Final training loss:\n0.0318', '\\n', 'Final validation loss: 0.0228', '\\n', 'Final validation quality-\nspeed tradeoff: 1.0243', '\\n', 'Metrics for dropout_rate_0.5:', '\\n', 'Final\ntraining loss: 0.0464', '\\n', 'Final validation loss: 0.0431', '\\n', 'Final\nvalidation quality-speed tradeoff: 1.0068', '\\n', 'Execution time: a moment\nseconds (time limit is an hour).']", "['Dataset for Momentum: 0.0', '\\n', 'Final Training Loss: 0.0137', '\\n', 'Final\nValidation Loss: 0.0140', '\\n', 'Final Quality-Speed Tradeoff: 1.0524', '\\n',\n'Dataset for Momentum: 0.5', '\\n', 'Final Training Loss: 0.0098', '\\n', 'Final\nValidation Loss: 0.0086', '\\n', 'Final Quality-Speed Tradeoff: 1.0495', '\\n',\n'Dataset for Momentum: 0.9', '\\n', 'Final Training Loss: 0.0097', '\\n', 'Final\nValidation Loss: 0.0082', '\\n', 'Final Quality-Speed Tradeoff: 1.0599', '\\n',\n'Execution time: a moment seconds (time limit is an hour).']", "['Dataset for Momentum: 0.0', '\\n', 'Final Training Loss: 0.0132', '\\n', 'Final\nValidation Loss: 0.0112', '\\n', 'Final Quality-Speed Tradeoff: 1.0215', '\\n',\n'Dataset for Momentum: 0.5', '\\n', 'Final Training Loss: 0.0105', '\\n', 'Final\nValidation Loss: 0.0079', '\\n', 'Final Quality-Speed Tradeoff: 1.0118', '\\n',\n'Dataset for Momentum: 0.9', '\\n', 'Final Training Loss: 0.0105', '\\n', 'Final\nValidation Loss: 0.0079', '\\n', 'Final Quality-Speed Tradeoff: 1.0172', '\\n',\n'Execution time: a moment seconds (time limit is an hour).']", "['Dataset for Momentum: 0.0', '\\n', 'Final Training Loss: 0.0132', '\\n', 'Final\nValidation Loss: 0.0112', '\\n', 'Final Quality-Speed Tradeoff: 1.0215', '\\n',\n'Dataset for Momentum: 0.5', '\\n', 'Final Training Loss: 0.0105', '\\n', 'Final\nValidation Loss: 0.0079', '\\n', 'Final Quality-Speed Tradeoff: 1.0118', '\\n',\n'Dataset for Momentum: 0.9', '\\n', 'Final Training Loss: 0.0105', '\\n', 'Final\nValidation Loss: 0.0079', '\\n', 'Final Quality-Speed Tradeoff: 1.0172', '\\n',\n'Execution time: a moment seconds (time limit is an hour).']"], "parse_exc_type": [null, null, null, null, null, null, null, null, null], "parse_exc_info": [null, null, null, null, null, null, null, null, null], "parse_exc_stack": [null, null, null, null, null, null, null, null, null], "completed_stages": ["Stage_1", "Stage_2"]}